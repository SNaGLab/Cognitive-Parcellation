{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#To hide warnings export PYTHONWARNINGS=\"ignore\"\n",
    "#Imports{\n",
    "\n",
    "import os\n",
    "from os.path import dirname\n",
    "from os.path import join\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' #Cha\n",
    "\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from imageio import imread\n",
    "from skimage.transform import resize\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "#K.set_image_dim_ordering('tf')\n",
    "from keras_applications import imagenet_utils as utils\n",
    "from keras_applications import correct_pad\n",
    "from keras.layers import Lambda\n",
    "\n",
    "import PIL.Image\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code snippet needed to read activation values from each layer of the pre-trained artificial neural networks\n",
    "def get_activations(model, layer, X_batch):\n",
    "    #keras.backend.function(inputs, outputs, updates=None)\n",
    "    get_activations = keras.backend.function([model.layers[0].input, keras.backend.learning_phase()], [model.layers[layer].output,])\n",
    "    #The learning phase flag is a bool tensor (0 = test, 1 = train)\n",
    "    activations = get_activations([X_batch,0])\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'channels_last'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backend= keras.backend\n",
    "layers = keras.layers\n",
    "models = keras.models\n",
    "keras_utils = keras.utils\n",
    "keras.backend.image_data_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"MobileNet v2 models for Keras.\n",
    "\n",
    "MobileNetV2 is a general architecture and can be used for multiple use cases.\n",
    "Depending on the use case, it can use different input layer size and\n",
    "different width factors. This allows different width models to reduce\n",
    "the number of multiply-adds and thereby\n",
    "reduce inference cost on mobile devices.\n",
    "\n",
    "MobileNetV2 is very similar to the original MobileNet,\n",
    "except that it uses inverted residual blocks with\n",
    "bottlenecking features. It has a drastically lower\n",
    "parameter count than the original MobileNet.\n",
    "MobileNets support any input size greater\n",
    "than 32 x 32, with larger image sizes\n",
    "offering better performance.\n",
    "\n",
    "The number of parameters and number of multiply-adds\n",
    "can be modified by using the `alpha` parameter,\n",
    "which increases/decreases the number of filters in each layer.\n",
    "By altering the image size and `alpha` parameter,\n",
    "all 22 models from the paper can be built, with ImageNet weights provided.\n",
    "\n",
    "The paper demonstrates the performance of MobileNets using `alpha` values of\n",
    "1.0 (also called 100 % MobileNet), 0.35, 0.5, 0.75, 1.0, 1.3, and 1.4\n",
    "\n",
    "For each of these `alpha` values, weights for 5 different input image sizes\n",
    "are provided (224, 192, 160, 128, and 96).\n",
    "\n",
    "\n",
    "The following table describes the performance of\n",
    "MobileNet on various input sizes:\n",
    "------------------------------------------------------------------------\n",
    "MACs stands for Multiply Adds\n",
    "\n",
    " Classification Checkpoint| MACs (M) | Parameters (M)| Top 1 Accuracy| Top 5 Accuracy\n",
    "--------------------------|------------|---------------|---------|----|-------------\n",
    "| [mobilenet_v2_1.4_224]  | 582 | 6.06 |          75.0 | 92.5 |\n",
    "| [mobilenet_v2_1.3_224]  | 509 | 5.34 |          74.4 | 92.1 |\n",
    "| [mobilenet_v2_1.0_224]  | 300 | 3.47 |          71.8 | 91.0 |\n",
    "| [mobilenet_v2_1.0_192]  | 221 | 3.47 |          70.7 | 90.1 |\n",
    "| [mobilenet_v2_1.0_160]  | 154 | 3.47 |          68.8 | 89.0 |\n",
    "| [mobilenet_v2_1.0_128]  | 99  | 3.47 |          65.3 | 86.9 |\n",
    "| [mobilenet_v2_1.0_96]   | 56  | 3.47 |          60.3 | 83.2 |\n",
    "| [mobilenet_v2_0.75_224] | 209 | 2.61 |          69.8 | 89.6 |\n",
    "| [mobilenet_v2_0.75_192] | 153 | 2.61 |          68.7 | 88.9 |\n",
    "| [mobilenet_v2_0.75_160] | 107 | 2.61 |          66.4 | 87.3 |\n",
    "| [mobilenet_v2_0.75_128] | 69  | 2.61 |          63.2 | 85.3 |\n",
    "| [mobilenet_v2_0.75_96]  | 39  | 2.61 |          58.8 | 81.6 |\n",
    "| [mobilenet_v2_0.5_224]  | 97  | 1.95 |          65.4 | 86.4 |\n",
    "| [mobilenet_v2_0.5_192]  | 71  | 1.95 |          63.9 | 85.4 |\n",
    "| [mobilenet_v2_0.5_160]  | 50  | 1.95 |          61.0 | 83.2 |\n",
    "| [mobilenet_v2_0.5_128]  | 32  | 1.95 |          57.7 | 80.8 |\n",
    "| [mobilenet_v2_0.5_96]   | 18  | 1.95 |          51.2 | 75.8 |\n",
    "| [mobilenet_v2_0.35_224] | 59  | 1.66 |          60.3 | 82.9 |\n",
    "| [mobilenet_v2_0.35_192] | 43  | 1.66 |          58.2 | 81.2 |\n",
    "| [mobilenet_v2_0.35_160] | 30  | 1.66 |          55.7 | 79.1 |\n",
    "| [mobilenet_v2_0.35_128] | 20  | 1.66 |          50.8 | 75.0 |\n",
    "| [mobilenet_v2_0.35_96]  | 11  | 1.66 |          45.5 | 70.4 |\n",
    "\n",
    "The weights for all 16 models are obtained and\n",
    "translated from the Tensorflow checkpoints\n",
    "from TensorFlow checkpoints found [here]\n",
    "(https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/README.md).\n",
    "\n",
    "# Reference\n",
    "\n",
    "This file contains building code for MobileNetV2, based on\n",
    "[MobileNetV2: Inverted Residuals and Linear Bottlenecks]\n",
    "(https://arxiv.org/abs/1801.04381) (CVPR 2018)\n",
    "\n",
    "Tests comparing this model to the existing Tensorflow model can be\n",
    "found at [mobilenet_v2_keras]\n",
    "(https://github.com/JonathanCMitchell/mobilenet_v2_keras)\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "# TODO Change path to v1.1\n",
    "BASE_WEIGHT_PATH = ('https://github.com/JonathanCMitchell/mobilenet_v2_keras/'\n",
    "                    'releases/download/v1.1/')\n",
    "\n",
    "backend= keras.backend\n",
    "layers = keras.layers\n",
    "models = keras.models\n",
    "keras_utils = keras.utils\n",
    "\n",
    "\n",
    "def preprocess_input(x, **kwargs):\n",
    "    \"\"\"Preprocesses a numpy array encoding a batch of images.\n",
    "\n",
    "    # Arguments\n",
    "        x: a 4D numpy array consists of RGB values within [0, 255].\n",
    "\n",
    "    # Returns\n",
    "        Preprocessed array.\n",
    "    \"\"\"\n",
    "    return utils.preprocess_input(x, mode='tf', **kwargs)\n",
    "\n",
    "\n",
    "# This function is taken from the original tf repo.\n",
    "# It ensures that all layers have a channel number that is divisible by 8\n",
    "# It can be seen here:\n",
    "# https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py\n",
    "\n",
    "\n",
    "def _make_divisible(v, divisor, min_value=None):\n",
    "    if min_value is None:\n",
    "        min_value = divisor\n",
    "    new_v = max(min_value, int(v + divisor / 2) // divisor * divisor)\n",
    "    # Make sure that round down does not go down by more than 10%.\n",
    "    if new_v < 0.9 * v:\n",
    "        new_v += divisor\n",
    "    return new_v\n",
    "\n",
    "\n",
    "def MobileNetV2(input_shape=None,\n",
    "                alpha=1.0,\n",
    "                include_top=True,\n",
    "                weights='imagenet',\n",
    "                input_tensor=None,\n",
    "                pooling=None,\n",
    "                classes=1000,\n",
    "                lambda_mask = None,\n",
    "                **kwargs):\n",
    "    \"\"\"Instantiates the MobileNetV2 architecture.\n",
    "\n",
    "    # Arguments\n",
    "        input_shape: optional shape tuple, to be specified if you would\n",
    "            like to use a model with an input img resolution that is not\n",
    "            (224, 224, 3).\n",
    "            It should have exactly 3 inputs channels (224, 224, 3).\n",
    "            You can also omit this option if you would like\n",
    "            to infer input_shape from an input_tensor.\n",
    "            If you choose to include both input_tensor and input_shape then\n",
    "            input_shape will be used if they match, if the shapes\n",
    "            do not match then we will throw an error.\n",
    "            E.g. `(160, 160, 3)` would be one valid value.\n",
    "        alpha: controls the width of the network. This is known as the\n",
    "        width multiplier in the MobileNetV2 paper, but the name is kept for\n",
    "        consistency with MobileNetV1 in Keras.\n",
    "            - If `alpha` < 1.0, proportionally decreases the number\n",
    "                of filters in each layer.\n",
    "            - If `alpha` > 1.0, proportionally increases the number\n",
    "                of filters in each layer.\n",
    "            - If `alpha` = 1, default number of filters from the paper\n",
    "                 are used at each layer.\n",
    "        include_top: whether to include the fully-connected\n",
    "            layer at the top of the network.\n",
    "        weights: one of `None` (random initialization),\n",
    "              'imagenet' (pre-training on ImageNet),\n",
    "              or the path to the weights file to be loaded.\n",
    "        input_tensor: optional Keras tensor (i.e. output of\n",
    "            `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        pooling: Optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model\n",
    "                will be the 4D tensor output of the\n",
    "                last convolutional block.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional block, and thus\n",
    "                the output of the model will be a\n",
    "                2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "            if no `weights` argument is specified.\n",
    "\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "\n",
    "    # Raises\n",
    "        ValueError: in case of invalid argument for `weights`,\n",
    "            or invalid input shape or invalid alpha, rows when\n",
    "            weights='imagenet'\n",
    "    \"\"\"\n",
    "    global backend, layers, models, keras_utils, debug\n",
    "    debug = True\n",
    "    backend= keras.backend\n",
    "    layers = keras.layers\n",
    "    models = keras.models\n",
    "    keras_utils = keras.utils\n",
    "\n",
    "    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization), `imagenet` '\n",
    "                         '(pre-training on ImageNet), '\n",
    "                         'or the path to the weights file to be loaded.')\n",
    "\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as `\"imagenet\"` with `include_top` '\n",
    "                         'as true, `classes` should be 1000')\n",
    "\n",
    "    # Determine proper input shape and default size.\n",
    "    # If both input_shape and input_tensor are used, they should match\n",
    "    if input_shape is not None and input_tensor is not None:\n",
    "        try:\n",
    "            is_input_t_tensor = backend.is_keras_tensor(input_tensor)\n",
    "        except ValueError:\n",
    "            try:\n",
    "                is_input_t_tensor = backend.is_keras_tensor(\n",
    "                    keras_utils.get_source_inputs(input_tensor))\n",
    "            except ValueError:\n",
    "                raise ValueError('input_tensor: ', input_tensor,\n",
    "                                 'is not type input_tensor')\n",
    "        if is_input_t_tensor:\n",
    "            if backend.image_data_format == 'channels_first':\n",
    "                if backend.int_shape(input_tensor)[1] != input_shape[1]:\n",
    "                    raise ValueError('input_shape: ', input_shape,\n",
    "                                     'and input_tensor: ', input_tensor,\n",
    "                                     'do not meet the same shape requirements')\n",
    "            else:\n",
    "                if backend.int_shape(input_tensor)[2] != input_shape[1]:\n",
    "                    raise ValueError('input_shape: ', input_shape,\n",
    "                                     'and input_tensor: ', input_tensor,\n",
    "                                     'do not meet the same shape requirements')\n",
    "        else:\n",
    "            raise ValueError('input_tensor specified: ', input_tensor,\n",
    "                             'is not a keras tensor')\n",
    "\n",
    "    # If input_shape is None, infer shape from input_tensor\n",
    "    if input_shape is None and input_tensor is not None:\n",
    "\n",
    "        try:\n",
    "            backend.is_keras_tensor(input_tensor)\n",
    "        except ValueError:\n",
    "            raise ValueError('input_tensor: ', input_tensor,\n",
    "                             'is type: ', type(input_tensor),\n",
    "                             'which is not a valid type')\n",
    "\n",
    "        if input_shape is None and not backend.is_keras_tensor(input_tensor):\n",
    "            default_size = 224\n",
    "        elif input_shape is None and backend.is_keras_tensor(input_tensor):\n",
    "            if backend.image_data_format() == 'channels_first':\n",
    "                rows = backend.int_shape(input_tensor)[2]\n",
    "                cols = backend.int_shape(input_tensor)[3]\n",
    "            else:\n",
    "                rows = backend.int_shape(input_tensor)[1]\n",
    "                cols = backend.int_shape(input_tensor)[2]\n",
    "\n",
    "            if rows == cols and rows in [96, 128, 160, 192, 224]:\n",
    "                default_size = rows\n",
    "            else:\n",
    "                default_size = 224\n",
    "\n",
    "    # If input_shape is None and no input_tensor\n",
    "    elif input_shape is None:\n",
    "        default_size = 224\n",
    "\n",
    "    # If input_shape is not None, assume default size\n",
    "    else:\n",
    "        if backend.image_data_format() == 'channels_first':\n",
    "            rows = input_shape[1]\n",
    "            cols = input_shape[2]\n",
    "        else:\n",
    "            rows = input_shape[0]\n",
    "            cols = input_shape[1]\n",
    "\n",
    "        if rows == cols and rows in [96, 128, 160, 192, 224]:\n",
    "            default_size = rows\n",
    "        else:\n",
    "            default_size = 224\n",
    "\n",
    "    input_shape = utils._obtain_input_shape(input_shape,\n",
    "                                      default_size=default_size,\n",
    "                                      min_size=32,\n",
    "                                      data_format=backend.image_data_format(),\n",
    "                                      require_flatten=include_top,\n",
    "                                      weights=weights)\n",
    "\n",
    "    if backend.image_data_format() == 'channels_last':\n",
    "        row_axis, col_axis = (0, 1)\n",
    "    else:\n",
    "        row_axis, col_axis = (1, 2)\n",
    "    rows = input_shape[row_axis]\n",
    "    cols = input_shape[col_axis]\n",
    "\n",
    "    if weights == 'imagenet':\n",
    "        if alpha not in [0.35, 0.50, 0.75, 1.0, 1.3, 1.4]:\n",
    "            raise ValueError('If imagenet weights are being loaded, '\n",
    "                             'alpha can be one of `0.35`, `0.50`, `0.75`, '\n",
    "                             '`1.0`, `1.3` or `1.4` only.')\n",
    "\n",
    "        if rows != cols or rows not in [96, 128, 160, 192, 224]:\n",
    "            rows = 224\n",
    "            warnings.warn('`input_shape` is undefined or non-square, '\n",
    "                          'or `rows` is not in [96, 128, 160, 192, 224].'\n",
    "                          ' Weights for input shape (224, 224) will be'\n",
    "                          ' loaded as the default.')\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = layers.Input(shape=input_shape)\n",
    "    else:\n",
    "        if not backend.is_keras_tensor(input_tensor):\n",
    "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    channel_axis = 1 if backend.image_data_format() == 'channels_first' else -1\n",
    "\n",
    "    first_block_filters = _make_divisible(32 * alpha, 8)\n",
    "    x = layers.ZeroPadding2D(padding=correct_pad(backend, img_input, 3),\n",
    "                             name='Conv1_pad')(img_input)\n",
    "    x = layers.Conv2D(first_block_filters,\n",
    "                      kernel_size=3,\n",
    "                      strides=(2, 2),\n",
    "                      padding='valid',\n",
    "                      use_bias=False,\n",
    "                      name='Conv1')(x)\n",
    "    global start_index, end_index\n",
    "    start_index = end_index = 0\n",
    "    #################\n",
    "    if lambda_mask is not None:\n",
    "        start_index = end_index\n",
    "        end_index = start_index + (default_size//2 * default_size//2 * first_block_filters)\n",
    "        x_mask  = np.reshape(lambda_mask[start_index:end_index], (default_size//2, default_size//2, first_block_filters))\n",
    "        if debug:\n",
    "            print('Conv_1',start_index,end_index)\n",
    "    else:\n",
    "        x_mask = np.ones(shape=((default_size//2, default_size//2, first_block_filters)))\n",
    "\n",
    "    x_mask  = backend.variable(x_mask)\n",
    "    x = Lambda(lambda z: z * x_mask)(x)\n",
    "    ####################\n",
    "    x = layers.BatchNormalization(axis=channel_axis,\n",
    "                                  epsilon=1e-3,\n",
    "                                  momentum=0.999,\n",
    "                                  name='bn_Conv1')(x)\n",
    "    #################\n",
    "    if lambda_mask is not None:\n",
    "        start_index = end_index\n",
    "        end_index = start_index + (default_size//2 * default_size//2 * first_block_filters)\n",
    "        x_mask  = np.reshape(lambda_mask[start_index:end_index], (default_size//2, default_size//2, first_block_filters))\n",
    "        if debug:\n",
    "            print('Conv_1_BN',start_index,end_index)\n",
    "    else:\n",
    "        x_mask = np.ones(shape=((default_size//2, default_size//2, first_block_filters)))\n",
    "\n",
    "    x_mask  = backend.variable(x_mask)\n",
    "    x = Lambda(lambda z: z * x_mask)(x)\n",
    "    ####################\n",
    "    x = layers.ReLU(6., name='Conv1_relu')(x)\n",
    "\n",
    "    x = _inverted_res_block(x, filters=16, alpha=alpha, stride=1,\n",
    "                            expansion=1, block_id=0, lambda_mask=lambda_mask)\n",
    "\n",
    "    x = _inverted_res_block(x, filters=24, alpha=alpha, stride=2,\n",
    "                            expansion=6, block_id=1, lambda_mask=lambda_mask)\n",
    "    x = _inverted_res_block(x, filters=24, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=2, lambda_mask=lambda_mask)\n",
    "\n",
    "    x = _inverted_res_block(x, filters=32, alpha=alpha, stride=2,\n",
    "                            expansion=6, block_id=3, lambda_mask=lambda_mask)\n",
    "    x = _inverted_res_block(x, filters=32, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=4, lambda_mask=lambda_mask)\n",
    "    x = _inverted_res_block(x, filters=32, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=5, lambda_mask=lambda_mask)\n",
    "\n",
    "    x = _inverted_res_block(x, filters=64, alpha=alpha, stride=2,\n",
    "                            expansion=6, block_id=6, lambda_mask=lambda_mask)\n",
    "    x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=7, lambda_mask=lambda_mask)\n",
    "    x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=8, lambda_mask=lambda_mask)\n",
    "    x = _inverted_res_block(x, filters=64, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=9, lambda_mask=lambda_mask)\n",
    "\n",
    "    x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=10, lambda_mask=lambda_mask)\n",
    "    x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=11, lambda_mask=lambda_mask)\n",
    "    x = _inverted_res_block(x, filters=96, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=12, lambda_mask=lambda_mask)\n",
    "\n",
    "    x = _inverted_res_block(x, filters=160, alpha=alpha, stride=2,\n",
    "                            expansion=6, block_id=13, lambda_mask=lambda_mask)\n",
    "    x = _inverted_res_block(x, filters=160, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=14, lambda_mask=lambda_mask)\n",
    "    x = _inverted_res_block(x, filters=160, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=15, lambda_mask=lambda_mask)\n",
    "\n",
    "    x = _inverted_res_block(x, filters=320, alpha=alpha, stride=1,\n",
    "                            expansion=6, block_id=16, lambda_mask=lambda_mask)\n",
    "\n",
    "    # no alpha applied to last conv as stated in the paper:\n",
    "    # if the width multiplier is greater than 1 we\n",
    "    # increase the number of output channels\n",
    "    if alpha > 1.0:\n",
    "        last_block_filters = _make_divisible(1280 * alpha, 8)\n",
    "    else:\n",
    "        last_block_filters = 1280\n",
    "\n",
    "    x = layers.Conv2D(last_block_filters,\n",
    "                      kernel_size=1,\n",
    "                      use_bias=False,\n",
    "                      name='Conv_1')(x)\n",
    "    #################\n",
    "    if lambda_mask is not None:\n",
    "        start_index = end_index\n",
    "        end_index = start_index + (x.shape[1] * x.shape[2]* last_block_filters)\n",
    "        x_mask  = np.reshape(lambda_mask[start_index:end_index], (x.shape[1], x.shape[2], last_block_filters))\n",
    "        if debug:\n",
    "            print('Conv_1',start_index,end_index)\n",
    "    else:\n",
    "        x_mask = np.ones(shape=((x.shape[1], x.shape[2], last_block_filters)))\n",
    "\n",
    "    x_mask  = backend.variable(x_mask)\n",
    "    x = Lambda(lambda z: z * x_mask)(x)\n",
    "    ####################\n",
    "    x = layers.BatchNormalization(axis=channel_axis,\n",
    "                                  epsilon=1e-3,\n",
    "                                  momentum=0.999,\n",
    "                                  name='Conv_1_bn')(x)\n",
    "    #################\n",
    "    if lambda_mask is not None:\n",
    "        start_index = end_index\n",
    "        end_index = start_index + (x.shape[1] * x.shape[2] * last_block_filters)\n",
    "        x_mask  = np.reshape(lambda_mask[start_index:end_index], (x.shape[1], x.shape[2], last_block_filters))\n",
    "        if debug:\n",
    "            print('Conv_1_bn',start_index,end_index)\n",
    "    else:\n",
    "        x_mask = np.ones(shape=((x.shape[1],x.shape[2], last_block_filters)))\n",
    "\n",
    "    x_mask  = backend.variable(x_mask)\n",
    "    x = Lambda(lambda z: z * x_mask)(x)\n",
    "    ####################\n",
    "    x = layers.ReLU(6., name='out_relu')(x)\n",
    "\n",
    "    if include_top:\n",
    "        x = layers.GlobalAveragePooling2D()(x)\n",
    "        x = layers.Dense(classes, activation='softmax', use_bias=True, name='Logits')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = layers.GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = keras_utils.get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "\n",
    "    # Create model.\n",
    "    model = models.Model(inputs, x, name='mobilenetv2_%0.2f_%s' % (alpha, rows))\n",
    "\n",
    "    # Load weights.\n",
    "    if weights == 'imagenet':\n",
    "        if include_top:\n",
    "            model_name = ('mobilenet_v2_weights_tf_dim_ordering_tf_kernels_' + str(alpha) + '_' + str(rows) + '.h5')\n",
    "            weight_path = BASE_WEIGHT_PATH + model_name\n",
    "            weights_path = keras_utils.get_file(model_name, weight_path, cache_subdir='models')\n",
    "        else:\n",
    "            model_name = ('mobilenet_v2_weights_tf_dim_ordering_tf_kernels_' + str(alpha) + '_' + str(rows) + '_no_top' + '.h5')\n",
    "            weight_path = BASE_WEIGHT_PATH + model_name\n",
    "            weights_path = keras_utils.get_file(model_name, weight_path, cache_subdir='models')\n",
    "        model.load_weights(weights_path)\n",
    "    elif weights is not None:\n",
    "        model.load_weights(weights)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def _inverted_res_block(inputs, expansion, stride, alpha, filters, block_id, lambda_mask = None):\n",
    "    global debug\n",
    "    channel_axis = 1 if backend.image_data_format() == 'channels_first' else -1\n",
    "    in_channels = backend.int_shape(inputs)[channel_axis]\n",
    "    pointwise_conv_filters = int(filters * alpha)\n",
    "    pointwise_filters = _make_divisible(pointwise_conv_filters, 8)\n",
    "    x = inputs\n",
    "    prefix = 'block_{}_'.format(block_id)\n",
    "    #print(prefix, inputs.shape,inputs.shape[0],inputs.shape[1] , in_channels, pointwise_conv_filters, pointwise_filters, filters)\n",
    "    global start_index, end_index\n",
    "    if block_id:\n",
    "        # Expand\n",
    "        x = layers.Conv2D(expansion * in_channels,\n",
    "                          kernel_size=1,\n",
    "                          padding='same',\n",
    "                          use_bias=False,\n",
    "                          activation=None,\n",
    "                          name=prefix + 'expand')(x)\n",
    "        #################\n",
    "        if lambda_mask is not None:\n",
    "            start_index = end_index\n",
    "            end_index = start_index + (inputs.shape[1] * inputs.shape[2] * inputs.shape[3]*expansion)\n",
    "            x_mask  = np.reshape(lambda_mask[start_index:end_index], (inputs.shape[1], inputs.shape[2], inputs.shape[3]*expansion))\n",
    "            if debug:\n",
    "                print(prefix + 'expand',start_index,end_index)\n",
    "        else:\n",
    "            x_mask = np.ones(shape=((inputs.shape[1], inputs.shape[2], inputs.shape[3]*expansion)))\n",
    "\n",
    "        x_mask  = backend.variable(x_mask)\n",
    "        x = Lambda(lambda z: z * x_mask)(x)\n",
    "        ####################\n",
    "        x = layers.BatchNormalization(axis=channel_axis,\n",
    "                                      epsilon=1e-3,\n",
    "                                      momentum=0.999,\n",
    "                                      name=prefix + 'expand_BN')(x)\n",
    "  \n",
    "        #################\n",
    "        if lambda_mask is not None:\n",
    "            start_index = end_index\n",
    "            end_index = start_index + (inputs.shape[1] * inputs.shape[2] * inputs.shape[3]*expansion)\n",
    "            x_mask  = np.reshape(lambda_mask[start_index:end_index], (inputs.shape[1], inputs.shape[2], inputs.shape[3]*expansion))\n",
    "            if debug:\n",
    "                print(prefix + 'expand_BN',start_index,end_index)\n",
    "        else:\n",
    "            x_mask = np.ones(shape=((inputs.shape[1], inputs.shape[2], inputs.shape[3]*expansion)))\n",
    "\n",
    "        x_mask  = backend.variable(x_mask)\n",
    "        x = Lambda(lambda z: z * x_mask)(x)\n",
    "        ####################\n",
    "        x = layers.ReLU(6., name=prefix + 'expand_relu')(x)\n",
    "    else:\n",
    "        prefix = 'expanded_conv_'\n",
    "\n",
    "    # Depthwise\n",
    "    if stride == 2:\n",
    "        x = layers.ZeroPadding2D(padding=correct_pad(backend, x, 3), name=prefix + 'pad')(x)\n",
    "    x = layers.DepthwiseConv2D(kernel_size=3, strides=stride, activation=None, use_bias=False,padding='same' if stride == 1 else 'valid', name=prefix + 'depthwise')(x)\n",
    "    #################\n",
    "    if lambda_mask is not None:\n",
    "        start_index = end_index\n",
    "        end_index = start_index + (inputs.shape[1]//stride * inputs.shape[2]//stride * inputs.shape[3]*expansion)\n",
    "        x_mask  = np.reshape(lambda_mask[start_index:end_index], (inputs.shape[1]//stride, inputs.shape[2]//stride, inputs.shape[3]*expansion))\n",
    "        if debug:\n",
    "            print(prefix + 'depthwise',start_index,end_index)\n",
    "    else:\n",
    "        x_mask = np.ones(shape=((inputs.shape[1]//stride, inputs.shape[2]//stride, inputs.shape[3]*expansion)))\n",
    "\n",
    "    x_mask  = backend.variable(x_mask)\n",
    "    x = Lambda(lambda z: z * x_mask)(x)\n",
    "    ####################\n",
    "    x = layers.BatchNormalization(axis=channel_axis,epsilon=1e-3,momentum=0.999, name=prefix + 'depthwise_BN')(x)\n",
    "    #################\n",
    "    if lambda_mask is not None:\n",
    "        start_index = end_index\n",
    "        end_index = start_index + (inputs.shape[1]//stride * inputs.shape[2]//stride * inputs.shape[3]*expansion)\n",
    "        x_mask  = np.reshape(lambda_mask[start_index:end_index], (inputs.shape[1]//stride, inputs.shape[2]//stride, inputs.shape[3]*expansion))\n",
    "        if debug:\n",
    "            print(prefix + 'depthwise_BN',start_index,end_index)\n",
    "    else:\n",
    "        x_mask = np.ones(shape=((inputs.shape[1]//stride, inputs.shape[2]//stride, inputs.shape[3]*expansion)))\n",
    "\n",
    "    x_mask  = backend.variable(x_mask)\n",
    "    x = Lambda(lambda z: z * x_mask)(x)\n",
    "    ####################\n",
    "\n",
    "    x = layers.ReLU(6., name=prefix + 'depthwise_relu')(x)\n",
    "\n",
    "    # Project\n",
    "    x = layers.Conv2D(pointwise_filters, kernel_size=1, padding='same', use_bias=False, activation=None, name=prefix + 'project')(x)\n",
    "    #################\n",
    "    if lambda_mask is not None:\n",
    "        start_index = end_index\n",
    "        end_index = start_index + (inputs.shape[1]//stride * inputs.shape[2]//stride * pointwise_filters)\n",
    "        x_mask  = np.reshape(lambda_mask[start_index:end_index], (inputs.shape[1]//stride, inputs.shape[2]//stride, pointwise_filters))\n",
    "        if debug:\n",
    "            print(prefix + 'project',start_index,end_index)\n",
    "    else:\n",
    "        x_mask = np.ones(shape=((inputs.shape[1]//stride, inputs.shape[2]//stride, pointwise_filters)))\n",
    "\n",
    "    x_mask  = backend.variable(x_mask)\n",
    "    x = Lambda(lambda z: z * x_mask)(x)\n",
    "    ####################\n",
    "    x = layers.BatchNormalization(axis=channel_axis, epsilon=1e-3, momentum=0.999, name=prefix + 'project_BN')(x)\n",
    "    #################\n",
    "    if lambda_mask is not None:\n",
    "        start_index = end_index\n",
    "        end_index = start_index + (inputs.shape[1]//stride * inputs.shape[2]//stride * pointwise_filters)\n",
    "        x_mask  = np.reshape(lambda_mask[start_index:end_index], (inputs.shape[1]//stride, inputs.shape[2]//stride, pointwise_filters))\n",
    "        if debug:\n",
    "            print(prefix + 'project_BN',start_index,end_index)\n",
    "    else:\n",
    "        x_mask = np.ones(shape=((inputs.shape[1]//stride, inputs.shape[2]//stride, pointwise_filters)))\n",
    "\n",
    "    x_mask  = backend.variable(x_mask)\n",
    "    x = Lambda(lambda z: z * x_mask)(x)\n",
    "    ####################\n",
    "\n",
    "    if in_channels == pointwise_filters and stride == 1:\n",
    "        return layers.Add(name=prefix + 'add')([inputs, x])\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to pre-process the input image to ensure uniform size and color\n",
    "def preprocess_image_batch(image_paths, img_size=None, crop_size=None, color_mode='rgb', out=None):\n",
    "    \"\"\"\n",
    "    Consistent preprocessing of images batches\n",
    "    :param image_paths: iterable: images to process\n",
    "    :param crop_size: tuple: crop images if specified\n",
    "    :param img_size: tuple: resize images if specified\n",
    "    :param color_mode: Use rgb or change to bgr mode based on type of model you want to use\n",
    "    :param out: append output to this iterable if specified\n",
    "    \"\"\"\n",
    "    img_list = []\n",
    "\n",
    "    for im_path in image_paths:\n",
    "        '''\n",
    "        img = imread(im_path,as_gray=False, pilmode=\"RGB\")\n",
    "        #print im_path\n",
    "        #print img.shape\n",
    "        if img_size:\n",
    "            img = resize(img, img_size)\n",
    "\n",
    "        img = img.astype('float32')\n",
    "        # We normalize the colors (in RGB space) with the empirical means on the training set\n",
    "        img[:, :, 0] -= 123.68\n",
    "        img[:, :, 1] -= 116.779\n",
    "        img[:, :, 2] -= 103.939\n",
    "        # We permute the colors to get them in the BGR order\n",
    "        if color_mode == 'bgr':\n",
    "            img[:, :, [0, 1, 2]] = img[:, :, [2, 1, 0]]\n",
    "        img = img.transpose((2, 0, 1))\n",
    "\n",
    "        if crop_size:\n",
    "            img = img[:, (img_size[0] - crop_size[0]) // 2:(img_size[0] + crop_size[0]) // 2\n",
    "            , (img_size[1] - crop_size[1]) // 2:(img_size[1] + crop_size[1]) // 2]\n",
    "\n",
    "        img_list.append(img)\n",
    "        '''\n",
    "        size = 224\n",
    "        ret = PIL.Image.open(im_path)\n",
    "        ret = ret.resize((size, size))\n",
    "        ret = np.asarray(ret, dtype=np.uint8).astype(np.float32)\n",
    "        if ret.ndim == 2:\n",
    "            ret.resize((size, size, 1))\n",
    "            ret = np.repeat(ret, 3, axis=-1)\n",
    "        #ret = ret.transpose((2, 0, 1))\n",
    "        #ret = np.flip(ret,0)\n",
    "        global backend\n",
    "        x = preprocess_input(ret, \n",
    "            data_format=backend.image_data_format())\n",
    "        img_list.append(x)\n",
    "\n",
    "\n",
    "    try:\n",
    "        img_batch = np.stack(img_list, axis=0)\n",
    "    except:\n",
    "        print(im_path)\n",
    "        raise ValueError('when img_size and crop_size are None, images'\n",
    "                ' in image_paths must have the same shapes.')\n",
    "\n",
    "    if out is not None and hasattr(out, 'append'):\n",
    "        out.append(img_batch)\n",
    "    else:\n",
    "        return img_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to predict the top 5 accuracy\n",
    "def top5accuracy(true, predicted):\n",
    "    assert len(true) == len(predicted)\n",
    "    result = []\n",
    "    flag  = 0\n",
    "    for i in range(len(true)):\n",
    "        flag  = 0\n",
    "        temp = true[i]\n",
    "        for j in predicted[i][0:5]:\n",
    "            if j == temp:\n",
    "                flag = 1\n",
    "                break\n",
    "        if flag == 1:\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(0)\n",
    "    counter = 0.\n",
    "    for i in result:\n",
    "        if i == 1:\n",
    "            counter += 1.\n",
    "    error = 1.0 - counter/float(len(result))\n",
    "    #print len(np.where(np.asarray(result) == 1)[0])\n",
    "    return len(np.where(np.asarray(result) == 1)[0]), error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the details of all the 1000 classes and the function to conver the synset id to words{\n",
    "meta_clsloc_file = '../../data/meta_clsloc.mat'\n",
    "synsets = loadmat(meta_clsloc_file)['synsets'][0]\n",
    "synsets_imagenet_sorted = sorted([(int(s[0]), str(s[1][0])) for s in synsets[:1000]],key=lambda v: v[1])\n",
    "corr = {}\n",
    "for j in range(1000):\n",
    "    corr[synsets_imagenet_sorted[j][0]] = j\n",
    "\n",
    "corr_inv = {}\n",
    "for j in range(1, 1001):\n",
    "    corr_inv[corr[j]] = j\n",
    "\n",
    "def id_to_words(id_):\n",
    "    return synsets[corr_inv[id_] - 1][2][0]\n",
    "\n",
    "def pprint_output(out, n_max_synsets=10):\n",
    "    wids = []\n",
    "    best_ids = out.argsort()[::-1][:10]\n",
    "    for u in best_ids:\n",
    "        wids.append(str(synsets[corr_inv[u] - 1][1][0]))\n",
    "    #print('%.2f' % round(100 * out[u], 2) + ' : ' + id_to_words(u)+' '+ str(synsets[corr_inv[u] - 1][1][0]))\n",
    "    return wids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code snippet to load the ground truth labels to measure the performance{\n",
    "truth = {}\n",
    "with open('../../data/ILSVRC2014_clsloc_validation_ground_truth.txt') as f:\n",
    "    line_num = 1\n",
    "    for line in f.readlines():\n",
    "        ind_ = int(line)\n",
    "        temp  = None\n",
    "        for i in synsets_imagenet_sorted:\n",
    "            if i[0] == ind_:\n",
    "                temp = i\n",
    "        #print ind_,temp\n",
    "        if temp != None:\n",
    "            truth[line_num] = temp\n",
    "        else:\n",
    "            print('##########', ind_)\n",
    "            pass\n",
    "        line_num += 1\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inanimate\n"
     ]
    }
   ],
   "source": [
    "# Loading the folder to be procesed from command line{\n",
    "p = 'inanimate'\n",
    "tmp = p.replace('/','_')\n",
    "print(tmp)\n",
    "\n",
    "\n",
    "p_num = 1\n",
    "url_path = '../../data/'+p+'/'\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194\n"
     ]
    }
   ],
   "source": [
    "# Prepare the image list and pre-process them{\n",
    "true_wids = []\n",
    "im_list = []\n",
    "for i in os.listdir(url_path):\n",
    "    if not i.startswith('~') and not i.startswith('.'):\n",
    "        #print i, truth\n",
    "        temp = i.split('.')[0].split('_')[2]\n",
    "        true_wids.append(truth[int(temp)][1])\n",
    "        im_list.append(url_path+i)\n",
    "print(len(im_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = preprocess_image_batch(im_list,img_size=(256,256), crop_size=(224,224), color_mode=\"rgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv_1 0 200704\n",
      "Conv_1_BN 200704 401408\n",
      "expanded_conv_depthwise 401408 602112\n",
      "expanded_conv_depthwise_BN 602112 802816\n",
      "expanded_conv_project 802816 903168\n",
      "expanded_conv_project_BN 903168 1003520\n",
      "block_1_expand 1003520 1605632\n",
      "block_1_expand_BN 1605632 2207744\n",
      "block_1_depthwise 2207744 2358272\n",
      "block_1_depthwise_BN 2358272 2508800\n",
      "block_1_project 2508800 2533888\n",
      "block_1_project_BN 2533888 2558976\n",
      "block_2_expand 2558976 2709504\n",
      "block_2_expand_BN 2709504 2860032\n",
      "block_2_depthwise 2860032 3010560\n",
      "block_2_depthwise_BN 3010560 3161088\n",
      "block_2_project 3161088 3186176\n",
      "block_2_project_BN 3186176 3211264\n",
      "block_3_expand 3211264 3361792\n",
      "block_3_expand_BN 3361792 3512320\n",
      "block_3_depthwise 3512320 3549952\n",
      "block_3_depthwise_BN 3549952 3587584\n",
      "block_3_project 3587584 3600128\n",
      "block_3_project_BN 3600128 3612672\n",
      "block_4_expand 3612672 3687936\n",
      "block_4_expand_BN 3687936 3763200\n",
      "block_4_depthwise 3763200 3838464\n",
      "block_4_depthwise_BN 3838464 3913728\n",
      "block_4_project 3913728 3926272\n",
      "block_4_project_BN 3926272 3938816\n",
      "block_5_expand 3938816 4014080\n",
      "block_5_expand_BN 4014080 4089344\n",
      "block_5_depthwise 4089344 4164608\n",
      "block_5_depthwise_BN 4164608 4239872\n",
      "block_5_project 4239872 4252416\n",
      "block_5_project_BN 4252416 4264960\n",
      "block_6_expand 4264960 4340224\n",
      "block_6_expand_BN 4340224 4415488\n",
      "block_6_depthwise 4415488 4434304\n",
      "block_6_depthwise_BN 4434304 4453120\n",
      "block_6_project 4453120 4457824\n",
      "block_6_project_BN 4457824 4462528\n",
      "block_7_expand 4462528 4490752\n",
      "block_7_expand_BN 4490752 4518976\n",
      "block_7_depthwise 4518976 4547200\n",
      "block_7_depthwise_BN 4547200 4575424\n",
      "block_7_project 4575424 4580128\n",
      "block_7_project_BN 4580128 4584832\n",
      "block_8_expand 4584832 4613056\n",
      "block_8_expand_BN 4613056 4641280\n",
      "block_8_depthwise 4641280 4669504\n",
      "block_8_depthwise_BN 4669504 4697728\n",
      "block_8_project 4697728 4702432\n",
      "block_8_project_BN 4702432 4707136\n",
      "block_9_expand 4707136 4735360\n",
      "block_9_expand_BN 4735360 4763584\n",
      "block_9_depthwise 4763584 4791808\n",
      "block_9_depthwise_BN 4791808 4820032\n",
      "block_9_project 4820032 4824736\n",
      "block_9_project_BN 4824736 4829440\n",
      "block_10_expand 4829440 4857664\n",
      "block_10_expand_BN 4857664 4885888\n",
      "block_10_depthwise 4885888 4914112\n",
      "block_10_depthwise_BN 4914112 4942336\n",
      "block_10_project 4942336 4948608\n",
      "block_10_project_BN 4948608 4954880\n",
      "block_11_expand 4954880 4992512\n",
      "block_11_expand_BN 4992512 5030144\n",
      "block_11_depthwise 5030144 5067776\n",
      "block_11_depthwise_BN 5067776 5105408\n",
      "block_11_project 5105408 5111680\n",
      "block_11_project_BN 5111680 5117952\n",
      "block_12_expand 5117952 5155584\n",
      "block_12_expand_BN 5155584 5193216\n",
      "block_12_depthwise 5193216 5230848\n",
      "block_12_depthwise_BN 5230848 5268480\n",
      "block_12_project 5268480 5274752\n",
      "block_12_project_BN 5274752 5281024\n",
      "block_13_expand 5281024 5318656\n",
      "block_13_expand_BN 5318656 5356288\n",
      "block_13_depthwise 5356288 5365696\n",
      "block_13_depthwise_BN 5365696 5375104\n",
      "block_13_project 5375104 5377848\n",
      "block_13_project_BN 5377848 5380592\n",
      "block_14_expand 5380592 5397056\n",
      "block_14_expand_BN 5397056 5413520\n",
      "block_14_depthwise 5413520 5429984\n",
      "block_14_depthwise_BN 5429984 5446448\n",
      "block_14_project 5446448 5449192\n",
      "block_14_project_BN 5449192 5451936\n",
      "block_15_expand 5451936 5468400\n",
      "block_15_expand_BN 5468400 5484864\n",
      "block_15_depthwise 5484864 5501328\n",
      "block_15_depthwise_BN 5501328 5517792\n",
      "block_15_project 5517792 5520536\n",
      "block_15_project_BN 5520536 5523280\n",
      "block_16_expand 5523280 5539744\n",
      "block_16_expand_BN 5539744 5556208\n",
      "block_16_depthwise 5556208 5572672\n",
      "block_16_depthwise_BN 5572672 5589136\n",
      "block_16_project 5589136 5594624\n",
      "block_16_project_BN 5594624 5600112\n",
      "Conv_1 5600112 5662832\n",
      "Conv_1_bn 5662832 5725552\n"
     ]
    }
   ],
   "source": [
    "# Model parmeters and running the model from the loaded weights{\n",
    "\n",
    "\n",
    "#vals = random.standard_normal(5725552)\n",
    "vals = np.ones(())\n",
    "model_name = 'MobileNetV2'\n",
    "model = MobileNetV2( input_shape=None,\n",
    "    alpha=0.35,\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    pooling=None,\n",
    "    lambda_mask = np.ones(5725552),\n",
    "    classes=1000,\n",
    "    classifier_activation=\"softmax\")\n",
    "#KFold\n",
    "k = 4\n",
    "\n",
    "im_train, im_test = train_test_split(im_list, test_size=0.2, random_state=234)\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_pad (ZeroPadding2D)       (None, 225, 225, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, 112, 112, 16) 432         Conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 112, 112, 16) 0           Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalization)   (None, 112, 112, 16) 64          lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 112, 112, 16) 0           bn_Conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)               (None, 112, 112, 16) 0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (Depthw (None, 112, 112, 16) 144         Conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 112, 112, 16) 0           expanded_conv_depthwise[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (Bat (None, 112, 112, 16) 64          lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 112, 112, 16) 0           expanded_conv_depthwise_BN[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (R (None, 112, 112, 16) 0           lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)  (None, 112, 112, 8)  128         expanded_conv_depthwise_relu[0][0\n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 112, 112, 8)  0           expanded_conv_project[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (Batch (None, 112, 112, 8)  32          lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 112, 112, 8)  0           expanded_conv_project_BN[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)         (None, 112, 112, 48) 384         lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 112, 112, 48) 0           block_1_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormali (None, 112, 112, 48) 192         lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 112, 112, 48) 0           block_1_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)      (None, 112, 112, 48) 0           lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_pad (ZeroPadding2D)     (None, 113, 113, 48) 0           block_1_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseCon (None, 56, 56, 48)   432         block_1_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 56, 56, 48)   0           block_1_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNorm (None, 56, 56, 48)   192         lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 56, 56, 48)   0           block_1_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)   (None, 56, 56, 48)   0           lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)        (None, 56, 56, 8)    384         block_1_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 56, 56, 8)    0           block_1_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project_BN (BatchNormal (None, 56, 56, 8)    32          lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 56, 56, 8)    0           block_1_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)         (None, 56, 56, 48)   384         lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 56, 56, 48)   0           block_2_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_BN (BatchNormali (None, 56, 56, 48)   192         lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 56, 56, 48)   0           block_2_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)      (None, 56, 56, 48)   0           lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise (DepthwiseCon (None, 56, 56, 48)   432         block_2_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 56, 56, 48)   0           block_2_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_BN (BatchNorm (None, 56, 56, 48)   192         lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 56, 56, 48)   0           block_2_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_relu (ReLU)   (None, 56, 56, 48)   0           lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project (Conv2D)        (None, 56, 56, 8)    384         block_2_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 56, 56, 8)    0           block_2_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project_BN (BatchNormal (None, 56, 56, 8)    32          lambda_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 56, 56, 8)    0           block_2_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_2_add (Add)               (None, 56, 56, 8)    0           lambda_12[0][0]                  \n",
      "                                                                 lambda_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand (Conv2D)         (None, 56, 56, 48)   384         block_2_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 56, 56, 48)   0           block_3_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_BN (BatchNormali (None, 56, 56, 48)   192         lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 56, 56, 48)   0           block_3_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_relu (ReLU)      (None, 56, 56, 48)   0           lambda_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_3_pad (ZeroPadding2D)     (None, 57, 57, 48)   0           block_3_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise (DepthwiseCon (None, 28, 28, 48)   432         block_3_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 28, 28, 48)   0           block_3_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_BN (BatchNorm (None, 28, 28, 48)   192         lambda_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 28, 28, 48)   0           block_3_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_relu (ReLU)   (None, 28, 28, 48)   0           lambda_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project (Conv2D)        (None, 28, 28, 16)   768         block_3_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 28, 28, 16)   0           block_3_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project_BN (BatchNormal (None, 28, 28, 16)   64          lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 28, 28, 16)   0           block_3_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand (Conv2D)         (None, 28, 28, 96)   1536        lambda_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 28, 28, 96)   0           block_4_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_BN (BatchNormali (None, 28, 28, 96)   384         lambda_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 28, 28, 96)   0           block_4_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_relu (ReLU)      (None, 28, 28, 96)   0           lambda_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise (DepthwiseCon (None, 28, 28, 96)   864         block_4_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)              (None, 28, 28, 96)   0           block_4_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_BN (BatchNorm (None, 28, 28, 96)   384         lambda_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)              (None, 28, 28, 96)   0           block_4_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_relu (ReLU)   (None, 28, 28, 96)   0           lambda_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project (Conv2D)        (None, 28, 28, 16)   1536        block_4_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_29 (Lambda)              (None, 28, 28, 16)   0           block_4_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project_BN (BatchNormal (None, 28, 28, 16)   64          lambda_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_30 (Lambda)              (None, 28, 28, 16)   0           block_4_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4_add (Add)               (None, 28, 28, 16)   0           lambda_24[0][0]                  \n",
      "                                                                 lambda_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand (Conv2D)         (None, 28, 28, 96)   1536        block_4_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_31 (Lambda)              (None, 28, 28, 96)   0           block_5_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_BN (BatchNormali (None, 28, 28, 96)   384         lambda_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_32 (Lambda)              (None, 28, 28, 96)   0           block_5_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_relu (ReLU)      (None, 28, 28, 96)   0           lambda_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise (DepthwiseCon (None, 28, 28, 96)   864         block_5_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_33 (Lambda)              (None, 28, 28, 96)   0           block_5_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_BN (BatchNorm (None, 28, 28, 96)   384         lambda_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_34 (Lambda)              (None, 28, 28, 96)   0           block_5_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_relu (ReLU)   (None, 28, 28, 96)   0           lambda_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project (Conv2D)        (None, 28, 28, 16)   1536        block_5_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_35 (Lambda)              (None, 28, 28, 16)   0           block_5_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project_BN (BatchNormal (None, 28, 28, 16)   64          lambda_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_36 (Lambda)              (None, 28, 28, 16)   0           block_5_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_5_add (Add)               (None, 28, 28, 16)   0           block_4_add[0][0]                \n",
      "                                                                 lambda_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand (Conv2D)         (None, 28, 28, 96)   1536        block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_37 (Lambda)              (None, 28, 28, 96)   0           block_6_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_BN (BatchNormali (None, 28, 28, 96)   384         lambda_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_38 (Lambda)              (None, 28, 28, 96)   0           block_6_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_relu (ReLU)      (None, 28, 28, 96)   0           lambda_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_6_pad (ZeroPadding2D)     (None, 29, 29, 96)   0           block_6_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise (DepthwiseCon (None, 14, 14, 96)   864         block_6_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_39 (Lambda)              (None, 14, 14, 96)   0           block_6_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_BN (BatchNorm (None, 14, 14, 96)   384         lambda_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_40 (Lambda)              (None, 14, 14, 96)   0           block_6_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_relu (ReLU)   (None, 14, 14, 96)   0           lambda_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project (Conv2D)        (None, 14, 14, 24)   2304        block_6_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_41 (Lambda)              (None, 14, 14, 24)   0           block_6_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project_BN (BatchNormal (None, 14, 14, 24)   96          lambda_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_42 (Lambda)              (None, 14, 14, 24)   0           block_6_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand (Conv2D)         (None, 14, 14, 144)  3456        lambda_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_43 (Lambda)              (None, 14, 14, 144)  0           block_7_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_BN (BatchNormali (None, 14, 14, 144)  576         lambda_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_44 (Lambda)              (None, 14, 14, 144)  0           block_7_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_relu (ReLU)      (None, 14, 14, 144)  0           lambda_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise (DepthwiseCon (None, 14, 14, 144)  1296        block_7_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_45 (Lambda)              (None, 14, 14, 144)  0           block_7_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_BN (BatchNorm (None, 14, 14, 144)  576         lambda_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_46 (Lambda)              (None, 14, 14, 144)  0           block_7_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_relu (ReLU)   (None, 14, 14, 144)  0           lambda_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project (Conv2D)        (None, 14, 14, 24)   3456        block_7_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_47 (Lambda)              (None, 14, 14, 24)   0           block_7_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project_BN (BatchNormal (None, 14, 14, 24)   96          lambda_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_48 (Lambda)              (None, 14, 14, 24)   0           block_7_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_7_add (Add)               (None, 14, 14, 24)   0           lambda_42[0][0]                  \n",
      "                                                                 lambda_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand (Conv2D)         (None, 14, 14, 144)  3456        block_7_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_49 (Lambda)              (None, 14, 14, 144)  0           block_8_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_BN (BatchNormali (None, 14, 14, 144)  576         lambda_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_50 (Lambda)              (None, 14, 14, 144)  0           block_8_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_relu (ReLU)      (None, 14, 14, 144)  0           lambda_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise (DepthwiseCon (None, 14, 14, 144)  1296        block_8_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_51 (Lambda)              (None, 14, 14, 144)  0           block_8_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_BN (BatchNorm (None, 14, 14, 144)  576         lambda_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_52 (Lambda)              (None, 14, 14, 144)  0           block_8_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_relu (ReLU)   (None, 14, 14, 144)  0           lambda_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project (Conv2D)        (None, 14, 14, 24)   3456        block_8_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_53 (Lambda)              (None, 14, 14, 24)   0           block_8_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project_BN (BatchNormal (None, 14, 14, 24)   96          lambda_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_54 (Lambda)              (None, 14, 14, 24)   0           block_8_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_8_add (Add)               (None, 14, 14, 24)   0           block_7_add[0][0]                \n",
      "                                                                 lambda_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand (Conv2D)         (None, 14, 14, 144)  3456        block_8_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_55 (Lambda)              (None, 14, 14, 144)  0           block_9_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_BN (BatchNormali (None, 14, 14, 144)  576         lambda_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_56 (Lambda)              (None, 14, 14, 144)  0           block_9_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_relu (ReLU)      (None, 14, 14, 144)  0           lambda_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise (DepthwiseCon (None, 14, 14, 144)  1296        block_9_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_57 (Lambda)              (None, 14, 14, 144)  0           block_9_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_BN (BatchNorm (None, 14, 14, 144)  576         lambda_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_58 (Lambda)              (None, 14, 14, 144)  0           block_9_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_relu (ReLU)   (None, 14, 14, 144)  0           lambda_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project (Conv2D)        (None, 14, 14, 24)   3456        block_9_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "lambda_59 (Lambda)              (None, 14, 14, 24)   0           block_9_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project_BN (BatchNormal (None, 14, 14, 24)   96          lambda_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_60 (Lambda)              (None, 14, 14, 24)   0           block_9_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_9_add (Add)               (None, 14, 14, 24)   0           block_8_add[0][0]                \n",
      "                                                                 lambda_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand (Conv2D)        (None, 14, 14, 144)  3456        block_9_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lambda_61 (Lambda)              (None, 14, 14, 144)  0           block_10_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_BN (BatchNormal (None, 14, 14, 144)  576         lambda_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_62 (Lambda)              (None, 14, 14, 144)  0           block_10_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_relu (ReLU)     (None, 14, 14, 144)  0           lambda_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise (DepthwiseCo (None, 14, 14, 144)  1296        block_10_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_63 (Lambda)              (None, 14, 14, 144)  0           block_10_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_BN (BatchNor (None, 14, 14, 144)  576         lambda_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_64 (Lambda)              (None, 14, 14, 144)  0           block_10_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_relu (ReLU)  (None, 14, 14, 144)  0           lambda_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project (Conv2D)       (None, 14, 14, 32)   4608        block_10_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_65 (Lambda)              (None, 14, 14, 32)   0           block_10_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project_BN (BatchNorma (None, 14, 14, 32)   128         lambda_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_66 (Lambda)              (None, 14, 14, 32)   0           block_10_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand (Conv2D)        (None, 14, 14, 192)  6144        lambda_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_67 (Lambda)              (None, 14, 14, 192)  0           block_11_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_BN (BatchNormal (None, 14, 14, 192)  768         lambda_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_68 (Lambda)              (None, 14, 14, 192)  0           block_11_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_relu (ReLU)     (None, 14, 14, 192)  0           lambda_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise (DepthwiseCo (None, 14, 14, 192)  1728        block_11_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_69 (Lambda)              (None, 14, 14, 192)  0           block_11_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_BN (BatchNor (None, 14, 14, 192)  768         lambda_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_70 (Lambda)              (None, 14, 14, 192)  0           block_11_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_relu (ReLU)  (None, 14, 14, 192)  0           lambda_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project (Conv2D)       (None, 14, 14, 32)   6144        block_11_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_71 (Lambda)              (None, 14, 14, 32)   0           block_11_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project_BN (BatchNorma (None, 14, 14, 32)   128         lambda_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_72 (Lambda)              (None, 14, 14, 32)   0           block_11_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_11_add (Add)              (None, 14, 14, 32)   0           lambda_66[0][0]                  \n",
      "                                                                 lambda_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand (Conv2D)        (None, 14, 14, 192)  6144        block_11_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_73 (Lambda)              (None, 14, 14, 192)  0           block_12_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_BN (BatchNormal (None, 14, 14, 192)  768         lambda_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_74 (Lambda)              (None, 14, 14, 192)  0           block_12_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_relu (ReLU)     (None, 14, 14, 192)  0           lambda_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise (DepthwiseCo (None, 14, 14, 192)  1728        block_12_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_75 (Lambda)              (None, 14, 14, 192)  0           block_12_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_BN (BatchNor (None, 14, 14, 192)  768         lambda_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_76 (Lambda)              (None, 14, 14, 192)  0           block_12_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_relu (ReLU)  (None, 14, 14, 192)  0           lambda_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project (Conv2D)       (None, 14, 14, 32)   6144        block_12_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_77 (Lambda)              (None, 14, 14, 32)   0           block_12_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project_BN (BatchNorma (None, 14, 14, 32)   128         lambda_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_78 (Lambda)              (None, 14, 14, 32)   0           block_12_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_12_add (Add)              (None, 14, 14, 32)   0           block_11_add[0][0]               \n",
      "                                                                 lambda_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand (Conv2D)        (None, 14, 14, 192)  6144        block_12_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_79 (Lambda)              (None, 14, 14, 192)  0           block_13_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_BN (BatchNormal (None, 14, 14, 192)  768         lambda_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_80 (Lambda)              (None, 14, 14, 192)  0           block_13_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_relu (ReLU)     (None, 14, 14, 192)  0           lambda_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_13_pad (ZeroPadding2D)    (None, 15, 15, 192)  0           block_13_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise (DepthwiseCo (None, 7, 7, 192)    1728        block_13_pad[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_81 (Lambda)              (None, 7, 7, 192)    0           block_13_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_BN (BatchNor (None, 7, 7, 192)    768         lambda_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_82 (Lambda)              (None, 7, 7, 192)    0           block_13_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_relu (ReLU)  (None, 7, 7, 192)    0           lambda_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project (Conv2D)       (None, 7, 7, 56)     10752       block_13_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_83 (Lambda)              (None, 7, 7, 56)     0           block_13_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project_BN (BatchNorma (None, 7, 7, 56)     224         lambda_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_84 (Lambda)              (None, 7, 7, 56)     0           block_13_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand (Conv2D)        (None, 7, 7, 336)    18816       lambda_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_85 (Lambda)              (None, 7, 7, 336)    0           block_14_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_BN (BatchNormal (None, 7, 7, 336)    1344        lambda_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_86 (Lambda)              (None, 7, 7, 336)    0           block_14_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_relu (ReLU)     (None, 7, 7, 336)    0           lambda_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise (DepthwiseCo (None, 7, 7, 336)    3024        block_14_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_87 (Lambda)              (None, 7, 7, 336)    0           block_14_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_BN (BatchNor (None, 7, 7, 336)    1344        lambda_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_88 (Lambda)              (None, 7, 7, 336)    0           block_14_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_relu (ReLU)  (None, 7, 7, 336)    0           lambda_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project (Conv2D)       (None, 7, 7, 56)     18816       block_14_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_89 (Lambda)              (None, 7, 7, 56)     0           block_14_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project_BN (BatchNorma (None, 7, 7, 56)     224         lambda_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_90 (Lambda)              (None, 7, 7, 56)     0           block_14_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_14_add (Add)              (None, 7, 7, 56)     0           lambda_84[0][0]                  \n",
      "                                                                 lambda_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand (Conv2D)        (None, 7, 7, 336)    18816       block_14_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_91 (Lambda)              (None, 7, 7, 336)    0           block_15_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_BN (BatchNormal (None, 7, 7, 336)    1344        lambda_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_92 (Lambda)              (None, 7, 7, 336)    0           block_15_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_relu (ReLU)     (None, 7, 7, 336)    0           lambda_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise (DepthwiseCo (None, 7, 7, 336)    3024        block_15_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_93 (Lambda)              (None, 7, 7, 336)    0           block_15_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_BN (BatchNor (None, 7, 7, 336)    1344        lambda_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_94 (Lambda)              (None, 7, 7, 336)    0           block_15_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_relu (ReLU)  (None, 7, 7, 336)    0           lambda_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project (Conv2D)       (None, 7, 7, 56)     18816       block_15_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_95 (Lambda)              (None, 7, 7, 56)     0           block_15_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project_BN (BatchNorma (None, 7, 7, 56)     224         lambda_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_96 (Lambda)              (None, 7, 7, 56)     0           block_15_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_15_add (Add)              (None, 7, 7, 56)     0           block_14_add[0][0]               \n",
      "                                                                 lambda_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand (Conv2D)        (None, 7, 7, 336)    18816       block_15_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_97 (Lambda)              (None, 7, 7, 336)    0           block_16_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_BN (BatchNormal (None, 7, 7, 336)    1344        lambda_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_98 (Lambda)              (None, 7, 7, 336)    0           block_16_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_relu (ReLU)     (None, 7, 7, 336)    0           lambda_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise (DepthwiseCo (None, 7, 7, 336)    3024        block_16_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "lambda_99 (Lambda)              (None, 7, 7, 336)    0           block_16_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_BN (BatchNor (None, 7, 7, 336)    1344        lambda_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_100 (Lambda)             (None, 7, 7, 336)    0           block_16_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_relu (ReLU)  (None, 7, 7, 336)    0           lambda_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project (Conv2D)       (None, 7, 7, 112)    37632       block_16_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_101 (Lambda)             (None, 7, 7, 112)    0           block_16_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project_BN (BatchNorma (None, 7, 7, 112)    448         lambda_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_102 (Lambda)             (None, 7, 7, 112)    0           block_16_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 7, 7, 1280)   143360      lambda_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_103 (Lambda)             (None, 7, 7, 1280)   0           Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)   5120        lambda_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_104 (Lambda)             (None, 7, 7, 1280)   0           Conv_1_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "out_relu (ReLU)                 (None, 7, 7, 1280)   0           lambda_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 1280)         0           out_relu[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "Logits (Dense)                  (None, 1000)         1281000     global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 1,691,208\n",
      "Trainable params: 1,677,128\n",
      "Non-trainable params: 14,080\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv1 1 (3, 3, 3, 16)\n",
      "2 1 (155, 112, 112, 16)\n",
      "bn_Conv1 4 (16,)\n",
      "4 1 (155, 112, 112, 16)\n",
      "expanded_conv_depthwise 1 (3, 3, 16, 1)\n",
      "7 1 (155, 112, 112, 16)\n",
      "expanded_conv_depthwise_BN 4 (16,)\n",
      "9 1 (155, 112, 112, 16)\n",
      "expanded_conv_project 1 (1, 1, 16, 8)\n",
      "12 1 (155, 112, 112, 8)\n",
      "expanded_conv_project_BN 4 (8,)\n",
      "14 1 (155, 112, 112, 8)\n",
      "block_1_expand 1 (1, 1, 8, 48)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-0f472250a161>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mactivations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_activations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mim_temp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-eccd4f8914ff>\u001b[0m in \u001b[0;36mget_activations\u001b[0;34m(model, layer, X_batch)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mget_activations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#The learning phase flag is a bool tensor (0 = test, 1 = train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mactivations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_activations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_batch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lesion/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lesion/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/lesion/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "im_temp = preprocess_image_batch(im_train,img_size=(256,256), crop_size=(224,224), color_mode=\"rgb\")\n",
    "i = 0\n",
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    if len(weights) > 0:\n",
    "        print(layer.name, len(weights), weights[0].shape)\n",
    "        if len(weights) > 0:\n",
    "            activations = get_activations(model,i,im_temp)\n",
    "            print(i, len(activations), activations[0].shape)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155 155 155\n",
      "120 0.22580645161290325\n",
      "Conv1 1 1 (155, 112, 112, 16) (112, 112, 16) (200704,)\n",
      "bn_Conv1 4 1 (155, 112, 112, 16) (112, 112, 16) (200704,)\n",
      "expanded_conv_depthwise 1 1 (155, 112, 112, 16) (112, 112, 16) (200704,)\n",
      "expanded_conv_depthwise_BN 4 1 (155, 112, 112, 16) (112, 112, 16) (200704,)\n",
      "expanded_conv_project 1 1 (155, 112, 112, 8) (112, 112, 8) (100352,)\n",
      "expanded_conv_project_BN 4 1 (155, 112, 112, 8) (112, 112, 8) (100352,)\n",
      "block_1_expand 1 1 (155, 112, 112, 48) (112, 112, 48) (602112,)\n",
      "block_1_expand_BN 4 1 (155, 112, 112, 48) (112, 112, 48) (602112,)\n",
      "block_1_depthwise 1 1 (155, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_1_depthwise_BN 4 1 (155, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_1_project 1 1 (155, 56, 56, 8) (56, 56, 8) (25088,)\n",
      "block_1_project_BN 4 1 (155, 56, 56, 8) (56, 56, 8) (25088,)\n",
      "block_2_expand 1 1 (155, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_2_expand_BN 4 1 (155, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_2_depthwise 1 1 (155, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_2_depthwise_BN 4 1 (155, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_2_project 1 1 (155, 56, 56, 8) (56, 56, 8) (25088,)\n",
      "block_2_project_BN 4 1 (155, 56, 56, 8) (56, 56, 8) (25088,)\n",
      "block_3_expand 1 1 (155, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_3_expand_BN 4 1 (155, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_3_depthwise 1 1 (155, 28, 28, 48) (28, 28, 48) (37632,)\n",
      "block_3_depthwise_BN 4 1 (155, 28, 28, 48) (28, 28, 48) (37632,)\n",
      "block_3_project 1 1 (155, 28, 28, 16) (28, 28, 16) (12544,)\n",
      "block_3_project_BN 4 1 (155, 28, 28, 16) (28, 28, 16) (12544,)\n",
      "block_4_expand 1 1 (155, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_4_expand_BN 4 1 (155, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_4_depthwise 1 1 (155, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_4_depthwise_BN 4 1 (155, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_4_project 1 1 (155, 28, 28, 16) (28, 28, 16) (12544,)\n",
      "block_4_project_BN 4 1 (155, 28, 28, 16) (28, 28, 16) (12544,)\n",
      "block_5_expand 1 1 (155, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_5_expand_BN 4 1 (155, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_5_depthwise 1 1 (155, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_5_depthwise_BN 4 1 (155, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_5_project 1 1 (155, 28, 28, 16) (28, 28, 16) (12544,)\n",
      "block_5_project_BN 4 1 (155, 28, 28, 16) (28, 28, 16) (12544,)\n",
      "block_6_expand 1 1 (155, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_6_expand_BN 4 1 (155, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_6_depthwise 1 1 (155, 14, 14, 96) (14, 14, 96) (18816,)\n",
      "block_6_depthwise_BN 4 1 (155, 14, 14, 96) (14, 14, 96) (18816,)\n",
      "block_6_project 1 1 (155, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_6_project_BN 4 1 (155, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_7_expand 1 1 (155, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_7_expand_BN 4 1 (155, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_7_depthwise 1 1 (155, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_7_depthwise_BN 4 1 (155, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_7_project 1 1 (155, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_7_project_BN 4 1 (155, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_8_expand 1 1 (155, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_8_expand_BN 4 1 (155, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_8_depthwise 1 1 (155, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_8_depthwise_BN 4 1 (155, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_8_project 1 1 (155, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_8_project_BN 4 1 (155, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_9_expand 1 1 (155, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_9_expand_BN 4 1 (155, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_9_depthwise 1 1 (155, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_9_depthwise_BN 4 1 (155, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_9_project 1 1 (155, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_9_project_BN 4 1 (155, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_10_expand 1 1 (155, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_10_expand_BN 4 1 (155, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_10_depthwise 1 1 (155, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_10_depthwise_BN 4 1 (155, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_10_project 1 1 (155, 14, 14, 32) (14, 14, 32) (6272,)\n",
      "block_10_project_BN 4 1 (155, 14, 14, 32) (14, 14, 32) (6272,)\n",
      "block_11_expand 1 1 (155, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_11_expand_BN 4 1 (155, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_11_depthwise 1 1 (155, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_11_depthwise_BN 4 1 (155, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_11_project 1 1 (155, 14, 14, 32) (14, 14, 32) (6272,)\n",
      "block_11_project_BN 4 1 (155, 14, 14, 32) (14, 14, 32) (6272,)\n",
      "block_12_expand 1 1 (155, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_12_expand_BN 4 1 (155, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_12_depthwise 1 1 (155, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_12_depthwise_BN 4 1 (155, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_12_project 1 1 (155, 14, 14, 32) (14, 14, 32) (6272,)\n",
      "block_12_project_BN 4 1 (155, 14, 14, 32) (14, 14, 32) (6272,)\n",
      "block_13_expand 1 1 (155, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_13_expand_BN 4 1 (155, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_13_depthwise 1 1 (155, 7, 7, 192) (7, 7, 192) (9408,)\n",
      "block_13_depthwise_BN 4 1 (155, 7, 7, 192) (7, 7, 192) (9408,)\n",
      "block_13_project 1 1 (155, 7, 7, 56) (7, 7, 56) (2744,)\n",
      "block_13_project_BN 4 1 (155, 7, 7, 56) (7, 7, 56) (2744,)\n",
      "block_14_expand 1 1 (155, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_14_expand_BN 4 1 (155, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_14_depthwise 1 1 (155, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_14_depthwise_BN 4 1 (155, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_14_project 1 1 (155, 7, 7, 56) (7, 7, 56) (2744,)\n",
      "block_14_project_BN 4 1 (155, 7, 7, 56) (7, 7, 56) (2744,)\n",
      "block_15_expand 1 1 (155, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_15_expand_BN 4 1 (155, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_15_depthwise 1 1 (155, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_15_depthwise_BN 4 1 (155, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_15_project 1 1 (155, 7, 7, 56) (7, 7, 56) (2744,)\n",
      "block_15_project_BN 4 1 (155, 7, 7, 56) (7, 7, 56) (2744,)\n",
      "block_16_expand 1 1 (155, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_16_expand_BN 4 1 (155, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_16_depthwise 1 1 (155, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_16_depthwise_BN 4 1 (155, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_16_project 1 1 (155, 7, 7, 112) (7, 7, 112) (5488,)\n",
      "block_16_project_BN 4 1 (155, 7, 7, 112) (7, 7, 112) (5488,)\n",
      "Conv_1 1 1 (155, 7, 7, 1280) (7, 7, 1280) (62720,)\n",
      "Conv_1_bn 4 1 (155, 7, 7, 1280) (7, 7, 1280) (62720,)\n",
      "(5725552,)\n"
     ]
    }
   ],
   "source": [
    "#Training data pkl\n",
    "fp_name = '../../data/pkl_mobile/'+str(p)+'_'+str(model_name)+'_train_no_lesion_performance.txt'\n",
    "fp = open(fp_name,'a+')\n",
    "im_temp = preprocess_image_batch(im_train,img_size=(256,256), crop_size=(224,224), color_mode=\"rgb\")\n",
    "out = model.predict(im_temp)\n",
    "\n",
    "true_valid_wids = []\n",
    "for i in im_train:\n",
    "        temp1 = i.split('/')[4]\n",
    "        temp = temp1.split('.')[0].split('_')[2]\n",
    "        true_valid_wids.append(truth[int(temp)][1])\n",
    "\n",
    "predicted_valid_wids = []\n",
    "for i in range(len(im_train)):\n",
    "    #print(im_list[i], pprint_output(out[i]), true_wids[i])\n",
    "    predicted_valid_wids.append(pprint_output(out[i]))\n",
    "\n",
    "count, error  = top5accuracy(true_valid_wids, predicted_valid_wids)\n",
    "\n",
    "fp.write(str(p)+' '+str(count)+' '+str(len(im_train))+' '+str(error)+'\\n')\n",
    "\n",
    "\n",
    "print(len(true_valid_wids), len(predicted_valid_wids), len(im_train))\n",
    "print(count, error)\n",
    "\n",
    "\n",
    "#}\n",
    "# Code snippet to get the activation values and saving information{\n",
    "data = np.array([])\n",
    "\n",
    "i = 0\n",
    "result ={}\n",
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    #print(layer.name, len(weights))\n",
    "    if len(weights) > 0:\n",
    "        activations = get_activations(model,i,im_temp)\n",
    "        if result.get(layer.name, Noneif len(weights) > 0:\n",
    "        activations = get_activations(model,i,im_temp)) is None:\n",
    "            result[layer.name] = activations[0]\n",
    "            temp = np.mean(activations[0], axis=0).ravel()\n",
    "            if layer.name != 'Logits':\n",
    "                print(layer.name,len(weights),len(activations), activations[0].shape, np.mean(activations[0], axis=0).shape, temp.shape)\n",
    "                data = np.append(data, temp)\n",
    "    i += 1\n",
    "\n",
    "print(data.shape)\n",
    "fp.close()\n",
    "with open('../../data/pkl_mobile/'+str(p)+'_train_'+model_name+'.pkl', 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 39 39\n",
      "33 0.15384615384615385\n",
      "Conv1 1 1 (39, 112, 112, 16) (112, 112, 16) (200704,)\n",
      "bn_Conv1 4 1 (39, 112, 112, 16) (112, 112, 16) (200704,)\n",
      "expanded_conv_depthwise 1 1 (39, 112, 112, 16) (112, 112, 16) (200704,)\n",
      "expanded_conv_depthwise_BN 4 1 (39, 112, 112, 16) (112, 112, 16) (200704,)\n",
      "expanded_conv_project 1 1 (39, 112, 112, 8) (112, 112, 8) (100352,)\n",
      "expanded_conv_project_BN 4 1 (39, 112, 112, 8) (112, 112, 8) (100352,)\n",
      "block_1_expand 1 1 (39, 112, 112, 48) (112, 112, 48) (602112,)\n",
      "block_1_expand_BN 4 1 (39, 112, 112, 48) (112, 112, 48) (602112,)\n",
      "block_1_depthwise 1 1 (39, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_1_depthwise_BN 4 1 (39, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_1_project 1 1 (39, 56, 56, 8) (56, 56, 8) (25088,)\n",
      "block_1_project_BN 4 1 (39, 56, 56, 8) (56, 56, 8) (25088,)\n",
      "block_2_expand 1 1 (39, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_2_expand_BN 4 1 (39, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_2_depthwise 1 1 (39, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_2_depthwise_BN 4 1 (39, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_2_project 1 1 (39, 56, 56, 8) (56, 56, 8) (25088,)\n",
      "block_2_project_BN 4 1 (39, 56, 56, 8) (56, 56, 8) (25088,)\n",
      "block_3_expand 1 1 (39, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_3_expand_BN 4 1 (39, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_3_depthwise 1 1 (39, 28, 28, 48) (28, 28, 48) (37632,)\n",
      "block_3_depthwise_BN 4 1 (39, 28, 28, 48) (28, 28, 48) (37632,)\n",
      "block_3_project 1 1 (39, 28, 28, 16) (28, 28, 16) (12544,)\n",
      "block_3_project_BN 4 1 (39, 28, 28, 16) (28, 28, 16) (12544,)\n",
      "block_4_expand 1 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_4_expand_BN 4 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_4_depthwise 1 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_4_depthwise_BN 4 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_4_project 1 1 (39, 28, 28, 16) (28, 28, 16) (12544,)\n",
      "block_4_project_BN 4 1 (39, 28, 28, 16) (28, 28, 16) (12544,)\n",
      "block_5_expand 1 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_5_expand_BN 4 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_5_depthwise 1 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_5_depthwise_BN 4 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_5_project 1 1 (39, 28, 28, 16) (28, 28, 16) (12544,)\n",
      "block_5_project_BN 4 1 (39, 28, 28, 16) (28, 28, 16) (12544,)\n",
      "block_6_expand 1 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_6_expand_BN 4 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_6_depthwise 1 1 (39, 14, 14, 96) (14, 14, 96) (18816,)\n",
      "block_6_depthwise_BN 4 1 (39, 14, 14, 96) (14, 14, 96) (18816,)\n",
      "block_6_project 1 1 (39, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_6_project_BN 4 1 (39, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_7_expand 1 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_7_expand_BN 4 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_7_depthwise 1 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_7_depthwise_BN 4 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_7_project 1 1 (39, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_7_project_BN 4 1 (39, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_8_expand 1 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_8_expand_BN 4 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_8_depthwise 1 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_8_depthwise_BN 4 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_8_project 1 1 (39, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_8_project_BN 4 1 (39, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_9_expand 1 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_9_expand_BN 4 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_9_depthwise 1 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_9_depthwise_BN 4 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_9_project 1 1 (39, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_9_project_BN 4 1 (39, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_10_expand 1 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_10_expand_BN 4 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_10_depthwise 1 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_10_depthwise_BN 4 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_10_project 1 1 (39, 14, 14, 32) (14, 14, 32) (6272,)\n",
      "block_10_project_BN 4 1 (39, 14, 14, 32) (14, 14, 32) (6272,)\n",
      "block_11_expand 1 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_11_expand_BN 4 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_11_depthwise 1 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_11_depthwise_BN 4 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_11_project 1 1 (39, 14, 14, 32) (14, 14, 32) (6272,)\n",
      "block_11_project_BN 4 1 (39, 14, 14, 32) (14, 14, 32) (6272,)\n",
      "block_12_expand 1 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_12_expand_BN 4 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_12_depthwise 1 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_12_depthwise_BN 4 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_12_project 1 1 (39, 14, 14, 32) (14, 14, 32) (6272,)\n",
      "block_12_project_BN 4 1 (39, 14, 14, 32) (14, 14, 32) (6272,)\n",
      "block_13_expand 1 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_13_expand_BN 4 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_13_depthwise 1 1 (39, 7, 7, 192) (7, 7, 192) (9408,)\n",
      "block_13_depthwise_BN 4 1 (39, 7, 7, 192) (7, 7, 192) (9408,)\n",
      "block_13_project 1 1 (39, 7, 7, 56) (7, 7, 56) (2744,)\n",
      "block_13_project_BN 4 1 (39, 7, 7, 56) (7, 7, 56) (2744,)\n",
      "block_14_expand 1 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_14_expand_BN 4 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_14_depthwise 1 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_14_depthwise_BN 4 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_14_project 1 1 (39, 7, 7, 56) (7, 7, 56) (2744,)\n",
      "block_14_project_BN 4 1 (39, 7, 7, 56) (7, 7, 56) (2744,)\n",
      "block_15_expand 1 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_15_expand_BN 4 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_15_depthwise 1 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_15_depthwise_BN 4 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_15_project 1 1 (39, 7, 7, 56) (7, 7, 56) (2744,)\n",
      "block_15_project_BN 4 1 (39, 7, 7, 56) (7, 7, 56) (2744,)\n",
      "block_16_expand 1 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_16_expand_BN 4 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_16_depthwise 1 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_16_depthwise_BN 4 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_16_project 1 1 (39, 7, 7, 112) (7, 7, 112) (5488,)\n",
      "block_16_project_BN 4 1 (39, 7, 7, 112) (7, 7, 112) (5488,)\n",
      "Conv_1 1 1 (39, 7, 7, 1280) (7, 7, 1280) (62720,)\n",
      "Conv_1_bn 4 1 (39, 7, 7, 1280) (7, 7, 1280) (62720,)\n",
      "(5725552,)\n"
     ]
    }
   ],
   "source": [
    "#Testing data pkl\n",
    "fp_name = '../../data/pkl_mobile/'+str(p)+'_'+str(model_name)+'_test_no_lesion_performance.txt'\n",
    "fp = open(fp_name,'a+')\n",
    "\n",
    "im_temp = preprocess_image_batch(im_test,img_size=(256,256), crop_size=(224,224), color_mode=\"rgb\")\n",
    "out = model.predict(im_temp,batch_size=64)\n",
    "\n",
    "true_valid_wids = []\n",
    "for i in im_test:\n",
    "        temp1 = i.split('/')[4]\n",
    "        temp = temp1.split('.')[0].split('_')[2]\n",
    "        true_valid_wids.append(truth[int(temp)][1])\n",
    "\n",
    "predicted_valid_wids = []\n",
    "for i in range(len(im_test)):\n",
    "    #print im_list[i], pprint_output(out[i]), true_wids[i]\n",
    "    predicted_valid_wids.append(pprint_output(out[i]))\n",
    "\n",
    "count, error  = top5accuracy(true_valid_wids, predicted_valid_wids)\n",
    "\n",
    "fp.write(str(p)+' '+str(count)+' '+str(len(im_test))+' '+str(error)+'\\n')\n",
    "\n",
    "\n",
    "print(len(true_valid_wids), len(predicted_valid_wids), len(im_test))\n",
    "print(count, error)\n",
    "\n",
    "\n",
    "#}\n",
    "# Code snippet to get the activation values and saving information{\n",
    "data = np.array([])\n",
    "\n",
    "i = 0\n",
    "result ={}\n",
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    if len(weights) > 0:\n",
    "        activations = get_activations(model,i,im_temp)\n",
    "        if result.get(layer.name, None) is None:\n",
    "            result[layer.name] = activations[0]\n",
    "            temp = np.mean(activations[0], axis=0).ravel()\n",
    "            if layer.name != 'Logits':\n",
    "                print(layer.name,len(weights),len(activations), activations[0].shape, np.mean(activations[0], axis=0).shape, temp.shape)\n",
    "                data = np.append(data, temp)\n",
    "    i += 1\n",
    "    \n",
    "print(data.shape)\n",
    "fp.close()\n",
    "with open('../../data/pkl_mobile/'+str(p)+'_test_'+model_name+'.pkl', 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Fold:  1\n",
      "39 39 39\n",
      "33 0.15384615384615385\n",
      "Conv1 1 1 (39, 112, 112, 16) (112, 112, 16) (200704,)\n",
      "bn_Conv1 4 1 (39, 112, 112, 16) (112, 112, 16) (200704,)\n",
      "expanded_conv_depthwise 1 1 (39, 112, 112, 16) (112, 112, 16) (200704,)\n",
      "expanded_conv_depthwise_BN 4 1 (39, 112, 112, 16) (112, 112, 16) (200704,)\n",
      "expanded_conv_project 1 1 (39, 112, 112, 8) (112, 112, 8) (100352,)\n",
      "expanded_conv_project_BN 4 1 (39, 112, 112, 8) (112, 112, 8) (100352,)\n",
      "block_1_expand 1 1 (39, 112, 112, 48) (112, 112, 48) (602112,)\n",
      "block_1_expand_BN 4 1 (39, 112, 112, 48) (112, 112, 48) (602112,)\n",
      "block_1_depthwise 1 1 (39, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_1_depthwise_BN 4 1 (39, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_1_project 1 1 (39, 56, 56, 8) (56, 56, 8) (25088,)\n",
      "block_1_project_BN 4 1 (39, 56, 56, 8) (56, 56, 8) (25088,)\n",
      "block_2_expand 1 1 (39, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_2_expand_BN 4 1 (39, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_2_depthwise 1 1 (39, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_2_depthwise_BN 4 1 (39, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_2_project 1 1 (39, 56, 56, 8) (56, 56, 8) (25088,)\n",
      "block_2_project_BN 4 1 (39, 56, 56, 8) (56, 56, 8) (25088,)\n",
      "block_3_expand 1 1 (39, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_3_expand_BN 4 1 (39, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_3_depthwise 1 1 (39, 28, 28, 48) (28, 28, 48) (37632,)\n",
      "block_3_depthwise_BN 4 1 (39, 28, 28, 48) (28, 28, 48) (37632,)\n",
      "block_3_project 1 1 (39, 28, 28, 16) (28, 28, 16) (12544,)\n",
      "block_3_project_BN 4 1 (39, 28, 28, 16) (28, 28, 16) (12544,)\n",
      "block_4_expand 1 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_4_expand_BN 4 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_4_depthwise 1 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_4_depthwise_BN 4 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_4_project 1 1 (39, 28, 28, 16) (28, 28, 16) (12544,)\n",
      "block_4_project_BN 4 1 (39, 28, 28, 16) (28, 28, 16) (12544,)\n",
      "block_5_expand 1 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_5_expand_BN 4 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_5_depthwise 1 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_5_depthwise_BN 4 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_5_project 1 1 (39, 28, 28, 16) (28, 28, 16) (12544,)\n",
      "block_5_project_BN 4 1 (39, 28, 28, 16) (28, 28, 16) (12544,)\n",
      "block_6_expand 1 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_6_expand_BN 4 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_6_depthwise 1 1 (39, 14, 14, 96) (14, 14, 96) (18816,)\n",
      "block_6_depthwise_BN 4 1 (39, 14, 14, 96) (14, 14, 96) (18816,)\n",
      "block_6_project 1 1 (39, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_6_project_BN 4 1 (39, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_7_expand 1 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_7_expand_BN 4 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_7_depthwise 1 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_7_depthwise_BN 4 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_7_project 1 1 (39, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_7_project_BN 4 1 (39, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_8_expand 1 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_8_expand_BN 4 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_8_depthwise 1 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_8_depthwise_BN 4 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_8_project 1 1 (39, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_8_project_BN 4 1 (39, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_9_expand 1 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_9_expand_BN 4 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_9_depthwise 1 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_9_depthwise_BN 4 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_9_project 1 1 (39, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_9_project_BN 4 1 (39, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_10_expand 1 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_10_expand_BN 4 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_10_depthwise 1 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_10_depthwise_BN 4 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_10_project 1 1 (39, 14, 14, 32) (14, 14, 32) (6272,)\n",
      "block_10_project_BN 4 1 (39, 14, 14, 32) (14, 14, 32) (6272,)\n",
      "block_11_expand 1 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_11_expand_BN 4 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_11_depthwise 1 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_11_depthwise_BN 4 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_11_project 1 1 (39, 14, 14, 32) (14, 14, 32) (6272,)\n",
      "block_11_project_BN 4 1 (39, 14, 14, 32) (14, 14, 32) (6272,)\n",
      "block_12_expand 1 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_12_expand_BN 4 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_12_depthwise 1 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_12_depthwise_BN 4 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_12_project 1 1 (39, 14, 14, 32) (14, 14, 32) (6272,)\n",
      "block_12_project_BN 4 1 (39, 14, 14, 32) (14, 14, 32) (6272,)\n",
      "block_13_expand 1 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_13_expand_BN 4 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_13_depthwise 1 1 (39, 7, 7, 192) (7, 7, 192) (9408,)\n",
      "block_13_depthwise_BN 4 1 (39, 7, 7, 192) (7, 7, 192) (9408,)\n",
      "block_13_project 1 1 (39, 7, 7, 56) (7, 7, 56) (2744,)\n",
      "block_13_project_BN 4 1 (39, 7, 7, 56) (7, 7, 56) (2744,)\n",
      "block_14_expand 1 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_14_expand_BN 4 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_14_depthwise 1 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_14_depthwise_BN 4 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_14_project 1 1 (39, 7, 7, 56) (7, 7, 56) (2744,)\n",
      "block_14_project_BN 4 1 (39, 7, 7, 56) (7, 7, 56) (2744,)\n",
      "block_15_expand 1 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_15_expand_BN 4 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_15_depthwise 1 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_15_depthwise_BN 4 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_15_project 1 1 (39, 7, 7, 56) (7, 7, 56) (2744,)\n",
      "block_15_project_BN 4 1 (39, 7, 7, 56) (7, 7, 56) (2744,)\n",
      "block_16_expand 1 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_16_expand_BN 4 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_16_depthwise 1 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_16_depthwise_BN 4 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_16_project 1 1 (39, 7, 7, 112) (7, 7, 112) (5488,)\n",
      "block_16_project_BN 4 1 (39, 7, 7, 112) (7, 7, 112) (5488,)\n",
      "Conv_1 1 1 (39, 7, 7, 1280) (7, 7, 1280) (62720,)\n",
      "Conv_1_bn 4 1 (39, 7, 7, 1280) (7, 7, 1280) (62720,)\n",
      "(5725552,)\n",
      "Starting Fold:  2\n",
      "39 39 39\n",
      "28 0.28205128205128205\n",
      "Conv1 1 1 (39, 112, 112, 16) (112, 112, 16) (200704,)\n",
      "bn_Conv1 4 1 (39, 112, 112, 16) (112, 112, 16) (200704,)\n",
      "expanded_conv_depthwise 1 1 (39, 112, 112, 16) (112, 112, 16) (200704,)\n",
      "expanded_conv_depthwise_BN 4 1 (39, 112, 112, 16) (112, 112, 16) (200704,)\n",
      "expanded_conv_project 1 1 (39, 112, 112, 8) (112, 112, 8) (100352,)\n",
      "expanded_conv_project_BN 4 1 (39, 112, 112, 8) (112, 112, 8) (100352,)\n",
      "block_1_expand 1 1 (39, 112, 112, 48) (112, 112, 48) (602112,)\n",
      "block_1_expand_BN 4 1 (39, 112, 112, 48) (112, 112, 48) (602112,)\n",
      "block_1_depthwise 1 1 (39, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_1_depthwise_BN 4 1 (39, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_1_project 1 1 (39, 56, 56, 8) (56, 56, 8) (25088,)\n",
      "block_1_project_BN 4 1 (39, 56, 56, 8) (56, 56, 8) (25088,)\n",
      "block_2_expand 1 1 (39, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_2_expand_BN 4 1 (39, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_2_depthwise 1 1 (39, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_2_depthwise_BN 4 1 (39, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_2_project 1 1 (39, 56, 56, 8) (56, 56, 8) (25088,)\n",
      "block_2_project_BN 4 1 (39, 56, 56, 8) (56, 56, 8) (25088,)\n",
      "block_3_expand 1 1 (39, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_3_expand_BN 4 1 (39, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_3_depthwise 1 1 (39, 28, 28, 48) (28, 28, 48) (37632,)\n",
      "block_3_depthwise_BN 4 1 (39, 28, 28, 48) (28, 28, 48) (37632,)\n",
      "block_3_project 1 1 (39, 28, 28, 16) (28, 28, 16) (12544,)\n",
      "block_3_project_BN 4 1 (39, 28, 28, 16) (28, 28, 16) (12544,)\n",
      "block_4_expand 1 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_4_expand_BN 4 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_4_depthwise 1 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_4_depthwise_BN 4 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_4_project 1 1 (39, 28, 28, 16) (28, 28, 16) (12544,)\n",
      "block_4_project_BN 4 1 (39, 28, 28, 16) (28, 28, 16) (12544,)\n",
      "block_5_expand 1 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_5_expand_BN 4 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_5_depthwise 1 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_5_depthwise_BN 4 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_5_project 1 1 (39, 28, 28, 16) (28, 28, 16) (12544,)\n",
      "block_5_project_BN 4 1 (39, 28, 28, 16) (28, 28, 16) (12544,)\n",
      "block_6_expand 1 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_6_expand_BN 4 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_6_depthwise 1 1 (39, 14, 14, 96) (14, 14, 96) (18816,)\n",
      "block_6_depthwise_BN 4 1 (39, 14, 14, 96) (14, 14, 96) (18816,)\n",
      "block_6_project 1 1 (39, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_6_project_BN 4 1 (39, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_7_expand 1 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_7_expand_BN 4 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_7_depthwise 1 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_7_depthwise_BN 4 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_7_project 1 1 (39, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_7_project_BN 4 1 (39, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_8_expand 1 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_8_expand_BN 4 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_8_depthwise 1 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_8_depthwise_BN 4 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_8_project 1 1 (39, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_8_project_BN 4 1 (39, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_9_expand 1 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_9_expand_BN 4 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_9_depthwise 1 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_9_depthwise_BN 4 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_9_project 1 1 (39, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_9_project_BN 4 1 (39, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_10_expand 1 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_10_expand_BN 4 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_10_depthwise 1 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_10_depthwise_BN 4 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_10_project 1 1 (39, 14, 14, 32) (14, 14, 32) (6272,)\n",
      "block_10_project_BN 4 1 (39, 14, 14, 32) (14, 14, 32) (6272,)\n",
      "block_11_expand 1 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_11_expand_BN 4 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_11_depthwise 1 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_11_depthwise_BN 4 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_11_project 1 1 (39, 14, 14, 32) (14, 14, 32) (6272,)\n",
      "block_11_project_BN 4 1 (39, 14, 14, 32) (14, 14, 32) (6272,)\n",
      "block_12_expand 1 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_12_expand_BN 4 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_12_depthwise 1 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_12_depthwise_BN 4 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_12_project 1 1 (39, 14, 14, 32) (14, 14, 32) (6272,)\n",
      "block_12_project_BN 4 1 (39, 14, 14, 32) (14, 14, 32) (6272,)\n",
      "block_13_expand 1 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_13_expand_BN 4 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_13_depthwise 1 1 (39, 7, 7, 192) (7, 7, 192) (9408,)\n",
      "block_13_depthwise_BN 4 1 (39, 7, 7, 192) (7, 7, 192) (9408,)\n",
      "block_13_project 1 1 (39, 7, 7, 56) (7, 7, 56) (2744,)\n",
      "block_13_project_BN 4 1 (39, 7, 7, 56) (7, 7, 56) (2744,)\n",
      "block_14_expand 1 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_14_expand_BN 4 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_14_depthwise 1 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_14_depthwise_BN 4 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_14_project 1 1 (39, 7, 7, 56) (7, 7, 56) (2744,)\n",
      "block_14_project_BN 4 1 (39, 7, 7, 56) (7, 7, 56) (2744,)\n",
      "block_15_expand 1 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_15_expand_BN 4 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_15_depthwise 1 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_15_depthwise_BN 4 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_15_project 1 1 (39, 7, 7, 56) (7, 7, 56) (2744,)\n",
      "block_15_project_BN 4 1 (39, 7, 7, 56) (7, 7, 56) (2744,)\n",
      "block_16_expand 1 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_16_expand_BN 4 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_16_depthwise 1 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_16_depthwise_BN 4 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_16_project 1 1 (39, 7, 7, 112) (7, 7, 112) (5488,)\n",
      "block_16_project_BN 4 1 (39, 7, 7, 112) (7, 7, 112) (5488,)\n",
      "Conv_1 1 1 (39, 7, 7, 1280) (7, 7, 1280) (62720,)\n",
      "Conv_1_bn 4 1 (39, 7, 7, 1280) (7, 7, 1280) (62720,)\n",
      "(5725552,)\n",
      "Starting Fold:  3\n",
      "39 39 39\n",
      "30 0.23076923076923073\n",
      "Conv1 1 1 (39, 112, 112, 16) (112, 112, 16) (200704,)\n",
      "bn_Conv1 4 1 (39, 112, 112, 16) (112, 112, 16) (200704,)\n",
      "expanded_conv_depthwise 1 1 (39, 112, 112, 16) (112, 112, 16) (200704,)\n",
      "expanded_conv_depthwise_BN 4 1 (39, 112, 112, 16) (112, 112, 16) (200704,)\n",
      "expanded_conv_project 1 1 (39, 112, 112, 8) (112, 112, 8) (100352,)\n",
      "expanded_conv_project_BN 4 1 (39, 112, 112, 8) (112, 112, 8) (100352,)\n",
      "block_1_expand 1 1 (39, 112, 112, 48) (112, 112, 48) (602112,)\n",
      "block_1_expand_BN 4 1 (39, 112, 112, 48) (112, 112, 48) (602112,)\n",
      "block_1_depthwise 1 1 (39, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_1_depthwise_BN 4 1 (39, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_1_project 1 1 (39, 56, 56, 8) (56, 56, 8) (25088,)\n",
      "block_1_project_BN 4 1 (39, 56, 56, 8) (56, 56, 8) (25088,)\n",
      "block_2_expand 1 1 (39, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_2_expand_BN 4 1 (39, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_2_depthwise 1 1 (39, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_2_depthwise_BN 4 1 (39, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_2_project 1 1 (39, 56, 56, 8) (56, 56, 8) (25088,)\n",
      "block_2_project_BN 4 1 (39, 56, 56, 8) (56, 56, 8) (25088,)\n",
      "block_3_expand 1 1 (39, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_3_expand_BN 4 1 (39, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_3_depthwise 1 1 (39, 28, 28, 48) (28, 28, 48) (37632,)\n",
      "block_3_depthwise_BN 4 1 (39, 28, 28, 48) (28, 28, 48) (37632,)\n",
      "block_3_project 1 1 (39, 28, 28, 16) (28, 28, 16) (12544,)\n",
      "block_3_project_BN 4 1 (39, 28, 28, 16) (28, 28, 16) (12544,)\n",
      "block_4_expand 1 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_4_expand_BN 4 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_4_depthwise 1 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_4_depthwise_BN 4 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_4_project 1 1 (39, 28, 28, 16) (28, 28, 16) (12544,)\n",
      "block_4_project_BN 4 1 (39, 28, 28, 16) (28, 28, 16) (12544,)\n",
      "block_5_expand 1 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_5_expand_BN 4 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_5_depthwise 1 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_5_depthwise_BN 4 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_5_project 1 1 (39, 28, 28, 16) (28, 28, 16) (12544,)\n",
      "block_5_project_BN 4 1 (39, 28, 28, 16) (28, 28, 16) (12544,)\n",
      "block_6_expand 1 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_6_expand_BN 4 1 (39, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_6_depthwise 1 1 (39, 14, 14, 96) (14, 14, 96) (18816,)\n",
      "block_6_depthwise_BN 4 1 (39, 14, 14, 96) (14, 14, 96) (18816,)\n",
      "block_6_project 1 1 (39, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_6_project_BN 4 1 (39, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_7_expand 1 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_7_expand_BN 4 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_7_depthwise 1 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_7_depthwise_BN 4 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_7_project 1 1 (39, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_7_project_BN 4 1 (39, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_8_expand 1 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_8_expand_BN 4 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_8_depthwise 1 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_8_depthwise_BN 4 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_8_project 1 1 (39, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_8_project_BN 4 1 (39, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_9_expand 1 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_9_expand_BN 4 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_9_depthwise 1 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_9_depthwise_BN 4 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_9_project 1 1 (39, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_9_project_BN 4 1 (39, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_10_expand 1 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_10_expand_BN 4 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_10_depthwise 1 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_10_depthwise_BN 4 1 (39, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_10_project 1 1 (39, 14, 14, 32) (14, 14, 32) (6272,)\n",
      "block_10_project_BN 4 1 (39, 14, 14, 32) (14, 14, 32) (6272,)\n",
      "block_11_expand 1 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_11_expand_BN 4 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_11_depthwise 1 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_11_depthwise_BN 4 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_11_project 1 1 (39, 14, 14, 32) (14, 14, 32) (6272,)\n",
      "block_11_project_BN 4 1 (39, 14, 14, 32) (14, 14, 32) (6272,)\n",
      "block_12_expand 1 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_12_expand_BN 4 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_12_depthwise 1 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_12_depthwise_BN 4 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_12_project 1 1 (39, 14, 14, 32) (14, 14, 32) (6272,)\n",
      "block_12_project_BN 4 1 (39, 14, 14, 32) (14, 14, 32) (6272,)\n",
      "block_13_expand 1 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_13_expand_BN 4 1 (39, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_13_depthwise 1 1 (39, 7, 7, 192) (7, 7, 192) (9408,)\n",
      "block_13_depthwise_BN 4 1 (39, 7, 7, 192) (7, 7, 192) (9408,)\n",
      "block_13_project 1 1 (39, 7, 7, 56) (7, 7, 56) (2744,)\n",
      "block_13_project_BN 4 1 (39, 7, 7, 56) (7, 7, 56) (2744,)\n",
      "block_14_expand 1 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_14_expand_BN 4 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_14_depthwise 1 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_14_depthwise_BN 4 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_14_project 1 1 (39, 7, 7, 56) (7, 7, 56) (2744,)\n",
      "block_14_project_BN 4 1 (39, 7, 7, 56) (7, 7, 56) (2744,)\n",
      "block_15_expand 1 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_15_expand_BN 4 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_15_depthwise 1 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_15_depthwise_BN 4 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_15_project 1 1 (39, 7, 7, 56) (7, 7, 56) (2744,)\n",
      "block_15_project_BN 4 1 (39, 7, 7, 56) (7, 7, 56) (2744,)\n",
      "block_16_expand 1 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_16_expand_BN 4 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_16_depthwise 1 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_16_depthwise_BN 4 1 (39, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_16_project 1 1 (39, 7, 7, 112) (7, 7, 112) (5488,)\n",
      "block_16_project_BN 4 1 (39, 7, 7, 112) (7, 7, 112) (5488,)\n",
      "Conv_1 1 1 (39, 7, 7, 1280) (7, 7, 1280) (62720,)\n",
      "Conv_1_bn 4 1 (39, 7, 7, 1280) (7, 7, 1280) (62720,)\n",
      "(5725552,)\n",
      "Starting Fold:  4\n",
      "38 38 38\n",
      "29 0.23684210526315785\n",
      "Conv1 1 1 (38, 112, 112, 16) (112, 112, 16) (200704,)\n",
      "bn_Conv1 4 1 (38, 112, 112, 16) (112, 112, 16) (200704,)\n",
      "expanded_conv_depthwise 1 1 (38, 112, 112, 16) (112, 112, 16) (200704,)\n",
      "expanded_conv_depthwise_BN 4 1 (38, 112, 112, 16) (112, 112, 16) (200704,)\n",
      "expanded_conv_project 1 1 (38, 112, 112, 8) (112, 112, 8) (100352,)\n",
      "expanded_conv_project_BN 4 1 (38, 112, 112, 8) (112, 112, 8) (100352,)\n",
      "block_1_expand 1 1 (38, 112, 112, 48) (112, 112, 48) (602112,)\n",
      "block_1_expand_BN 4 1 (38, 112, 112, 48) (112, 112, 48) (602112,)\n",
      "block_1_depthwise 1 1 (38, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_1_depthwise_BN 4 1 (38, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_1_project 1 1 (38, 56, 56, 8) (56, 56, 8) (25088,)\n",
      "block_1_project_BN 4 1 (38, 56, 56, 8) (56, 56, 8) (25088,)\n",
      "block_2_expand 1 1 (38, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_2_expand_BN 4 1 (38, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_2_depthwise 1 1 (38, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_2_depthwise_BN 4 1 (38, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_2_project 1 1 (38, 56, 56, 8) (56, 56, 8) (25088,)\n",
      "block_2_project_BN 4 1 (38, 56, 56, 8) (56, 56, 8) (25088,)\n",
      "block_3_expand 1 1 (38, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_3_expand_BN 4 1 (38, 56, 56, 48) (56, 56, 48) (150528,)\n",
      "block_3_depthwise 1 1 (38, 28, 28, 48) (28, 28, 48) (37632,)\n",
      "block_3_depthwise_BN 4 1 (38, 28, 28, 48) (28, 28, 48) (37632,)\n",
      "block_3_project 1 1 (38, 28, 28, 16) (28, 28, 16) (12544,)\n",
      "block_3_project_BN 4 1 (38, 28, 28, 16) (28, 28, 16) (12544,)\n",
      "block_4_expand 1 1 (38, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_4_expand_BN 4 1 (38, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_4_depthwise 1 1 (38, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_4_depthwise_BN 4 1 (38, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_4_project 1 1 (38, 28, 28, 16) (28, 28, 16) (12544,)\n",
      "block_4_project_BN 4 1 (38, 28, 28, 16) (28, 28, 16) (12544,)\n",
      "block_5_expand 1 1 (38, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_5_expand_BN 4 1 (38, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_5_depthwise 1 1 (38, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_5_depthwise_BN 4 1 (38, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_5_project 1 1 (38, 28, 28, 16) (28, 28, 16) (12544,)\n",
      "block_5_project_BN 4 1 (38, 28, 28, 16) (28, 28, 16) (12544,)\n",
      "block_6_expand 1 1 (38, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_6_expand_BN 4 1 (38, 28, 28, 96) (28, 28, 96) (75264,)\n",
      "block_6_depthwise 1 1 (38, 14, 14, 96) (14, 14, 96) (18816,)\n",
      "block_6_depthwise_BN 4 1 (38, 14, 14, 96) (14, 14, 96) (18816,)\n",
      "block_6_project 1 1 (38, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_6_project_BN 4 1 (38, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_7_expand 1 1 (38, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_7_expand_BN 4 1 (38, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_7_depthwise 1 1 (38, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_7_depthwise_BN 4 1 (38, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_7_project 1 1 (38, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_7_project_BN 4 1 (38, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_8_expand 1 1 (38, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_8_expand_BN 4 1 (38, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_8_depthwise 1 1 (38, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_8_depthwise_BN 4 1 (38, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_8_project 1 1 (38, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_8_project_BN 4 1 (38, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_9_expand 1 1 (38, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_9_expand_BN 4 1 (38, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_9_depthwise 1 1 (38, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_9_depthwise_BN 4 1 (38, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_9_project 1 1 (38, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_9_project_BN 4 1 (38, 14, 14, 24) (14, 14, 24) (4704,)\n",
      "block_10_expand 1 1 (38, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_10_expand_BN 4 1 (38, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_10_depthwise 1 1 (38, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_10_depthwise_BN 4 1 (38, 14, 14, 144) (14, 14, 144) (28224,)\n",
      "block_10_project 1 1 (38, 14, 14, 32) (14, 14, 32) (6272,)\n",
      "block_10_project_BN 4 1 (38, 14, 14, 32) (14, 14, 32) (6272,)\n",
      "block_11_expand 1 1 (38, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_11_expand_BN 4 1 (38, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_11_depthwise 1 1 (38, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_11_depthwise_BN 4 1 (38, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_11_project 1 1 (38, 14, 14, 32) (14, 14, 32) (6272,)\n",
      "block_11_project_BN 4 1 (38, 14, 14, 32) (14, 14, 32) (6272,)\n",
      "block_12_expand 1 1 (38, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_12_expand_BN 4 1 (38, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_12_depthwise 1 1 (38, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_12_depthwise_BN 4 1 (38, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_12_project 1 1 (38, 14, 14, 32) (14, 14, 32) (6272,)\n",
      "block_12_project_BN 4 1 (38, 14, 14, 32) (14, 14, 32) (6272,)\n",
      "block_13_expand 1 1 (38, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_13_expand_BN 4 1 (38, 14, 14, 192) (14, 14, 192) (37632,)\n",
      "block_13_depthwise 1 1 (38, 7, 7, 192) (7, 7, 192) (9408,)\n",
      "block_13_depthwise_BN 4 1 (38, 7, 7, 192) (7, 7, 192) (9408,)\n",
      "block_13_project 1 1 (38, 7, 7, 56) (7, 7, 56) (2744,)\n",
      "block_13_project_BN 4 1 (38, 7, 7, 56) (7, 7, 56) (2744,)\n",
      "block_14_expand 1 1 (38, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_14_expand_BN 4 1 (38, 7, 7, 336) (7, 7, 336) (16464,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "block_14_depthwise 1 1 (38, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_14_depthwise_BN 4 1 (38, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_14_project 1 1 (38, 7, 7, 56) (7, 7, 56) (2744,)\n",
      "block_14_project_BN 4 1 (38, 7, 7, 56) (7, 7, 56) (2744,)\n",
      "block_15_expand 1 1 (38, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_15_expand_BN 4 1 (38, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_15_depthwise 1 1 (38, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_15_depthwise_BN 4 1 (38, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_15_project 1 1 (38, 7, 7, 56) (7, 7, 56) (2744,)\n",
      "block_15_project_BN 4 1 (38, 7, 7, 56) (7, 7, 56) (2744,)\n",
      "block_16_expand 1 1 (38, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_16_expand_BN 4 1 (38, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_16_depthwise 1 1 (38, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_16_depthwise_BN 4 1 (38, 7, 7, 336) (7, 7, 336) (16464,)\n",
      "block_16_project 1 1 (38, 7, 7, 112) (7, 7, 112) (5488,)\n",
      "block_16_project_BN 4 1 (38, 7, 7, 112) (7, 7, 112) (5488,)\n",
      "Conv_1 1 1 (38, 7, 7, 1280) (7, 7, 1280) (62720,)\n",
      "Conv_1_bn 4 1 (38, 7, 7, 1280) (7, 7, 1280) (62720,)\n",
      "(5725552,)\n"
     ]
    }
   ],
   "source": [
    "out_r = []\n",
    "\n",
    "image_list_test = '../../data/pkl_mobile/'+p+'_'+str(model_name)+'_image_list_test.txt'\n",
    "with open(image_list_test,'w+') as f:\n",
    "    for i in im_test:\n",
    "        f.write(i+'\\n')\n",
    "\n",
    "kf = KFold(n_splits= k)\n",
    "fold = 1\n",
    "fp_name = '../../data/pkl_mobile/'+str(p)+'_no_lesion_performance.txt'\n",
    "fp = open(fp_name,'a+')\n",
    "for train_index, valid_index in kf.split(im_train):\n",
    "    print(\"Starting Fold: \", fold)\n",
    "    im_valid_train = [im_train[i] for i in train_index] \n",
    "    im_valid_test = [im_train[i] for i in valid_index]\n",
    "    \n",
    "    image_list_train = '../../data/pkl_mobile/'+p+'_image_list_train_fold_'+str(fold)+'.txt'\n",
    "    with open(image_list_train,'w+') as f:\n",
    "        for i in im_valid_train:\n",
    "            f.write(i+'\\n')\n",
    "    \n",
    "    image_list_valid = '../../data/pkl_mobile/'+p+'_image_list_valid_fold_'+str(fold)+'.txt'\n",
    "    with open(image_list_valid,'w+') as f:\n",
    "        for i in im_valid_test:\n",
    "            f.write(i+'\\n')\n",
    "    \n",
    "   \n",
    "    im_temp = preprocess_image_batch(im_valid_test,img_size=(256,256), crop_size=(224,224), color_mode=\"rgb\")\n",
    "    out = model.predict(im_temp,batch_size=64)\n",
    "\n",
    "    true_valid_wids = []\n",
    "    for i in im_valid_test:\n",
    "            temp1 = i.split('/')[4]\n",
    "            temp = temp1.split('.')[0].split('_')[2]\n",
    "            true_valid_wids.append(truth[int(temp)][1])\n",
    "    \n",
    "    predicted_valid_wids = []\n",
    "    for i in range(len(im_valid_test)):\n",
    "        #print im_list[i], pprint_output(out[i]), true_wids[i]\n",
    "        predicted_valid_wids.append(pprint_output(out[i]))\n",
    "        \n",
    "    count, error  = top5accuracy(true_valid_wids, predicted_valid_wids)\n",
    "    \n",
    "    fp.write(str(p)+' '+str(fold)+' '+str(count)+' '+str(len(im_valid_test))+' '+str(error)+'\\n')\n",
    "\n",
    "    \n",
    "    print(len(true_valid_wids), len(predicted_valid_wids), len(im_valid_test))\n",
    "    print(count, error)\n",
    "    \n",
    "    \n",
    "    #}\n",
    "    # Code snippet to get the activation values and saving information{\n",
    "    data = np.array([])\n",
    "\n",
    "    i = 0\n",
    "    result ={}\n",
    "    for layer in model.layers:\n",
    "        weights = layer.get_weights()\n",
    "        if len(weights) > 0:\n",
    "            activations = get_activations(model,i,im_temp)\n",
    "            if result.get(layer.name, None) is None:\n",
    "                result[layer.name] = activations[0]\n",
    "                temp = np.mean(activations[0], axis=0).ravel()\n",
    "                if layer.name != 'Logits':\n",
    "                    print(layer.name,len(weights),len(activations), activations[0].shape, np.mean(activations[0], axis=0).shape, temp.shape)\n",
    "                    data = np.append(data, temp)\n",
    "        i += 1\n",
    "    print(data.shape)\n",
    "    out_r.append(data)\n",
    "    fold += 1\n",
    "    \n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inanimate_fold_1_train_MobileNetV2 5725552\n",
      "inanimate_fold_2_train_MobileNetV2 5725552\n",
      "inanimate_fold_3_train_MobileNetV2 5725552\n",
      "inanimate_fold_4_train_MobileNetV2 5725552\n"
     ]
    }
   ],
   "source": [
    "#Saving all the data into pkl files\n",
    "for i in range(k):\n",
    "    name = p+'_fold_'+str(i+1)+'_train_'+model_name\n",
    "    out_data = out_r[i]\n",
    "    with open('../../data/pkl_mobile/'+name+'.pkl', 'wb') as f:\n",
    "        pickle.dump(out_data, f)\n",
    "    print(name, len(out_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506645"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "from keras import backend as K \n",
    "\n",
    "K.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
