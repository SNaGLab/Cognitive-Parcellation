{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 632 ms, sys: 221 ms, total: 854 ms\n",
      "Wall time: 835 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#To hide warnings export PYTHONWARNINGS=\"ignore\"\n",
    "#Imports{\n",
    "\n",
    "import os\n",
    "from os.path import dirname\n",
    "from os.path import join\n",
    "os.environ['KERAS_BACKEND'] = 'theano'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' #Cha\n",
    "\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy.misc import imread\n",
    "from scipy.misc import imresize\n",
    "from scipy.io import loadmat\n",
    "from scipy.interpolate import spline\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, MaxPooling2D, Input, ZeroPadding2D,merge,Lambda,Conv2D\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.models import Model\n",
    "from keras.utils.layer_utils import convert_all_kernels_in_model\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "from keras.engine import Layer\n",
    "from keras.layers.core import Lambda\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.layers.core import  Lambda\n",
    "from keras.regularizers import l2\n",
    "import cv2\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code snippet needed to read activation values from each layer of the pre-trained artificial neural networks\n",
    "def get_activations(model, layer, X_batch):\n",
    "    #keras.backend.function(inputs, outputs, updates=None)\n",
    "    get_activations = K.function([model.layers[0].input, K.learning_phase()], [model.layers[layer].output,])\n",
    "    #The learning phase flag is a bool tensor (0 = test, 1 = train)\n",
    "    activations = get_activations([X_batch,0])\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_paths, image_height=224, image_width=224,color_mode='rgb'):\n",
    "    \"\"\"resize images to the appropriate dimensions\n",
    "    :param image_width:\n",
    "    :param image_height:\n",
    "    :param image: image\n",
    "    :return: image\n",
    "    \"\"\"\n",
    "    img_list = []\n",
    "    \n",
    "    for im_path in image_paths:\n",
    "        image = imread(im_path, mode='RGB')\n",
    "        image = cv2.resize(image, (image_height, image_width))\n",
    "    \n",
    "        if color_mode == 'bgr':\n",
    "            image = image.transpose((2, 0, 1))\n",
    "        img_list.append(image)\n",
    "        \n",
    "    try:\n",
    "        img_batch = np.stack(img_list, axis=0)\n",
    "    except:\n",
    "        print(im_path)\n",
    "        raise ValueError('when img_size and crop_size are None, images'\n",
    "                ' in image_paths must have the same shapes.')\n",
    "    return img_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function to normalization across channels\n",
    "K.set_image_dim_ordering('th')\n",
    "def crosschannelnormalization(alpha=1e-4, k=2, beta=0.75, n=5, **kwargs):\n",
    "    \"\"\"\n",
    "    This is the function used for cross channel normalization in the original\n",
    "    Alexnet\n",
    "    \"\"\"\n",
    "    def f(X):\n",
    "        if K.image_dim_ordering()=='tf':\n",
    "            b, r, c, ch = X.get_shape()\n",
    "        else:\n",
    "            b, ch, r, c = X.shape\n",
    "\n",
    "        half = n // 2\n",
    "        square = K.square(X)\n",
    "        scale = k\n",
    "        if K.image_dim_ordering() == 'th':\n",
    "            extra_channels = K.spatial_2d_padding(K.permute_dimensions(square, (0, 2, 3, 1)), ((0,0),(half,half)))\n",
    "            extra_channels = K.permute_dimensions(extra_channels, (0, 3, 1, 2))\n",
    "            for i in range(n):\n",
    "                scale += alpha * extra_channels[:, i:i+ch, :, :]\n",
    "        if K.image_dim_ordering() == 'tf':\n",
    "            extra_channels = K.spatial_2d_padding(K.permute_dimensions(square, (0, 3, 1, 2)), (half, 0))\n",
    "            extra_channels = K.permute_dimensions(extra_channels, (0, 2, 3, 1))\n",
    "            for i in range(n):\n",
    "                scale += alpha * extra_channels[:, :, :, i:i+int(ch)]\n",
    "        scale = scale ** beta\n",
    "        return X / scale\n",
    "\n",
    "\n",
    "    return Lambda(f, output_shape=lambda input_shape: input_shape, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Function to split tensor\n",
    "def splittensor(axis=1, ratio_split=1, id_split=0, **kwargs):\n",
    "    def f(X):\n",
    "        div = K.shape(X)[axis] // ratio_split\n",
    "\n",
    "        if axis == 0:\n",
    "            output = X[id_split*div:(id_split+1)*div, :, :, :]\n",
    "        elif axis == 1:\n",
    "            output = X[:, id_split*div:(id_split+1)*div, :, :]\n",
    "        elif axis == 2:\n",
    "            output = X[:, :, id_split*div:(id_split+1)*div, :]\n",
    "        elif axis == 3:\n",
    "            output = X[:, :, :, id_split*div:(id_split+1)*div]\n",
    "        else:\n",
    "            raise ValueError(\"This axis is not possible\")\n",
    "        return output\n",
    "\n",
    "    def g(input_shape):\n",
    "        output_shape = list(input_shape)\n",
    "        output_shape[axis] = output_shape[axis] // ratio_split\n",
    "        return tuple(output_shape)\n",
    "\n",
    "\n",
    "    return Lambda(f, output_shape=lambda input_shape: g(input_shape), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alexnet layer architecture class\n",
    "def AlexNet(img_shape=(3, 227, 227), n_classes=1000, l2_reg=0.,weights_path=None, lambda_mask=None):\n",
    "\n",
    "    dim_ordering = K.image_dim_ordering()\n",
    "    print dim_ordering\n",
    "    if dim_ordering == 'th':\n",
    "        batch_index = 0\n",
    "        channel_index = 1\n",
    "        row_index = 2\n",
    "        col_index = 3\n",
    "    if dim_ordering == 'tf':\n",
    "        batch_index = 0\n",
    "        channel_index = 3\n",
    "        row_index = 1\n",
    "        col_index = 2\n",
    "        \n",
    "    \n",
    "    inputs = Input(img_shape)\n",
    "\n",
    "    conv_1 = Convolution2D(96, 11, 11, subsample=(4, 4), activation='relu',\n",
    "                           name='conv_1', W_regularizer=l2(l2_reg))(inputs)\n",
    "\n",
    "    if lambda_mask is not None:\n",
    "        conv_1_mask  = np.reshape(lambda_mask[0:290400], (96,55,55))\n",
    "    else:\n",
    "        conv_1_mask = np.ones(shape=((96, 55, 55)))\n",
    "    \n",
    "    conv_1_mask  = K.variable(conv_1_mask)\n",
    "    conv_1_lambda = Lambda(lambda x: x * conv_1_mask)(conv_1)\n",
    "\n",
    "    conv_2 = MaxPooling2D((3, 3), strides=(2, 2))(conv_1_lambda)\n",
    "    conv_2 = crosschannelnormalization(name=\"convpool_1\")(conv_2)\n",
    "    conv_2 = ZeroPadding2D((2, 2))(conv_2)\n",
    "    conv_2 = merge([\n",
    "        Convolution2D(128, 5, 5, activation=\"relu\", name='conv_2_'+str(i+1),\n",
    "                      W_regularizer=l2(l2_reg))(\n",
    "            splittensor(axis=channel_index, ratio_split=2, id_split=i)(conv_2)\n",
    "        ) for i in range(2)], mode='concat', concat_axis=channel_index, name=\"conv_2\")\n",
    "\n",
    "    if lambda_mask is not None:\n",
    "        conv_2_mask  = np.reshape(lambda_mask[290400:477024],(256, 27, 27) )\n",
    "    else:\n",
    "        conv_2_mask = np.ones(shape=((256, 27, 27)))\n",
    "        \n",
    "    conv_2_mask = K.variable(conv_2_mask)\n",
    "    conv_2_lambda = Lambda(lambda x: x * conv_2_mask)(conv_2)\n",
    "\n",
    "    conv_3 = MaxPooling2D((3, 3), strides=(2, 2))(conv_2_lambda)\n",
    "    conv_3 = crosschannelnormalization()(conv_3)\n",
    "    conv_3 = ZeroPadding2D((1, 1))(conv_3)\n",
    "    conv_3 = Convolution2D(384, 3, 3, activation='relu', name='conv_3',\n",
    "                           W_regularizer=l2(l2_reg))(conv_3)\n",
    "\n",
    "    if lambda_mask is not None:\n",
    "        conv_3_mask  = np.reshape(lambda_mask[477024:541920],(384, 13, 13))\n",
    "    else:\n",
    "        conv_3_mask = np.ones(shape=((384, 13, 13)))\n",
    "    \n",
    "    conv_3_mask = K.variable(conv_3_mask)\n",
    "    conv_3_lambda = Lambda(lambda x: x * conv_3_mask)(conv_3)\n",
    "\n",
    "    conv_4 = ZeroPadding2D((1, 1))(conv_3_lambda)\n",
    "    conv_4 = merge([\n",
    "        Convolution2D(192, 3, 3, activation=\"relu\", name='conv_4_'+str(i+1),\n",
    "                      W_regularizer=l2(l2_reg))(\n",
    "            splittensor(axis=channel_index, ratio_split=2, id_split=i)(conv_4)\n",
    "        ) for i in range(2)], mode='concat', concat_axis=channel_index, name=\"conv_4\")\n",
    "\n",
    "    if lambda_mask is not None:\n",
    "        conv_4_mask  = np.reshape(lambda_mask[541920:606816],(384, 13, 13))\n",
    "    else:\n",
    "        conv_4_mask = np.ones(shape=((384, 13, 13)))\n",
    "        \n",
    "    conv_4_mask = K.variable(conv_4_mask)\n",
    "    conv_4_lambda = Lambda(lambda x: x * conv_4_mask)(conv_4)\n",
    "\n",
    "    conv_5 = ZeroPadding2D((1, 1))(conv_4_lambda)\n",
    "    conv_5 = merge([\n",
    "        Convolution2D(128, 3, 3, activation=\"relu\", name='conv_5_'+str(i+1),\n",
    "                      W_regularizer=l2(l2_reg))(\n",
    "            splittensor(axis=channel_index, ratio_split=2, id_split=i)(conv_5)\n",
    "        ) for i in range(2)], mode='concat', concat_axis=channel_index, name=\"conv_5\")\n",
    "\n",
    "    if lambda_mask is not None:\n",
    "        conv_5_mask  = np.reshape(lambda_mask[606816:650080],(256, 13, 13))\n",
    "    else:\n",
    "        conv_5_mask = np.ones(shape=((256, 13, 13)))\n",
    "    \n",
    "    conv_5_mask = K.variable(conv_5_mask)\n",
    "    conv_5_lambda = Lambda(lambda x: x * conv_5_mask)(conv_5)\n",
    "\n",
    "    dense_1 = MaxPooling2D((3, 3), strides=(2, 2), name=\"convpool_5\")(conv_5_lambda)\n",
    "\n",
    "    dense_1 = Flatten(name=\"flatten\")(dense_1)\n",
    "    dense_1 = Dense(4096, activation='relu', name='dense_1',\n",
    "                    W_regularizer=l2(l2_reg))(dense_1)\n",
    "\n",
    "    if lambda_mask is not None:\n",
    "        dense_1_mask  = np.reshape(lambda_mask[650080:654176],(4096,))\n",
    "    else:\n",
    "        dense_1_mask = np.ones(shape=((4096,)))\n",
    "    \n",
    "    \n",
    "    dense_1_mask = K.variable(dense_1_mask)\n",
    "    dense_1_lambda = Lambda(lambda x: x * dense_1_mask)(dense_1)\n",
    "\n",
    "    dense_2 = Dropout(0.5)(dense_1_lambda)\n",
    "    dense_2 = Dense(4096, activation='relu', name='dense_2',\n",
    "                    W_regularizer=l2(l2_reg))(dense_2)\n",
    "\n",
    "    if lambda_mask is not None:\n",
    "        dense_2_mask  = np.reshape(lambda_mask[654176:658272],(4096,))\n",
    "    else:\n",
    "        dense_2_mask = np.ones(shape=((4096,)))\n",
    "    \n",
    "    dense_2_mask = K.variable(dense_2_mask)\n",
    "    dense_2_lambda = Lambda(lambda x: x * dense_2_mask)(dense_2)\n",
    "\n",
    "    dense_3 = Dropout(0.5)(dense_2_lambda)\n",
    "    if n_classes == 1000:\n",
    "        dense_3 = Dense(n_classes, name='dense_3',\n",
    "                        W_regularizer=l2(l2_reg))(dense_3)\n",
    "    else:\n",
    "        # We change the name so when loading the weights_file from a\n",
    "        # Imagenet pretrained model does not crash\n",
    "        dense_3 = Dense(n_classes, name='dense_3_new',\n",
    "                        W_regularizer=l2(l2_reg))(dense_3)\n",
    "\n",
    "\n",
    "    prediction = Activation(\"softmax\", name=\"softmax\")(dense_3)\n",
    "\n",
    "    model = Model(input=inputs, output=prediction)\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the details of all the 1000 classes and the function to conver the synset id to words{\n",
    "meta_clsloc_file = '../../data/meta_clsloc.mat'\n",
    "synsets = loadmat(meta_clsloc_file)['synsets'][0]\n",
    "synsets_imagenet_sorted = sorted([(int(s[0]), str(s[1][0])) for s in synsets[:1000]],key=lambda v: v[1])\n",
    "corr = {}\n",
    "for j in range(1000):\n",
    "    corr[synsets_imagenet_sorted[j][0]] = j\n",
    "\n",
    "corr_inv = {}\n",
    "for j in range(1, 1001):\n",
    "    corr_inv[corr[j]] = j\n",
    "\n",
    "def id_to_words(id_):\n",
    "    return synsets[corr_inv[id_] - 1][2][0]\n",
    "\n",
    "def pprint_output(out, n_max_synsets=10):\n",
    "    wids = []\n",
    "    best_ids = out.argsort()[::-1][:10]\n",
    "    for u in best_ids:\n",
    "        wids.append(str(synsets[corr_inv[u] - 1][1][0]))\n",
    "    #print('%.2f' % round(100 * out[u], 2) + ' : ' + id_to_words(u)+' '+ str(synsets[corr_inv[u] - 1][1][0]))\n",
    "    return wids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code snippet to load the ground truth labels to measure the performance{\n",
    "truth = {}\n",
    "with open('../../data/ILSVRC2014_clsloc_validation_ground_truth.txt') as f:\n",
    "    line_num = 1\n",
    "    for line in f.readlines():\n",
    "        ind_ = int(line)\n",
    "        temp  = None\n",
    "        for i in synsets_imagenet_sorted:\n",
    "            if i[0] == ind_:\n",
    "                temp = i\n",
    "        #print ind_,temp\n",
    "        if temp != None:\n",
    "            truth[line_num] = temp\n",
    "        else:\n",
    "            print '##########', ind_\n",
    "            pass\n",
    "        line_num += 1\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to predict the top 5 accuracy\n",
    "def top5accuracy(true, predicted):\n",
    "    assert len(true) == len(predicted)\n",
    "    result = []\n",
    "    flag  = 0\n",
    "    for i in range(len(true)):\n",
    "        flag  = 0\n",
    "        temp = true[i]\n",
    "        for j in predicted[i]:\n",
    "            if j == temp:\n",
    "                flag = 1\n",
    "                break\n",
    "        if flag == 1:\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(0)\n",
    "    counter = 0.\n",
    "    for i in result:\n",
    "        if i == 1:\n",
    "            counter += 1.\n",
    "    error = 1.0 - counter/float(len(result))\n",
    "    #print len(np.where(np.asarray(result) == 1)[0])\n",
    "    return len(np.where(np.asarray(result) == 1)[0]), error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "#Testing on test data{\n",
    "data_path = '../../data/pkl/'\n",
    "classes = ['animate','inanimate']\n",
    "\n",
    "result = {}\n",
    "\n",
    "with open(data_path+classes[0]+'_test.pkl') as f:\n",
    "    X_fold = pickle.load(f)\n",
    "with open(data_path+classes[1]+'_test.pkl') as f:\n",
    "    y_fold = pickle.load(f)\n",
    "\n",
    "X = np.column_stack((X_fold,y_fold))  \n",
    "if os.path.exists('../../data/pkl/kmeans_first_test.pickle'):\n",
    "    with open('../../data/pkl/kmeans_first_test.pickle',\"rb\") as f:\n",
    "        X_new,pred_kmeans,kmeans = pickle.load(f)\n",
    "else:   \n",
    "   \n",
    "    kmeans = MiniBatchKMeans(n_clusters=65827,\n",
    "                             random_state=0,\n",
    "                             batch_size=6,\n",
    "                             max_iter=10).fit(X)\n",
    "    #print kmeans.cluster_centers_\n",
    "    pred_kmeans = kmeans.predict(X)\n",
    "    X_new = kmeans.cluster_centers_\n",
    "\n",
    "\n",
    "#DO CLUSTERING AND GET CLUSTERS\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import Birch\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "import genieclust\n",
    "import hdbscan\n",
    "import smm\n",
    "\n",
    "j = 22 #Set this value from scree plot!\n",
    "method = 'GMM'\n",
    "print j\n",
    "#clf = hdbscan.HDBSCAN(min_cluster_size=j, gen_min_span_tree=True)\n",
    "#clf = DBSCAN(eps=5.443)\n",
    "#clf = KMeans(n_clusters=j,random_state=143)\n",
    "#clf= SpectralClustering(n_clusters=j,random_state=143)\n",
    "#clf =  AgglomerativeClustering(n_clusters=j, linkage='ward')\n",
    "#clf = Birch(branching_factor=50, n_clusters=j, threshold=0.5,compute_labels=True)\n",
    "clf = GaussianMixture(n_components=j, covariance_type='full',random_state=143)\n",
    "#clf= genieclust.genie.Genie(n_clusters=j)\n",
    "#clf= smm.SMM(n_components=j, covariance_type='full', random_state=143, tol=1e-12,min_covar=1e-6, n_iter=1000, n_init=1, params='wmcd', init_params='wmcd')\n",
    "temp = clf.fit(X_new)\n",
    "y_pred = clf.predict(X_new)\n",
    "#y_pred = clf.fit_predict(X_new)\n",
    "print set(y_pred)\n",
    "#Z = clf.predict(X)\n",
    "\n",
    "for label in set(y_pred):\n",
    "    print('Cluster: ',j,'Label: ', label)\n",
    "\n",
    "    #Lesioning and measuring performance\n",
    "    #pred = clf.fit_predict(X_new)\n",
    "    temp = clf.fit(X_new)\n",
    "    pred = clf.predict(X_new)\n",
    "    loc = np.where(pred==label)\n",
    "    loc_temp = kmeans.predict(X_new[loc[0]])\n",
    "    loc_new =[]\n",
    "    for entry in set(loc_temp):\n",
    "        temp = np.where(pred_kmeans==entry)[0]\n",
    "        loc_new.extend(temp)\n",
    "\n",
    "    lambda_mask = np.ones(shape=((658272,)))\n",
    "    lambda_mask[loc_new] = 0.\n",
    "\n",
    "    #plt.scatter(X[:,0],X[:,1], c=y_pred) \n",
    "\n",
    "    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model = AlexNet(weights_path=\"../../data/weights/alexnet_weights.h5\",lambda_mask=lambda_mask)\n",
    "    model.compile(optimizer=sgd, loss='mse')\n",
    "\n",
    "    flag = 0\n",
    "    dprime = 0.\n",
    "    for p in classes:\n",
    "        im_valid_test = []\n",
    "        image_list_valid = '../../data/pkl/'+p+'_image_list_test.txt'\n",
    "        with open(image_list_valid,'rb') as f:\n",
    "            for line in f.readlines():\n",
    "                im_valid_test.append(line.strip('\\n'))\n",
    "        im_temp = preprocess_image(im_valid_test,227,227, color_mode=\"bgr\")\n",
    "        out = model.predict(im_temp,batch_size=64)\n",
    "        \n",
    "        true_valid_wids = []\n",
    "        for i in im_valid_test:\n",
    "                temp1 = i.split('/')[4]\n",
    "                temp = temp1.split('.')[0].split('_')[2]\n",
    "                true_valid_wids.append(truth[int(temp)][1])\n",
    "\n",
    "        predicted_valid_wids = []\n",
    "        for i in range(len(im_valid_test)):\n",
    "            #print im_list[i], pprint_output(out[i]), true_wids[i]\n",
    "            predicted_valid_wids.append(pprint_output(out[i]))\n",
    "\n",
    "        count, error  = top5accuracy(true_valid_wids, predicted_valid_wids)\n",
    "\n",
    "        print str(p)+' '+str(count)+' '+str(len(im_valid_test))+' '+str(error)+' '+str(1-error)\n",
    "\n",
    "        if flag == 0:\n",
    "            dprime = error\n",
    "            flag = 1\n",
    "        else:\n",
    "            dprime -= error\n",
    "\n",
    "    result[label] = dprime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result.values(),X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_temp = []\n",
    "for item in y_pred:\n",
    "    z_temp.append(result[item])\n",
    "print(len(z_temp),len(X_new))\n",
    "loc_z = kmeans.predict(X_new)\n",
    "z = np.ones(shape=((658272,)))\n",
    "for i in range(len(loc_z)):\n",
    "    temp = np.where(pred_kmeans==loc_z[i])[0]\n",
    "    z[temp] = z_temp[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X[:,0]\n",
    "y = X[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Density Plot for Animate/Inanimate\n",
    "\n",
    "print(x.shape,y.shape,z.shape)\n",
    "fig, ax = plt.subplots()\n",
    "cs = ax.scatter(x, y, c=z, s=10,cmap='coolwarm')\n",
    "cbar = fig.colorbar(cs)\n",
    "lims = [\n",
    "    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "]\n",
    "ax.plot(lims, lims, 'k-', alpha=0.75)\n",
    "plt.xlabel('Animate')\n",
    "plt.ylabel('Inanimate')\n",
    "plt.title('Performance Impact - Density plot')\n",
    "plt.savefig('../../results/scree/'+str(method)+'_results_density.png', format='png',dpi=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print result.values().index(max(result.values())), result.values().index(min(result.values()))\n",
    "ana = int(result.values().index(max(result.values())))\n",
    "ina = int(result.values().index(min(result.values())))\n",
    "print result[ana], -1*(result[ina])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "label_loc = np.where(pred==ana)[0]\n",
    "#print len(label_loc)\n",
    "Zx = []\n",
    "Zy = []\n",
    "for i in range(len(label_loc)):\n",
    "    temp = np.where(pred_kmeans==label_loc[i])[0]\n",
    "    for i in temp:\n",
    "        Zx.append(X[i][0])\n",
    "        Zy.append(X[i][1])\n",
    "#print len(np.where(Z!=0)[0])\n",
    "#print Z\n",
    "sc = plt.scatter(Zx,Zy) \n",
    "plt.xlim([-2.2,300])\n",
    "plt.ylim([-2.2,300])\n",
    "lims = [\n",
    "    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "]\n",
    "\n",
    "# now plot both limits against eachother\n",
    "ax.plot(lims, lims, 'k-', alpha=0.75, zorder=1)\n",
    "plt.xlabel('Animate')\n",
    "plt.ylabel('Inanimate')\n",
    "plt.title('Most selective cluster for animate class')\n",
    "plt.savefig('../../results/scree/'+str(method)+'_results_ana.png', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "label_loc = np.where(pred==ina)[0]\n",
    "print len(label_loc)\n",
    "Zx = []\n",
    "Zy = []\n",
    "for i in range(len(label_loc)):\n",
    "    temp = np.where(pred_kmeans==label_loc[i])[0]\n",
    "    for i in temp:\n",
    "        Zx.append(X[i][0])\n",
    "        Zy.append(X[i][1])\n",
    "sc = plt.scatter(Zx,Zy) \n",
    "plt.xlim([-2.2,300])\n",
    "plt.ylim([-2.2,300])\n",
    "lims = [\n",
    "    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "]\n",
    "\n",
    "# now plot both limits against eachother\n",
    "ax.plot(lims, lims, 'k-', alpha=0.75, zorder=1)\n",
    "plt.xlabel('Animate')\n",
    "plt.ylabel('Inanimate')\n",
    "plt.title('Most selective cluster for inanimate class')\n",
    "plt.savefig('../../results/scree/'+str(method)+'_results_ina.png', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_loc = np.where(pred==ana)[0]\n",
    "Z = []\n",
    "for i in range(len(label_loc)):\n",
    "    temp = np.where(pred_kmeans==label_loc[i])[0]\n",
    "    for i in temp:\n",
    "        Z.append(i)\n",
    "print(max(Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_loc = np.where(pred==ana)[0]\n",
    "Z = []\n",
    "for i in range(len(label_loc)):\n",
    "    temp = np.where(pred_kmeans==label_loc[i])[0]\n",
    "    for i in temp:\n",
    "        Z.append(i)\n",
    "X = np.arange(7)\n",
    "Y = np.zeros((7,))\n",
    "\n",
    "for i in Z:\n",
    "    if i in range(0,290400): \n",
    "        Y[0] += 1\n",
    "    elif i in range(290400,477024):\n",
    "        Y[1] += 1\n",
    "    elif i in range(477024,541920):\n",
    "        Y[2] += 1\n",
    "    elif i in range(541920,606816):\n",
    "        Y[3] += 1\n",
    "    elif i in range(606816,650080):\n",
    "        Y[4] += 1\n",
    "    elif i in range(650080,654176):\n",
    "        Y[5] += 1\n",
    "    elif i in range(654176,658272):\n",
    "        Y[6] += 1\n",
    "    else:\n",
    "        print i\n",
    "\n",
    "Y[0] = float(Y[0]) /290400\n",
    "Y[1] = float(Y[0]) / 196624\n",
    "Y[2] = float(Y[2]) / 64896\n",
    "Y[3] = float(Y[3]) / 64896\n",
    "Y[4] = float(Y[4]) /43264\n",
    "Y[5] = float(Y[5]) /4096\n",
    "Y[6] = float(Y[6]) /4096\n",
    "\n",
    "plt.ylim([0,1.])\n",
    "rect = plt.bar(X,Y)\n",
    "plt.xticks(X, ('conv_1', 'conv_2', 'conv_3', 'conv_4','conv_5','fc1','fc2'))\n",
    "plt.ylabel('Relative count of neurons')\n",
    "plt.title('Neurons from the animate cluster')\n",
    "#autolabel(rect)\n",
    "plt.savefig('../../results/scree/'+str(method)+'_results_ana_hist_alt.png', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_loc = np.where(pred==ina)[0]\n",
    "Z = []\n",
    "for i in range(len(label_loc)):\n",
    "    temp = np.where(pred_kmeans==label_loc[i])[0]\n",
    "    for i in temp:\n",
    "        Z.append(i)\n",
    "X = np.arange(7)\n",
    "Y = np.zeros((7,))\n",
    "\n",
    "for i in Z:\n",
    "    if i in range(0,290400): \n",
    "        Y[0] += 1\n",
    "    elif i in range(290400,477024):\n",
    "        Y[1] += 1\n",
    "    elif i in range(477024,541920):\n",
    "        Y[2] += 1\n",
    "    elif i in range(541920,606816):\n",
    "        Y[3] += 1\n",
    "    elif i in range(606816,650080):\n",
    "        Y[4] += 1\n",
    "    elif i in range(650080,654176):\n",
    "        Y[5] += 1\n",
    "    elif i in range(654176,658272):\n",
    "        Y[6] += 1\n",
    "    else:\n",
    "        print i\n",
    "\n",
    "Y[0] = float(Y[0]) /290400\n",
    "Y[1] = float(Y[0]) / 196624\n",
    "Y[2] = float(Y[2]) / 64896\n",
    "Y[3] = float(Y[3]) / 64896\n",
    "Y[4] = float(Y[4]) /43264\n",
    "Y[5] = float(Y[5]) /4096\n",
    "Y[6] = float(Y[6]) /4096\n",
    "\n",
    "plt.ylim([0,1.])\n",
    "rect = plt.bar(X,Y)\n",
    "plt.ylabel('Relative count of neurons')\n",
    "plt.title('Neurons from the inanimate cluster')\n",
    "plt.xticks(X, ('conv_1', 'conv_2', 'conv_3', 'conv_4','conv_5','fc1','fc2'))\n",
    "#autolabel(rect)\n",
    "plt.savefig('../../results/scree/'+str(method)+'_results_ina_hist_alt.png', format='png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_info = {}\n",
    "#Comparing Layer lesions\n",
    "classes = ['animate','inanimate']\n",
    "%time\n",
    "for label in [ana,ina]:\n",
    "    layer_info[label] = {}\n",
    "    for layer in [1,2,3,4,5,6,7]:\n",
    "        if layer == 1:\n",
    "            start = 0\n",
    "            end = 290400\n",
    "        elif layer == 2:\n",
    "            start = 290400\n",
    "            end = 477024\n",
    "        elif layer == 3:\n",
    "            start = 477024\n",
    "            end = 541920\n",
    "        elif layer == 4:\n",
    "            start = 541920\n",
    "            end = 606816\n",
    "        elif layer == 5:\n",
    "            start = 606816\n",
    "            end = 650080\n",
    "        elif layer == 6:\n",
    "            start = 650080\n",
    "            end = 654176\n",
    "        elif layer == 7:\n",
    "            start = 654177\n",
    "            end = 658272\n",
    "    \n",
    "        layer_info[label][layer] = {}\n",
    "    \n",
    "        #No lesion\n",
    "        #print('No-lesioning')\n",
    "        #print('Label:',label)\n",
    "        #print('Layer:',layer)\n",
    "\n",
    "        pred = clf.predict(X_new)\n",
    "        lambda_mask = np.ones(shape=((658272,)))\n",
    "       \n",
    "\n",
    "        sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "        model = AlexNet(weights_path=\"../../data/weights/alexnet_weights.h5\",lambda_mask=lambda_mask)\n",
    "        model.compile(optimizer=sgd, loss='mse')\n",
    "\n",
    "        flag = 0\n",
    "        dprime = 0.\n",
    "        for p in classes:\n",
    "            im_valid_test = []\n",
    "            image_list_valid = '../../data/pkl/'+p+'_image_list_test.txt'\n",
    "            with open(image_list_valid,'rb') as f:\n",
    "                for line in f.readlines():\n",
    "                    im_valid_test.append(line.strip('\\n'))\n",
    "            im_temp = preprocess_image(im_valid_test,227,227, color_mode=\"bgr\")\n",
    "            out = model.predict(im_temp,batch_size=64)\n",
    "\n",
    "            true_valid_wids = []\n",
    "            for i in im_valid_test:\n",
    "                    temp1 = i.split('/')[4]\n",
    "                    temp = temp1.split('.')[0].split('_')[2]\n",
    "                    true_valid_wids.append(truth[int(temp)][1])\n",
    "\n",
    "            predicted_valid_wids = []\n",
    "            for i in range(len(im_valid_test)):\n",
    "                #print im_list[i], pprint_output(out[i]), true_wids[i]\n",
    "                predicted_valid_wids.append(pprint_output(out[i]))\n",
    "\n",
    "            count, error  = top5accuracy(true_valid_wids, predicted_valid_wids)\n",
    "\n",
    "            print str(p)+' '+str(count)+' '+str(len(im_valid_test))+' '+str(error)+' '+str(1-error)\n",
    "              \n",
    "            if flag == 0:\n",
    "                dprime = error\n",
    "                flag = 1\n",
    "            else:\n",
    "                dprime -= error\n",
    "        print('Layer: ',layer,'Label: ', label)\n",
    "        print('No lesion: ',dprime)\n",
    "        layer_info[label][layer]['no'] = dprime\n",
    "        \n",
    "        \n",
    "        #Before lesion\n",
    "        #print('Pre-layer-lesioning')\n",
    "        #print('Label:',label)\n",
    "        #print('Layer:',layer)\n",
    "\n",
    "        pred = clf.predict(X_new)\n",
    "        loc = np.where(pred==label)[0]\n",
    "        loc_new =[]\n",
    "        for i in range(len(loc)):\n",
    "            temp = np.where(pred_kmeans==loc[i])[0]\n",
    "            loc_new.extend(temp)\n",
    "\n",
    "        lambda_mask = np.ones(shape=((658272,)))\n",
    "        lambda_mask[loc_new] = 0.\n",
    "        print('pre-loc', len(loc_new))\n",
    "        sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "        model = AlexNet(weights_path=\"../../data/weights/alexnet_weights.h5\",lambda_mask=lambda_mask)\n",
    "        model.compile(optimizer=sgd, loss='mse')\n",
    "\n",
    "        flag = 0\n",
    "        dprime = 0.\n",
    "        for p in classes:\n",
    "            im_valid_test = []\n",
    "            image_list_valid = '../../data/pkl/'+p+'_image_list_test.txt'\n",
    "            with open(image_list_valid,'rb') as f:\n",
    "                for line in f.readlines():\n",
    "                    im_valid_test.append(line.strip('\\n'))\n",
    "            im_temp = preprocess_image(im_valid_test,227,227, color_mode=\"bgr\")\n",
    "            out = model.predict(im_temp,batch_size=64)\n",
    "\n",
    "            true_valid_wids = []\n",
    "            for i in im_valid_test:\n",
    "                    temp1 = i.split('/')[4]\n",
    "                    temp = temp1.split('.')[0].split('_')[2]\n",
    "                    true_valid_wids.append(truth[int(temp)][1])\n",
    "\n",
    "            predicted_valid_wids = []\n",
    "            for i in range(len(im_valid_test)):\n",
    "                #print im_list[i], pprint_output(out[i]), true_wids[i]\n",
    "                predicted_valid_wids.append(pprint_output(out[i]))\n",
    "\n",
    "            count, error  = top5accuracy(true_valid_wids, predicted_valid_wids)\n",
    "\n",
    "            print str(p)+' '+str(count)+' '+str(len(im_valid_test))+' '+str(error)+' '+str(1-error)\n",
    "\n",
    "            if flag == 0:\n",
    "                dprime = error\n",
    "                flag = 1\n",
    "            else:\n",
    "                dprime -= error\n",
    "        print('Cluster Only: ',dprime)\n",
    "        layer_info[label][layer]['pre'] = dprime   \n",
    "             \n",
    "            \n",
    "        #After Lesion\n",
    "       # print('Post-layer-lesioning')\n",
    "        #print('Label:',label)\n",
    "        #print('Layer:',layer)\n",
    "        pred = clf.predict(X_new)\n",
    "        loc = np.where(pred==label)[0]\n",
    "        loc_new =[]\n",
    "        for i in range(len(loc)):\n",
    "            temp = np.where(pred_kmeans==loc[i])[0]\n",
    "            temp2 = temp[np.asarray(np.where((temp >end) | (temp <=start))[0])]\n",
    "            #print(len(temp), len(temp2))\n",
    "            loc_new.extend(temp2)\n",
    "\n",
    "\n",
    "        lambda_mask = np.ones(shape=((658272,)))\n",
    "        lambda_mask[loc_new] = 0.\n",
    "        print('post-loc', len(loc_new))\n",
    "        sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "        model = AlexNet(weights_path=\"../../data/weights/alexnet_weights.h5\",lambda_mask=lambda_mask)\n",
    "        model.compile(optimizer=sgd, loss='mse')\n",
    "\n",
    "        flag = 0\n",
    "        dprime = 0.\n",
    "        for p in classes:\n",
    "            im_valid_test = []\n",
    "            image_list_valid = '../../data/pkl/'+p+'_image_list_test.txt'\n",
    "            with open(image_list_valid,'rb') as f:\n",
    "                for line in f.readlines():\n",
    "                    im_valid_test.append(line.strip('\\n'))\n",
    "            im_temp = preprocess_image(im_valid_test,227,227, color_mode=\"bgr\")\n",
    "            out = model.predict(im_temp,batch_size=64)\n",
    "\n",
    "            true_valid_wids = []\n",
    "            for i in im_valid_test:\n",
    "                    temp1 = i.split('/')[4]\n",
    "                    temp = temp1.split('.')[0].split('_')[2]\n",
    "                    true_valid_wids.append(truth[int(temp)][1])\n",
    "\n",
    "            predicted_valid_wids = []\n",
    "            for i in range(len(im_valid_test)):\n",
    "                #print im_list[i], pprint_output(out[i]), true_wids[i]\n",
    "                predicted_valid_wids.append(pprint_output(out[i]))\n",
    "\n",
    "            count, error  = top5accuracy(true_valid_wids, predicted_valid_wids)\n",
    "\n",
    "            print str(p)+' '+str(count)+' '+str(len(im_valid_test))+' '+str(error)+' '+str(1-error)\n",
    "\n",
    "            if flag == 0:\n",
    "                dprime = error\n",
    "                flag = 1\n",
    "            else:\n",
    "                dprime -= error\n",
    "        print('Cluster - layer: ',dprime)\n",
    "        layer_info[label][layer]['post'] = dprime\n",
    "        \n",
    "        \n",
    "         #Random Lesion\n",
    "       # print('Post-layer-lesioning')\n",
    "        #print('Label:',label)\n",
    "        #print('Layer:',layer)\n",
    "        pred = clf.predict(X_new)\n",
    "        loc = np.where(pred==label)[0]\n",
    "        loc_new =[]\n",
    "        for i in range(len(loc)):\n",
    "            temp = np.where(pred_kmeans==loc[i])[0]\n",
    "            temp2 = temp[np.asarray(np.where((temp >end) | (temp <=start))[0])]\n",
    "            #print(len(temp), len(temp2))\n",
    "            loc_new.extend(temp2)\n",
    "\n",
    "        loc_new2 = np.random.randint(start,end,len(loc_new))\n",
    "        lambda_mask = np.ones(shape=((658272,)))\n",
    "        lambda_mask[loc_new2] = 0.\n",
    "        print('post-rand-loc', len(loc_new))\n",
    "        sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "        model = AlexNet(weights_path=\"../../data/weights/alexnet_weights.h5\",lambda_mask=lambda_mask)\n",
    "        model.compile(optimizer=sgd, loss='mse')\n",
    "\n",
    "        flag = 0\n",
    "        dprime = 0.\n",
    "        for p in classes:\n",
    "            im_valid_test = []\n",
    "            image_list_valid = '../../data/pkl/'+p+'_image_list_test.txt'\n",
    "            with open(image_list_valid,'rb') as f:\n",
    "                for line in f.readlines():\n",
    "                    im_valid_test.append(line.strip('\\n'))\n",
    "            im_temp = preprocess_image(im_valid_test,227,227, color_mode=\"bgr\")\n",
    "            out = model.predict(im_temp,batch_size=64)\n",
    "\n",
    "            true_valid_wids = []\n",
    "            for i in im_valid_test:\n",
    "                    temp1 = i.split('/')[4]\n",
    "                    temp = temp1.split('.')[0].split('_')[2]\n",
    "                    true_valid_wids.append(truth[int(temp)][1])\n",
    "\n",
    "            predicted_valid_wids = []\n",
    "            for i in range(len(im_valid_test)):\n",
    "                #print im_list[i], pprint_output(out[i]), true_wids[i]\n",
    "                predicted_valid_wids.append(pprint_output(out[i]))\n",
    "\n",
    "            count, error  = top5accuracy(true_valid_wids, predicted_valid_wids)\n",
    "\n",
    "            print str(p)+' '+str(count)+' '+str(len(im_valid_test))+' '+str(error)+' '+str(1-error)\n",
    "\n",
    "            if flag == 0:\n",
    "                dprime = error\n",
    "                flag = 1\n",
    "            else:\n",
    "                dprime -= error\n",
    "        print('Random: ',dprime)\n",
    "        layer_info[label][layer]['rand'] = dprime\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(1,8)\n",
    "Y = []\n",
    "Z =[]\n",
    "tmp = 0.\n",
    "for item in X:\n",
    "    print(item,layer_info[ana][item]['pre'],layer_info[ana][item]['post'],layer_info[ana][item]['rand'])\n",
    "    tmp += layer_info[ana][item]['pre']-layer_info[ana][item]['post']\n",
    "    Y.append(layer_info[ana][item]['pre']-layer_info[ana][item]['post'])\n",
    "    if layer_info[ana][item]['rand'] == 0.:\n",
    "        Z.append(0.)\n",
    "    else:\n",
    "        Z.append(layer_info[ana][item]['rand']-layer_info[ana][item]['no'])\n",
    "print tmp\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "rects1 = plt.bar(X- width/2, Y, width, label='Layer-specific cluster lesions')\n",
    "rects2 = plt.bar(X+width/2, Z, width, label='Random layer lesions')\n",
    "\n",
    "plt.ylabel('Relative change in performance impact')\n",
    "plt.xlabel('Different layers of Alexnet')\n",
    "plt.xticks(X, ('conv_1', 'conv_2', 'conv_3', 'conv_4','conv_5','fc1','fc2'))\n",
    "plt.title('Change in Performance by layer for Animate')\n",
    "plt.legend()\n",
    "plt.savefig('../../results/scree/animate_by_layer.png', format='png')\n",
    "#plt.ylim([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.arange(1,8)\n",
    "Y = []\n",
    "Z = []\n",
    "tmp = 0.\n",
    "for item in X:\n",
    "    print(item,layer_info[ina][item]['pre'],layer_info[ina][item]['post'],layer_info[ana][item]['rand'])\n",
    "    Y.append((-1*layer_info[ina][item]['pre'])-(-1*layer_info[ina][item]['post']))\n",
    "    if layer_info[ana][item]['rand'] == 0.:\n",
    "        Z.append(0.)\n",
    "    else:\n",
    "        Z.append(layer_info[ana][item]['rand']-layer_info[ana][item]['no'])\n",
    "    tmp += (-1*layer_info[ina][item]['pre'])-(-1*layer_info[ina][item]['post'])\n",
    "print(tmp)\n",
    "width = 0.35  # the width of the bars\n",
    "\n",
    "rects1 = plt.bar(X- width/2, Y, width, label='Layer-specific cluster lesions')\n",
    "rects2 = plt.bar(X+width/2, Z, width, label='Random layer lesions')\n",
    "\n",
    "plt.ylabel('Relative change in performance impact')\n",
    "plt.xticks(X, ('conv_1', 'conv_2', 'conv_3', 'conv_4','conv_5','fc1','fc2'))\n",
    "plt.xlabel('Different layers of Alexnet')\n",
    "plt.title('Change in Performance by layer for Inanimate')\n",
    "plt.legend()\n",
    "plt.savefig('../../results/scree/inaniamte_by_layer.png', format='png')\n",
    "#plt.ylim([0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.regularizers import l2\n",
    "\n",
    "def alexnet_model(img_shape=(227, 227, 3), n_classes=1000, l2_reg=0.,\n",
    "\tweights=None):\n",
    "\n",
    "\t# Initialize model\n",
    "\talexnet = Sequential()\n",
    "\n",
    "\t# Layer 1\n",
    "\talexnet.add(Conv2D(96, (11, 11), input_shape=img_shape,\n",
    "\t\tpadding='same', kernel_regularizer=l2(l2_reg)))\n",
    "\talexnet.add(BatchNormalization())\n",
    "\talexnet.add(Activation('relu'))\n",
    "\talexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\t# Layer 2\n",
    "\talexnet.add(Conv2D(256, (5, 5), padding='same'))\n",
    "\talexnet.add(BatchNormalization())\n",
    "\talexnet.add(Activation('relu'))\n",
    "\talexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\t# Layer 3\n",
    "\talexnet.add(ZeroPadding2D((1, 1)))\n",
    "\talexnet.add(Conv2D(512, (3, 3), padding='same'))\n",
    "\talexnet.add(BatchNormalization())\n",
    "\talexnet.add(Activation('relu'))\n",
    "\talexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\t# Layer 4\n",
    "\talexnet.add(ZeroPadding2D((1, 1)))\n",
    "\talexnet.add(Conv2D(1024, (3, 3), padding='same'))\n",
    "\talexnet.add(BatchNormalization())\n",
    "\talexnet.add(Activation('relu'))\n",
    "\n",
    "\t# Layer 5\n",
    "\talexnet.add(ZeroPadding2D((1, 1)))\n",
    "\talexnet.add(Conv2D(1024, (3, 3), padding='same'))\n",
    "\talexnet.add(BatchNormalization())\n",
    "\talexnet.add(Activation('relu'))\n",
    "\talexnet.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "\t# Layer 6\n",
    "\talexnet.add(Flatten())\n",
    "\talexnet.add(Dense(3072))\n",
    "\talexnet.add(BatchNormalization())\n",
    "\talexnet.add(Activation('relu'))\n",
    "\talexnet.add(Dropout(0.5))\n",
    "\n",
    "\t# Layer 7\n",
    "\talexnet.add(Dense(4096))\n",
    "\talexnet.add(BatchNormalization())\n",
    "\talexnet.add(Activation('relu'))\n",
    "\talexnet.add(Dropout(0.5))\n",
    "\n",
    "\t# Layer 8\n",
    "\talexnet.add(Dense(n_classes))\n",
    "\talexnet.add(BatchNormalization())\n",
    "\talexnet.add(Activation('softmax'))\n",
    "\n",
    "\tif weights is not None:\n",
    "\t\talexnet.load_weights(weights)\n",
    "\n",
    "\treturn alexnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = alexnet_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_11 (Conv2D)           (None, 96, 227, 3)        2636928   \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 96, 227, 3)        12        \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 96, 227, 3)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling (None, 96, 113, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 256, 113, 1)       614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 256, 113, 1)       4         \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 256, 113, 1)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling (None, 256, 56, 0)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_15 (ZeroPaddi (None, 256, 58, 2)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 512, 58, 2)        1180160   \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 512, 58, 2)        8         \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 512, 58, 2)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 512, 29, 1)        0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_16 (ZeroPaddi (None, 512, 31, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 1024, 31, 3)       4719616   \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 1024, 31, 3)       12        \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 1024, 31, 3)       0         \n",
      "_________________________________________________________________\n",
      "zero_padding2d_17 (ZeroPaddi (None, 1024, 33, 5)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 1024, 33, 5)       9438208   \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 1024, 33, 5)       20        \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 1024, 33, 5)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 1024, 16, 2)       0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 3072)              100666368 \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 3072)              12288     \n",
      "_________________________________________________________________\n",
      "activation_22 (Activation)   (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 3072)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 4096)              12587008  \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 4096)              16384     \n",
      "_________________________________________________________________\n",
      "activation_23 (Activation)   (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                40970     \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_24 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 131,912,682\n",
      "Trainable params: 131,898,298\n",
      "Non-trainable params: 14,384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 3, 227, 227)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_1 (Conv2D)                 (None, 96, 55, 55)   34944       input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 96, 55, 55)   0           conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 96, 27, 27)   0           lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "convpool_1 (Lambda)             (None, 96, 27, 27)   0           max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_5 (ZeroPadding2D (None, 96, 31, 31)   0           convpool_1[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 48, 31, 31)   0           zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 48, 31, 31)   0           zero_padding2d_5[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_1 (Conv2D)               (None, 128, 27, 27)  153728      lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_2_2 (Conv2D)               (None, 128, 27, 27)  153728      lambda_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_2 (Merge)                  (None, 256, 27, 27)  0           conv_2_1[0][0]                   \n",
      "                                                                 conv_2_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 256, 27, 27)  0           conv_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 256, 13, 13)  0           lambda_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 256, 13, 13)  0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_6 (ZeroPadding2D (None, 256, 15, 15)  0           lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_3 (Conv2D)                 (None, 384, 13, 13)  885120      zero_padding2d_6[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 384, 13, 13)  0           conv_3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_7 (ZeroPadding2D (None, 384, 15, 15)  0           lambda_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 192, 15, 15)  0           zero_padding2d_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 192, 15, 15)  0           zero_padding2d_7[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv_4_1 (Conv2D)               (None, 192, 13, 13)  331968      lambda_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_4_2 (Conv2D)               (None, 192, 13, 13)  331968      lambda_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_4 (Merge)                  (None, 384, 13, 13)  0           conv_4_1[0][0]                   \n",
      "                                                                 conv_4_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 384, 13, 13)  0           conv_4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_8 (ZeroPadding2D (None, 384, 15, 15)  0           lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 192, 15, 15)  0           zero_padding2d_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 192, 15, 15)  0           zero_padding2d_8[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv_5_1 (Conv2D)               (None, 128, 13, 13)  221312      lambda_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_5_2 (Conv2D)               (None, 128, 13, 13)  221312      lambda_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv_5 (Merge)                  (None, 256, 13, 13)  0           conv_5_1[0][0]                   \n",
      "                                                                 conv_5_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 256, 13, 13)  0           conv_5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "convpool_5 (MaxPooling2D)       (None, 256, 6, 6)    0           lambda_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 9216)         0           convpool_5[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 4096)         37752832    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)              (None, 4096)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 4096)         0           lambda_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 4096)         16781312    dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)              (None, 4096)         0           dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 4096)         0           lambda_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 1000)         4097000     dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 1000)         0           dense_3[0][0]                    \n",
      "==================================================================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total params: 60,965,224\n",
      "Trainable params: 60,965,224\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model1 = AlexNet(weights_path=\"../../data/weights/alexnet_weights.h5\")\n",
    "model1.summary()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    if len(weights) > 0:\n",
    "        print layer.name,len(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AlexNet' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-0ce9f6d442e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Get model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAlexNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"../../data/weights/alexnet_weights.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Strip softmax layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AlexNet' is not defined"
     ]
    }
   ],
   "source": [
    "#LRP\n",
    "\n",
    "import innvestigate\n",
    "import innvestigate.utils\n",
    "import imp\n",
    "import keras.applications.vgg16 as vgg16\n",
    "\n",
    "utils = imp.load_source(\"utils\", 'utils.py')\n",
    "\n",
    "# Get model\n",
    "#model = AlexNet(weights_path=\"../../data/weights/alexnet_weights.h5\")\n",
    "model, preprocess = vgg16.VGG16(), vgg16.preprocess_input\n",
    "\n",
    "# Strip softmax layer\n",
    "model = innvestigate.utils.model_wo_softmax(model)\n",
    "\n",
    "# Create analyzer\n",
    "analyzer = innvestigate.create_analyzer(\"lrp.z\", model,reverse_keep_tensors=True)\n",
    "\n",
    "\n",
    "im_valid_test = []\n",
    "image_list_valid = '../../data/pkl/'+p+'_image_list_test.txt'\n",
    "with open(image_list_valid,'rb') as f:\n",
    "    for line in f.readlines():\n",
    "        im_valid_test.append(line.strip('\\n'))\n",
    "im_temp = preprocess_image(im_valid_test,227,227, color_mode=\"bgr\")\n",
    "\n",
    "\n",
    "image_activations = []\n",
    "for image in im_temp:\n",
    "    x = preprocess(image[None])\n",
    "    # Apply analyzer w.r.t. maximum activated output-neuron\n",
    "    a = analyzer.analyze(x)\n",
    "    data = np.asarray(analyzer._reversed_tensors)\n",
    "    activations = np.array([])\n",
    "    for i  in range(1,len(model.layers)):\n",
    "        j = i-1\n",
    "        if model.layers[j].name.endswith('conv1') or model.layers[j].name.endswith('conv2') or model.layers[j].name.endswith('conv3') or  model.layers[j].name.endswith('fc1') or model.layers[j].name.endswith('fc2') :\n",
    "            #print(model.layers[j].name,data[i][1].shape)\n",
    "            temp = np.mean(data[i][1], axis=0).ravel()\n",
    "            activations = np.append(activations,temp)\n",
    "        image_activations.append(activations)\n",
    "\n",
    "image_activations = np.asarray(image_activations)\n",
    "image_activations = np.mean(image_activations, axis=0).ravel()\n",
    "print(image_activations.shape)\n",
    "\n",
    "\n",
    "number = 30 \n",
    "index= sorted(range(len(image_activations), key=lambda k: abs(image_activations[k]),reverse=True))\n",
    "print(index[0:number])\n",
    "\n",
    "idx = np.ones(image_activations.shape)\n",
    "idx[index[0:number]] = 0.\n",
    "\n",
    "'''\n",
    "def return_activations(model,image_list,algorithm='lrp.z'):\n",
    "  analyzer = innvestigate.create_analyzer(\"lrp.z\", model,reverse_keep_tensors=True)\n",
    "  data = np.asarray(analyzer._reversed_tensors)\n",
    "  data[22][1].shape\n",
    "\n",
    "image_list = []\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
