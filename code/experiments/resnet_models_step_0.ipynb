{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#To hide warnings export PYTHONWARNINGS=\"ignore\"\n",
    "#Imports{\n",
    "\n",
    "import os\n",
    "from os.path import dirname\n",
    "from os.path import join\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' #Cha\n",
    "\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from imageio import imread\n",
    "from skimage.transform import resize\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "#K.set_image_dim_ordering('tf')\n",
    "from keras_applications import imagenet_utils as utils\n",
    "from keras.layers import Lambda\n",
    "\n",
    "import PIL.Image\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code snippet needed to read activation values from each layer of the pre-trained artificial neural networks\n",
    "def get_activations(model, layer, X_batch):\n",
    "    #keras.backend.function(inputs, outputs, updates=None)\n",
    "    get_activations = keras.backend.function([model.layers[0].input, keras.backend.learning_phase()], [model.layers[layer].output,])\n",
    "    #The learning phase flag is a bool tensor (0 = test, 1 = train)\n",
    "    activations = get_activations([X_batch,0])\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'channels_last'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backend= keras.backend\n",
    "layers = keras.layers\n",
    "models = keras.models\n",
    "keras_utils = keras.utils\n",
    "keras.backend.image_data_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resnet 101 models for Keras.\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "backend= keras.backend\n",
    "layers = keras.layers\n",
    "models = keras.models\n",
    "keras_utils = keras.utils\n",
    "\n",
    "\n",
    "BASE_WEIGHTS_PATH = (\n",
    "    'https://github.com/keras-team/keras-applications/'\n",
    "    'releases/download/resnet/')\n",
    "WEIGHTS_HASHES = {\n",
    "    'resnet50': ('2cb95161c43110f7111970584f804107',\n",
    "                 '4d473c1dd8becc155b73f8504c6f6626'),\n",
    "    'resnet101': ('f1aeb4b969a6efcfb50fad2f0c20cfc5',\n",
    "                  '88cf7a10940856eca736dc7b7e228a21'),\n",
    "    'resnet152': ('100835be76be38e30d865e96f2aaae62',\n",
    "                  'ee4c566cf9a93f14d82f913c2dc6dd0c'),\n",
    "    'resnet50v2': ('3ef43a0b657b3be2300d5770ece849e0',\n",
    "                   'fac2f116257151a9d068a22e544a4917'),\n",
    "    'resnet101v2': ('6343647c601c52e1368623803854d971',\n",
    "                    'c0ed64b8031c3730f411d2eb4eea35b5'),\n",
    "    'resnet152v2': ('a49b44d1979771252814e80f8ec446f9',\n",
    "                    'ed17cf2e0169df9d443503ef94b23b33'),\n",
    "    'resnext50': ('67a5b30d522ed92f75a1f16eef299d1a',\n",
    "                  '62527c363bdd9ec598bed41947b379fc'),\n",
    "    'resnext101': ('34fb605428fcc7aa4d62f44404c11509',\n",
    "                   '0f678c91647380debd923963594981b3')\n",
    "}\n",
    "\n",
    "def block1(x, filters, kernel_size=3, stride=1,\n",
    "           conv_shortcut=True, name=None, lambda_mask = None, input_size = None):\n",
    "    \"\"\"A residual block.\n",
    "\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        filters: integer, filters of the bottleneck layer.\n",
    "        kernel_size: default 3, kernel size of the bottleneck layer.\n",
    "        stride: default 1, stride of the first layer.\n",
    "        conv_shortcut: default True, use convolution shortcut if True,\n",
    "            otherwise identity shortcut.\n",
    "        name: string, block label.\n",
    "\n",
    "    # Returns\n",
    "        Output tensor for the residual block.\n",
    "    \"\"\"\n",
    "    global start_index, end_index, debug\n",
    "    bn_axis = 3 if backend.image_data_format() == 'channels_last' else 1\n",
    "    #print(input_size, filters)\n",
    "    if conv_shortcut is True:\n",
    "        shortcut = layers.Conv2D(4 * filters, 1, strides=stride,name=name + '_0_conv')(x)\n",
    "        #################\n",
    "        if lambda_mask is not None:\n",
    "            start_index = end_index\n",
    "            end_index = start_index + (input_size* input_size* filters * 4)\n",
    "            if debug:\n",
    "                print(name + '_0_conv',start_index,end_index)\n",
    "            shortcut_mask  = np.reshape(lambda_mask[start_index:end_index], (input_size, input_size, filters * 4))\n",
    "        else:\n",
    "            shortcut_mask = np.ones(shape=((input_size, input_size, filters * 4)))\n",
    "\n",
    "        shortcut_mask  = backend.variable(shortcut_mask)\n",
    "        shortcut = Lambda(lambda z: z * shortcut_mask)(shortcut)\n",
    "        #################\n",
    "        shortcut = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,\n",
    "                                             name=name + '_0_bn')(shortcut)\n",
    "        #################\n",
    "        if lambda_mask is not None:\n",
    "            start_index = end_index\n",
    "            end_index = start_index + (input_size* input_size* filters * 4)\n",
    "            if debug:\n",
    "                print(name + '_0_bn',start_index,end_index)\n",
    "            shortcut_mask  = np.reshape(lambda_mask[start_index:end_index], (input_size, input_size, filters * 4))\n",
    "        else:\n",
    "            shortcut_mask = np.ones(shape=((input_size, input_size, filters * 4)))\n",
    "\n",
    "        shortcut_mask  = backend.variable(shortcut_mask)\n",
    "        shortcut = Lambda(lambda z: z * shortcut_mask)(shortcut)\n",
    "        #################\n",
    "    else:\n",
    "        shortcut = x\n",
    "    \n",
    "\n",
    "    x = layers.Conv2D(filters, 1, strides=stride, name=name + '_1_conv')(x)\n",
    "    #################\n",
    "    if lambda_mask is not None:\n",
    "        start_index = end_index\n",
    "        end_index = start_index + (input_size* input_size* (filters))\n",
    "        if debug:\n",
    "            print(name + '_1_conv',start_index,end_index)\n",
    "        x_mask  = np.reshape(lambda_mask[start_index:end_index], (input_size, input_size, filters))\n",
    "    else:\n",
    "        x_mask = np.ones(shape=((input_size, input_size, filters)))\n",
    "\n",
    "    x_mask  = backend.variable(x_mask)\n",
    "    x = Lambda(lambda z: z * x_mask)(x)\n",
    "    ####################\n",
    "    \n",
    "    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_1_bn')(x)\n",
    "    x = layers.Activation('relu', name=name + '_1_relu')(x)\n",
    "    #################\n",
    "    if lambda_mask is not None:\n",
    "        start_index = end_index\n",
    "        end_index = start_index + (input_size* input_size* (filters))\n",
    "        if debug:\n",
    "            print(name + '_1_bn',start_index,end_index)\n",
    "        x_mask  = np.reshape(lambda_mask[start_index:end_index], (input_size, input_size, filters))\n",
    "    else:\n",
    "        x_mask = np.ones(shape=((input_size, input_size, filters)))\n",
    "\n",
    "    x_mask  = backend.variable(x_mask)\n",
    "    x = Lambda(lambda z: z * x_mask)(x)\n",
    "    ####################\n",
    "\n",
    "    x = layers.Conv2D(filters, kernel_size, padding='SAME',\n",
    "                      name=name + '_2_conv')(x)\n",
    "   #################\n",
    "    if lambda_mask is not None:\n",
    "        start_index = end_index\n",
    "        end_index = start_index + (input_size* input_size* (filters))\n",
    "        if debug:\n",
    "            print(name + '_2_conv',start_index,end_index)\n",
    "        x_mask  = np.reshape(lambda_mask[start_index:end_index], (input_size, input_size, filters))\n",
    "    else:\n",
    "        x_mask = np.ones(shape=((input_size, input_size, filters)))\n",
    "\n",
    "    x_mask  = backend.variable(x_mask)\n",
    "    x = Lambda(lambda z: z * x_mask)(x)\n",
    "    ####################\n",
    "    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,name=name + '_2_bn')(x)\n",
    "    x = layers.Activation('relu', name=name + '_2_relu')(x)\n",
    "    #################\n",
    "    if lambda_mask is not None:\n",
    "        start_index = end_index\n",
    "        end_index = start_index + (input_size* input_size* (filters))\n",
    "        if debug:\n",
    "            print(name + '_2_bn',start_index,end_index)\n",
    "        x_mask  = np.reshape(lambda_mask[start_index:end_index], (input_size, input_size, filters))\n",
    "    else:\n",
    "        x_mask = np.ones(shape=((input_size, input_size, filters)))\n",
    "\n",
    "    x_mask  = backend.variable(x_mask)\n",
    "    x = Lambda(lambda z: z * x_mask)(x)\n",
    "    ####################\n",
    "\n",
    "    x = layers.Conv2D(4 * filters, 1, name=name + '_3_conv')(x)\n",
    "    #################\n",
    "    if lambda_mask is not None:\n",
    "        start_index = end_index\n",
    "        end_index = start_index + (input_size* input_size* (filters) * 4)\n",
    "        if debug:\n",
    "            print(name + '_3_conv',start_index,end_index)\n",
    "        x_mask  = np.reshape(lambda_mask[start_index:end_index], (input_size, input_size, filters * 4))\n",
    "    else:\n",
    "        x_mask = np.ones(shape=((input_size, input_size, filters * 4)))\n",
    "\n",
    "    x_mask  = backend.variable(x_mask)\n",
    "    x = Lambda(lambda z: z * x_mask)(x)\n",
    "    ####################\n",
    "    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,name=name + '_3_bn')(x)\n",
    "\n",
    "    #################\n",
    "    if lambda_mask is not None:\n",
    "        start_index = end_index\n",
    "        end_index = start_index + (input_size* input_size* (filters) * 4)\n",
    "        if debug:\n",
    "            print(name + '_3_bn',start_index,end_index)\n",
    "        x_mask  = np.reshape(lambda_mask[start_index:end_index], (input_size, input_size, filters * 4))\n",
    "    else:\n",
    "        x_mask = np.ones(shape=((input_size, input_size, filters * 4)))\n",
    "\n",
    "    x_mask  = backend.variable(x_mask)\n",
    "    x = Lambda(lambda z: z * x_mask)(x)\n",
    "    ####################\n",
    "    x = layers.Add(name=name + '_add')([shortcut, x])\n",
    "    x = layers.Activation('relu', name=name + '_out')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def stack1(x, filters, blocks, stride1=2, name=None, lambda_mask=None, input_size = None):\n",
    "    \"\"\"A set of stacked residual blocks.\n",
    "\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        filters: integer, filters of the bottleneck layer in a block.\n",
    "        blocks: integer, blocks in the stacked blocks.\n",
    "        stride1: default 2, stride of the first layer in the first block.\n",
    "        name: string, stack label.\n",
    "\n",
    "    # Returns\n",
    "        Output tensor for the stacked blocks.\n",
    "    \"\"\"\n",
    "    x = block1(x, filters, stride=stride1, name=name + '_block1', lambda_mask=lambda_mask, input_size = input_size)\n",
    "    for i in range(2, blocks + 1):\n",
    "        x = block1(x, filters, conv_shortcut=False, name=name + '_block' + str(i), lambda_mask=lambda_mask, input_size = input_size)\n",
    "    return x\n",
    "\n",
    "\n",
    "def block2(x, filters, kernel_size=3, stride=1,\n",
    "           conv_shortcut=False, name=None):\n",
    "    \"\"\"A residual block.\n",
    "\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        filters: integer, filters of the bottleneck layer.\n",
    "        kernel_size: default 3, kernel size of the bottleneck layer.\n",
    "        stride: default 1, stride of the first layer.\n",
    "        conv_shortcut: default False, use convolution shortcut if True,\n",
    "            otherwise identity shortcut.\n",
    "        name: string, block label.\n",
    "\n",
    "    # Returns\n",
    "        Output tensor for the residual block.\n",
    "    \"\"\"\n",
    "    bn_axis = 3 if backend.image_data_format() == 'channels_last' else 1\n",
    "\n",
    "    preact = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,name=name + '_preact_bn')(x)\n",
    "    preact = layers.Activation('relu', name=name + '_preact_relu')(preact)\n",
    "\n",
    "    if conv_shortcut is True:\n",
    "        shortcut = layers.Conv2D(4 * filters, 1, strides=stride, name=name + '_0_conv')(preact)\n",
    "    else:\n",
    "        shortcut = layers.MaxPooling2D(1, strides=stride)(x) if stride > 1 else x\n",
    "\n",
    "    x = layers.Conv2D(filters, 1, strides=1, use_bias=False, name=name + '_1_conv')(preact)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_1_bn')(x)\n",
    "    x = layers.Activation('relu', name=name + '_1_relu')(x)\n",
    "\n",
    "    x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name=name + '_2_pad')(x)\n",
    "    x = layers.Conv2D(filters, kernel_size, strides=stride, use_bias=False, name=name + '_2_conv')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_2_bn')(x)\n",
    "    x = layers.Activation('relu', name=name + '_2_relu')(x)\n",
    "\n",
    "    x = layers.Conv2D(4 * filters, 1, name=name + '_3_conv')(x)\n",
    "    x = layers.Add(name=name + '_out')([shortcut, x])\n",
    "    return x\n",
    "\n",
    "\n",
    "def stack2(x, filters, blocks, stride1=2, name=None):\n",
    "    \"\"\"A set of stacked residual blocks.\n",
    "\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        filters: integer, filters of the bottleneck layer in a block.\n",
    "        blocks: integer, blocks in the stacked blocks.\n",
    "        stride1: default 2, stride of the first layer in the first block.\n",
    "        name: string, stack label.\n",
    "\n",
    "    # Returns\n",
    "        Output tensor for the stacked blocks.\n",
    "    \"\"\"\n",
    "    x = block2(x, filters, conv_shortcut=True, name=name + '_block1')\n",
    "    for i in range(2, blocks):\n",
    "        x = block2(x, filters, name=name + '_block' + str(i))\n",
    "    x = block2(x, filters, stride=stride1, name=name + '_block' + str(blocks))\n",
    "    return x\n",
    "\n",
    "\n",
    "def block3(x, filters, kernel_size=3, stride=1, groups=32,\n",
    "           conv_shortcut=True, name=None,lambda_mask=None, input_size = None):\n",
    "    \"\"\"A residual block.\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        filters: integer, filters of the bottleneck layer.\n",
    "        kernel_size: default 3, kernel size of the bottleneck layer.\n",
    "        stride: default 1, stride of the first layer.\n",
    "        groups: default 32, group size for grouped convolution.\n",
    "        conv_shortcut: default True, use convolution shortcut if True,\n",
    "            otherwise identity shortcut.\n",
    "        name: string, block label.\n",
    "    # Returns\n",
    "        Output tensor for the residual block.\n",
    "    \"\"\"\n",
    "    bn_axis = 3 if backend.image_data_format() == 'channels_last' else 1\n",
    "\n",
    "    if conv_shortcut is True:\n",
    "        shortcut = layers.Conv2D((64 // groups) * filters, 1, strides=stride,use_bias=False, name=name + '_0_conv')(x)\n",
    "        if lambda_mask is not None:\n",
    "            shortcut_mask  = np.reshape(lambda_mask[3211264:6422528], (input_size, input_size, filters * 2))\n",
    "        else:\n",
    "            shortcut_mask = np.ones(shape=((input_size, input_size, filters * 2)))\n",
    "\n",
    "        shortcut_mask  = backend.variable(shortcut_mask)\n",
    "        shortcut_mask = Lambda(lambda z: z * shortcut_mask)(shortcut)\n",
    "        shortcut = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,name=name + '_0_bn')(shortcut)\n",
    "        if lambda_mask is not None:\n",
    "            shortcut_mask  = np.reshape(lambda_mask[3211264:6422528], (filters//2, filters//2, filters * 2))\n",
    "        else:\n",
    "            shortcut_mask = np.ones(shape=((filters//2, filters//2, filters * 2)))\n",
    "\n",
    "        shortcut_mask  = backend.variable(shortcut_mask)\n",
    "    else:\n",
    "        shortcut = x\n",
    "\n",
    "    x = layers.Conv2D(filters, 1, use_bias=False, name=name + '_1_conv')(x)\n",
    "    #################\n",
    "    if lambda_mask is not None:\n",
    "        x_mask  = np.reshape(lambda_mask[3211264:6422528], (input_size, input_size, filters // 2))\n",
    "    else:\n",
    "        x_mask = np.ones(shape=((input_size, input_size, filters)))\n",
    "\n",
    "    x_mask  = backend.variable(x_mask)\n",
    "    x = Lambda(lambda z: z * x_mask)(x)\n",
    "    ####################\n",
    "    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_1_bn')(x)\n",
    "    x = layers.Activation('relu', name=name + '_1_relu')(x)\n",
    "    #################\n",
    "    if lambda_mask is not None:\n",
    "        x_mask  = np.reshape(lambda_mask[3211264:6422528], (input_size, input_size, filters // 2))\n",
    "    else:\n",
    "        x_mask = np.ones(shape=((input_size, input_size, filters)))\n",
    "\n",
    "    x_mask  = backend.variable(x_mask)\n",
    "    x = Lambda(lambda z: z * x_mask)(x)\n",
    "    ####################\n",
    "    c = filters // groups\n",
    "    x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name=name + '_2_pad')(x)\n",
    "    x = layers.DepthwiseConv2D(kernel_size, strides=stride, depth_multiplier=c,use_bias=False, name=name + '_2_conv')(x)\n",
    "    #################\n",
    "    if lambda_mask is not None:\n",
    "        x_mask  = np.reshape(lambda_mask[3211264:6422528], (input_size, input_size, filters // 2))\n",
    "    else:\n",
    "        x_mask = np.ones(shape=((input_size, input_size, filters // 2)))\n",
    "\n",
    "    x_mask  = backend.variable(x_mask)\n",
    "    x = Lambda(lambda z: z * x_mask)(x)\n",
    "    ####################\n",
    "    kernel = np.zeros((1, 1, filters * c, filters), dtype=np.float32)\n",
    "    for i in range(filters):\n",
    "        start = (i // c) * c * c + i % c\n",
    "        end = start + c * c\n",
    "        kernel[:, :, start:end:c, i] = 1.\n",
    "    x = layers.Conv2D(filters, 1, use_bias=False, trainable=False,kernel_initializer={'class_name': 'Constant','config': {'value': kernel}},name=name + '_2_gconv')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,name=name + '_2_bn')(x)\n",
    "    x = layers.Activation('relu', name=name + '_2_relu')(x)\n",
    "\n",
    "    x = layers.Conv2D((64 // groups) * filters, 1, use_bias=False, name=name + '_3_conv')(x)\n",
    "    x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name=name + '_3_bn')(x)\n",
    "\n",
    "    x = layers.Add(name=name + '_add')([shortcut, x])\n",
    "    x = layers.Activation('relu', name=name + '_out')(x)\n",
    "    return x\n",
    "\n",
    "\n",
    "def stack3(x, filters, blocks, stride1=2, groups=32, name=None, lambda_mask=None, input_size = None):\n",
    "    \"\"\"A set of stacked residual blocks.\n",
    "\n",
    "    # Arguments\n",
    "        x: input tensor.\n",
    "        filters: integer, filters of the bottleneck layer in a block.\n",
    "        blocks: integer, blocks in the stacked blocks.\n",
    "        stride1: default 2, stride of the first layer in the first block.\n",
    "        groups: default 32, group size for grouped convolution.\n",
    "        name: string, stack label.\n",
    "\n",
    "    # Returns\n",
    "        Output tensor for the stacked blocks.\n",
    "    \"\"\"\n",
    "    x = block3(x, filters, stride=stride1, groups=groups, name=name + '_block1', lambda_mask=lambda_mask, input_size = input_size)\n",
    "    for i in range(2, blocks + 1):\n",
    "        x = block3(x, filters, groups=groups, conv_shortcut=False,\n",
    "                   name=name + '_block' + str(i), lambda_mask=lambda_mask, input_size = input_size)\n",
    "    return x\n",
    "\n",
    "\n",
    "def ResNet(stack_fn,\n",
    "           preact,\n",
    "           use_bias,\n",
    "           model_name='resnet',\n",
    "           include_top=True,\n",
    "           weights='imagenet',\n",
    "           input_tensor=None,\n",
    "           input_shape=None,\n",
    "           pooling=None,\n",
    "           classes=1000,\n",
    "           lambda_mask = None,\n",
    "           **kwargs):\n",
    "    \"\"\"Instantiates the ResNet, ResNetV2, and ResNeXt architecture.\n",
    "\n",
    "    Optionally loads weights pre-trained on ImageNet.\n",
    "    Note that the data format convention used by the model is\n",
    "    the one specified in your Keras config at `~/.keras/keras.json`.\n",
    "\n",
    "    # Arguments\n",
    "        stack_fn: a function that returns output tensor for the\n",
    "            stacked residual blocks.\n",
    "        preact: whether to use pre-activation or not\n",
    "            (True for ResNetV2, False for ResNet and ResNeXt).\n",
    "        use_bias: whether to use biases for convolutional layers or not\n",
    "            (True for ResNet and ResNetV2, False for ResNeXt).\n",
    "        model_name: string, model name.\n",
    "        include_top: whether to include the fully-connected\n",
    "            layer at the top of the network.\n",
    "        weights: one of `None` (random initialization),\n",
    "              'imagenet' (pre-training on ImageNet),\n",
    "              or the path to the weights file to be loaded.\n",
    "        input_tensor: optional Keras tensor\n",
    "            (i.e. output of `layers.Input()`)\n",
    "            to use as image input for the model.\n",
    "        input_shape: optional shape tuple, only to be specified\n",
    "            if `include_top` is False (otherwise the input shape\n",
    "            has to be `(224, 224, 3)` (with `channels_last` data format)\n",
    "            or `(3, 224, 224)` (with `channels_first` data format).\n",
    "            It should have exactly 3 inputs channels.\n",
    "        pooling: optional pooling mode for feature extraction\n",
    "            when `include_top` is `False`.\n",
    "            - `None` means that the output of the model will be\n",
    "                the 4D tensor output of the\n",
    "                last convolutional layer.\n",
    "            - `avg` means that global average pooling\n",
    "                will be applied to the output of the\n",
    "                last convolutional layer, and thus\n",
    "                the output of the model will be a 2D tensor.\n",
    "            - `max` means that global max pooling will\n",
    "                be applied.\n",
    "        classes: optional number of classes to classify images\n",
    "            into, only to be specified if `include_top` is True, and\n",
    "            if no `weights` argument is specified.\n",
    "\n",
    "    # Returns\n",
    "        A Keras model instance.\n",
    "\n",
    "    # Raises\n",
    "        ValueError: in case of invalid argument for `weights`,\n",
    "            or invalid input shape.\n",
    "    \"\"\"\n",
    "    global backend, layers, models, keras_utils, debug\n",
    "    debug =False\n",
    "    backend= keras.backend\n",
    "    layers = keras.layers\n",
    "    models = keras.models\n",
    "    keras_utils = keras.utils\n",
    "\n",
    "\n",
    "    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization), `imagenet` '\n",
    "                         '(pre-training on ImageNet), '\n",
    "                         'or the path to the weights file to be loaded.')\n",
    "\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as `\"imagenet\"` with `include_top`'\n",
    "                         ' as true, `classes` should be 1000')\n",
    "\n",
    "    # Determine proper input shape\n",
    "    input_shape = utils._obtain_input_shape(input_shape, default_size=224, min_size=32, data_format=backend.image_data_format(),require_flatten=include_top,weights=weights)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = layers.Input(shape=input_shape)\n",
    "    else:\n",
    "        if not backend.is_keras_tensor(input_tensor):\n",
    "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "\n",
    "    bn_axis = 3 if backend.image_data_format() == 'channels_last' else 1\n",
    "    \n",
    "    global start_index, end_index\n",
    "    start_index = 0\n",
    "    end_index = 112*112*64\n",
    "    x = layers.ZeroPadding2D(padding=((3, 3), (3, 3)), name='conv1_pad')(img_input)\n",
    "    x = layers.Conv2D(64, 7, strides=2, use_bias=use_bias, name='conv1_conv')(x)\n",
    "    \n",
    "    #################\n",
    "    if lambda_mask is not None:\n",
    "        if debug:\n",
    "            print('conv1_conv',start_index,end_index)\n",
    "        x_mask  = np.reshape(lambda_mask[start_index:end_index], (112, 112, 64))\n",
    "    else:\n",
    "        x_mask = np.ones(shape=((112, 112, 64)))\n",
    "\n",
    "    x_mask  = backend.variable(x_mask)\n",
    "    x = Lambda(lambda z: z * x_mask)(x)\n",
    "    ####################\n",
    "    if preact is False:\n",
    "        x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5, name='conv1_bn')(x)\n",
    "        x = layers.Activation('relu', name='conv1_relu')(x)\n",
    "        #################\n",
    "        if lambda_mask is not None:\n",
    "            start_index = end_index\n",
    "            end_index = start_index + 112*112*64 \n",
    "            if debug:\n",
    "                print('conv1_bn',start_index,end_index)\n",
    "            x_mask  = np.reshape(lambda_mask[start_index:end_index], (112, 112, 64))\n",
    "        else:\n",
    "            x_mask = np.ones(shape=((112, 112, 64)))\n",
    "\n",
    "        x_mask  = backend.variable(x_mask)\n",
    "        x = Lambda(lambda z: z * x_mask)(x)\n",
    "        ####################\n",
    "\n",
    "    x = layers.ZeroPadding2D(padding=((1, 1), (1, 1)), name='pool1_pad')(x)\n",
    "    x = layers.MaxPooling2D(3, strides=2, name='pool1_pool')(x)\n",
    "\n",
    "    x = stack_fn(x, lambda_mask=lambda_mask)\n",
    "\n",
    "    if preact is True:\n",
    "        x = layers.BatchNormalization(axis=bn_axis, epsilon=1.001e-5,name='post_bn')(x)\n",
    "        x = layers.Activation('relu', name='post_relu')(x)\n",
    "        \n",
    "\n",
    "    if include_top:\n",
    "        x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "        x = layers.Dense(classes, activation='softmax', name='probs')(x)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = layers.GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "        elif pooling == 'max':\n",
    "            x = layers.GlobalMaxPooling2D(name='max_pool')(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = keras_utils.get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "\n",
    "    # Create model.\n",
    "    model = models.Model(inputs, x, name=model_name)\n",
    "    #for layer in model.layers:\n",
    "    #    print(layer.name,layer.output_shape)\n",
    "\n",
    "    # Load weights.\n",
    "    if (weights == 'imagenet') and (model_name in WEIGHTS_HASHES):\n",
    "        if include_top:\n",
    "            file_name = model_name + '_weights_tf_dim_ordering_tf_kernels.h5'\n",
    "            file_hash = WEIGHTS_HASHES[model_name][0]\n",
    "        else:\n",
    "            file_name = model_name + '_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "            file_hash = WEIGHTS_HASHES[model_name][1]\n",
    "        weights_path = keras_utils.get_file(file_name,BASE_WEIGHTS_PATH + file_name,cache_subdir='models',file_hash=file_hash)\n",
    "        by_name = True\n",
    "        #by_name = True if 'resnext' in model_name else False\n",
    "        model.load_weights(weights_path, by_name=by_name)\n",
    "    elif weights is not None:\n",
    "        model.load_weights(weights)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def ResNet50(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,**kwargs):\n",
    "    def stack_fn(x, lambda_mask = None):\n",
    "        x = stack1(x, 64, 3, stride1=1, name='conv2')\n",
    "        x = stack1(x, 128, 4, name='conv3')\n",
    "        x = stack1(x, 256, 6, name='conv4')\n",
    "        x = stack1(x, 512, 3, name='conv5')\n",
    "        return x\n",
    "    return ResNet(stack_fn, False, True, 'resnet50',include_top, weights, input_tensor, input_shape,pooling, classes, **kwargs)\n",
    "\n",
    "\n",
    "def ResNet101(include_top=True, weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,lambda_mask = None,**kwargs):\n",
    "    def stack_fn(x, lambda_mask = None):\n",
    "        x = stack1(x, 64, 3, stride1=1, name='conv2',  lambda_mask=lambda_mask, input_size=56)\n",
    "        x = stack1(x, 128, 4, name='conv3',  lambda_mask=lambda_mask, input_size=28)\n",
    "        x = stack1(x, 256, 23, name='conv4',  lambda_mask=lambda_mask, input_size=14)\n",
    "        x = stack1(x, 512, 3, name='conv5',  lambda_mask=lambda_mask, input_size=7)\n",
    "        return x\n",
    "    return ResNet(stack_fn, False, True, 'resnet101', include_top, weights,input_tensor, input_shape,pooling, classes, lambda_mask,**kwargs)\n",
    "\n",
    "\n",
    "def ResNet152(include_top=True,weights='imagenet', input_tensor=None, input_shape=None,pooling=None,classes=1000, **kwargs):\n",
    "    def stack_fn(x, lambda_mask = None):\n",
    "        x = stack1(x, 64, 3, stride1=1, name='conv2')\n",
    "        x = stack1(x, 128, 8, name='conv3')\n",
    "        x = stack1(x, 256, 36, name='conv4')\n",
    "        x = stack1(x, 512, 3, name='conv5')\n",
    "        return x\n",
    "    return ResNet(stack_fn, False, True, 'resnet152',include_top, weights, input_tensor, input_shape, pooling, classes,**kwargs)\n",
    "\n",
    "\n",
    "def ResNet50V2(include_top=True, weights='imagenet',input_tensor=None, input_shape=None,pooling=None, classes=1000, **kwargs):\n",
    "    def stack_fn(x, lambda_mask = None):\n",
    "        x = stack2(x, 64, 3, name='conv2')\n",
    "        x = stack2(x, 128, 4, name='conv3')\n",
    "        x = stack2(x, 256, 6, name='conv4')\n",
    "        x = stack2(x, 512, 3, stride1=1, name='conv5')\n",
    "        return x\n",
    "    return ResNet(stack_fn, True, True, 'resnet50v2',include_top, weights, input_tensor, input_shape,pooling, classes, **kwargs)\n",
    "\n",
    "\n",
    "def ResNet101V2(include_top=True, weights='imagenet',input_tensor=None,input_shape=None, pooling=None,classes=1000, **kwargs):\n",
    "    def stack_fn(x, lambda_mask = None):\n",
    "        x = stack2(x, 64, 3, name='conv2')\n",
    "        x = stack2(x, 128, 4, name='conv3')\n",
    "        x = stack2(x, 256, 23, name='conv4')\n",
    "        x = stack2(x, 512, 3, stride1=1, name='conv5')\n",
    "        return x\n",
    "    return ResNet(stack_fn, True, True, 'resnet101v2', include_top, weights,input_tensor, input_shape, pooling, classes, **kwargs)\n",
    "\n",
    "\n",
    "def ResNet152V2(include_top=True,weights='imagenet',input_tensor=None, input_shape=None,pooling=None,classes=1000,**kwargs):\n",
    "    def stack_fn(x, lambda_mask = None):\n",
    "        x = stack2(x, 64, 3, name='conv2')\n",
    "        x = stack2(x, 128, 8, name='conv3')\n",
    "        x = stack2(x, 256, 36, name='conv4')\n",
    "        x = stack2(x, 512, 3, stride1=1, name='conv5')\n",
    "        return x\n",
    "    return ResNet(stack_fn, True, True, 'resnet152v2', include_top, weights, input_tensor, input_shape,pooling, classes, **kwargs)\n",
    "\n",
    "\n",
    "def ResNeXt50(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,**kwargs):\n",
    "    def stack_fn(x, lambda_mask = None):\n",
    "        x = stack3(x, 128, 3, stride1=1, name='conv2')\n",
    "        x = stack3(x, 256, 4, name='conv3')\n",
    "        x = stack3(x, 512, 6, name='conv4')\n",
    "        x = stack3(x, 1024, 3, name='conv5')\n",
    "        return x\n",
    "    return ResNet(stack_fn, False, False, 'resnext50',include_top, weights,input_tensor, input_shape,pooling, classes, **kwargs)\n",
    "\n",
    "\n",
    "def ResNeXt101(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,lambda_mask = None,**kwargs):\n",
    "    def stack_fn(x, lambda_mask = None):\n",
    "        x = stack3(x, 128, 3, stride1=1, name='conv2',  lambda_mask=lambda_mask, input_size=56)\n",
    "        x = stack3(x, 256, 4, name='conv3',  lambda_mask=lambda_mask, input_size=28)\n",
    "        x = stack3(x, 512, 23, name='conv4',  lambda_mask=lambda_mask, input_size=14)\n",
    "        x = stack3(x, 1024, 3, name='conv5',  lambda_mask=lambda_mask, input_size=7)\n",
    "        return x\n",
    "    return ResNet(stack_fn, False, False, 'resnext101',include_top, weights,input_tensor, input_shape,pooling, classes,lambda_mask,**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to pre-process the input image to ensure uniform size and color\n",
    "def preprocess_image_batch(image_paths, img_size=None, crop_size=None, color_mode='rgb', out=None):\n",
    "    \"\"\"\n",
    "    Consistent preprocessing of images batches\n",
    "    :param image_paths: iterable: images to process\n",
    "    :param crop_size: tuple: crop images if specified\n",
    "    :param img_size: tuple: resize images if specified\n",
    "    :param color_mode: Use rgb or change to bgr mode based on type of model you want to use\n",
    "    :param out: append output to this iterable if specified\n",
    "    \"\"\"\n",
    "    img_list = []\n",
    "\n",
    "    for im_path in image_paths:\n",
    "        '''\n",
    "        img = imread(im_path,as_gray=False, pilmode=\"RGB\")\n",
    "        #print im_path\n",
    "        #print img.shape\n",
    "        if img_size:\n",
    "            img = resize(img, img_size)\n",
    "\n",
    "        img = img.astype('float32')\n",
    "        # We normalize the colors (in RGB space) with the empirical means on the training set\n",
    "        img[:, :, 0] -= 123.68\n",
    "        img[:, :, 1] -= 116.779\n",
    "        img[:, :, 2] -= 103.939\n",
    "        # We permute the colors to get them in the BGR order\n",
    "        if color_mode == 'bgr':\n",
    "            img[:, :, [0, 1, 2]] = img[:, :, [2, 1, 0]]\n",
    "        img = img.transpose((2, 0, 1))\n",
    "\n",
    "        if crop_size:\n",
    "            img = img[:, (img_size[0] - crop_size[0]) // 2:(img_size[0] + crop_size[0]) // 2\n",
    "            , (img_size[1] - crop_size[1]) // 2:(img_size[1] + crop_size[1]) // 2]\n",
    "\n",
    "        img_list.append(img)\n",
    "        '''\n",
    "        size = 224\n",
    "        ret = PIL.Image.open(im_path)\n",
    "        ret = ret.resize((size, size))\n",
    "        ret = np.asarray(ret, dtype=np.uint8).astype(np.float32)\n",
    "        if ret.ndim == 2:\n",
    "            ret.resize((size, size, 1))\n",
    "            ret = np.repeat(ret, 3, axis=-1)\n",
    "        #ret = ret.transpose((2, 0, 1))\n",
    "        #ret = np.flip(ret,0)\n",
    "        global backend\n",
    "        x = utils.preprocess_input(ret, \n",
    "            data_format=backend.image_data_format())\n",
    "        img_list.append(x)\n",
    "\n",
    "\n",
    "    try:\n",
    "        img_batch = np.stack(img_list, axis=0)\n",
    "    except:\n",
    "        print(im_path)\n",
    "        raise ValueError('when img_size and crop_size are None, images'\n",
    "                ' in image_paths must have the same shapes.')\n",
    "\n",
    "    if out is not None and hasattr(out, 'append'):\n",
    "        out.append(img_batch)\n",
    "    else:\n",
    "        return img_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to predict the top 5 accuracy\n",
    "def top5accuracy(true, predicted):\n",
    "    assert len(true) == len(predicted)\n",
    "    result = []\n",
    "    flag  = 0\n",
    "    for i in range(len(true)):\n",
    "        flag  = 0\n",
    "        temp = true[i]\n",
    "        for j in predicted[i][0:5]:\n",
    "            if j == temp:\n",
    "                flag = 1\n",
    "                break\n",
    "        if flag == 1:\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(0)\n",
    "    counter = 0.\n",
    "    for i in result:\n",
    "        if i == 1:\n",
    "            counter += 1.\n",
    "    error = 1.0 - counter/float(len(result))\n",
    "    #print len(np.where(np.asarray(result) == 1)[0])\n",
    "    return len(np.where(np.asarray(result) == 1)[0]), error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the details of all the 1000 classes and the function to conver the synset id to words{\n",
    "meta_clsloc_file = '../../data/meta_clsloc.mat'\n",
    "synsets = loadmat(meta_clsloc_file)['synsets'][0]\n",
    "synsets_imagenet_sorted = sorted([(int(s[0]), str(s[1][0])) for s in synsets[:1000]],key=lambda v: v[1])\n",
    "corr = {}\n",
    "for j in range(1000):\n",
    "    corr[synsets_imagenet_sorted[j][0]] = j\n",
    "\n",
    "corr_inv = {}\n",
    "for j in range(1, 1001):\n",
    "    corr_inv[corr[j]] = j\n",
    "\n",
    "def id_to_words(id_):\n",
    "    return synsets[corr_inv[id_] - 1][2][0]\n",
    "\n",
    "def pprint_output(out, n_max_synsets=10):\n",
    "    wids = []\n",
    "    best_ids = out.argsort()[::-1][:10]\n",
    "    for u in best_ids:\n",
    "        wids.append(str(synsets[corr_inv[u] - 1][1][0]))\n",
    "    #print('%.2f' % round(100 * out[u], 2) + ' : ' + id_to_words(u)+' '+ str(synsets[corr_inv[u] - 1][1][0]))\n",
    "    return wids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code snippet to load the ground truth labels to measure the performance{\n",
    "truth = {}\n",
    "with open('../../data/ILSVRC2014_clsloc_validation_ground_truth.txt') as f:\n",
    "    line_num = 1\n",
    "    for line in f.readlines():\n",
    "        ind_ = int(line)\n",
    "        temp  = None\n",
    "        for i in synsets_imagenet_sorted:\n",
    "            if i[0] == ind_:\n",
    "                temp = i\n",
    "        #print ind_,temp\n",
    "        if temp != None:\n",
    "            truth[line_num] = temp\n",
    "        else:\n",
    "            print('##########', ind_)\n",
    "            pass\n",
    "        line_num += 1\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inanimate\n"
     ]
    }
   ],
   "source": [
    "# Loading the folder to be procesed from command line{\n",
    "p = 'inanimate'\n",
    "tmp = p.replace('/','_')\n",
    "print(tmp)\n",
    "\n",
    "\n",
    "p_num = 1\n",
    "url_path = '../../data/'+p+'/'\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194\n"
     ]
    }
   ],
   "source": [
    "# Prepare the image list and pre-process them{\n",
    "true_wids = []\n",
    "im_list = []\n",
    "for i in os.listdir(url_path):\n",
    "    if not i.startswith('~') and not i.startswith('.'):\n",
    "        #print i, truth\n",
    "        temp = i.split('.')[0].split('_')[2]\n",
    "        true_wids.append(truth[int(temp)][1])\n",
    "        im_list.append(url_path+i)\n",
    "print(len(im_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = preprocess_image_batch(im_list,img_size=(256,256), crop_size=(224,224), color_mode=\"rgb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31410176,)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import random\n",
    "vals = random.standard_normal(31410176)\n",
    "vals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/abhijit/anaconda3/envs/lesion/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/abhijit/anaconda3/envs/lesion/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/abhijit/anaconda3/envs/lesion/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/abhijit/anaconda3/envs/lesion/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/abhijit/anaconda3/envs/lesion/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/abhijit/anaconda3/envs/lesion/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/abhijit/anaconda3/envs/lesion/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Model parmeters and running the model from the loaded weights{\n",
    "import random\n",
    "#vals = random.standard_normal(31410176)\n",
    "model_name = 'ResNet101'\n",
    "model = ResNet101( include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=1000,\n",
    "    lambda_mask=None)\n",
    "#KFold\n",
    "k = 4\n",
    "\n",
    "im_train, im_test = train_test_split(im_list, test_size=0.2, random_state=234)\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 112, 112, 64) 0           conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 112, 112, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 56, 56, 64)   0           conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_6 (Lambda)               (None, 56, 56, 64)   0           conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       lambda_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 56, 56, 64)   0           conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         lambda_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_8 (Lambda)               (None, 56, 56, 64)   0           conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       lambda_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 56, 56, 256)  0           conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_9 (Lambda)               (None, 56, 56, 256)  0           conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        lambda_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_10 (Lambda)              (None, 56, 56, 256)  0           conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           lambda_4[0][0]                   \n",
      "                                                                 lambda_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_11 (Lambda)              (None, 56, 56, 64)   0           conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         lambda_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_12 (Lambda)              (None, 56, 56, 64)   0           conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       lambda_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_13 (Lambda)              (None, 56, 56, 64)   0           conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         lambda_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_14 (Lambda)              (None, 56, 56, 64)   0           conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       lambda_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_15 (Lambda)              (None, 56, 56, 256)  0           conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        lambda_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_16 (Lambda)              (None, 56, 56, 256)  0           conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 lambda_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_17 (Lambda)              (None, 56, 56, 64)   0           conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         lambda_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_18 (Lambda)              (None, 56, 56, 64)   0           conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       lambda_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_19 (Lambda)              (None, 56, 56, 64)   0           conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         lambda_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_20 (Lambda)              (None, 56, 56, 64)   0           conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       lambda_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_21 (Lambda)              (None, 56, 56, 256)  0           conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        lambda_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_22 (Lambda)              (None, 56, 56, 256)  0           conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 lambda_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_25 (Lambda)              (None, 28, 28, 128)  0           conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         lambda_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_26 (Lambda)              (None, 28, 28, 128)  0           conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      lambda_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_27 (Lambda)              (None, 28, 28, 128)  0           conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         lambda_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_28 (Lambda)              (None, 28, 28, 128)  0           conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       lambda_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_23 (Lambda)              (None, 28, 28, 512)  0           conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_29 (Lambda)              (None, 28, 28, 512)  0           conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        lambda_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        lambda_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_24 (Lambda)              (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_30 (Lambda)              (None, 28, 28, 512)  0           conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           lambda_24[0][0]                  \n",
      "                                                                 lambda_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_31 (Lambda)              (None, 28, 28, 128)  0           conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         lambda_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_32 (Lambda)              (None, 28, 28, 128)  0           conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      lambda_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_33 (Lambda)              (None, 28, 28, 128)  0           conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         lambda_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_34 (Lambda)              (None, 28, 28, 128)  0           conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       lambda_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_35 (Lambda)              (None, 28, 28, 512)  0           conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        lambda_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_36 (Lambda)              (None, 28, 28, 512)  0           conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 lambda_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_37 (Lambda)              (None, 28, 28, 128)  0           conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         lambda_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_38 (Lambda)              (None, 28, 28, 128)  0           conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      lambda_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_39 (Lambda)              (None, 28, 28, 128)  0           conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         lambda_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_40 (Lambda)              (None, 28, 28, 128)  0           conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       lambda_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_41 (Lambda)              (None, 28, 28, 512)  0           conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        lambda_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_42 (Lambda)              (None, 28, 28, 512)  0           conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 lambda_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_43 (Lambda)              (None, 28, 28, 128)  0           conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         lambda_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_44 (Lambda)              (None, 28, 28, 128)  0           conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      lambda_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_45 (Lambda)              (None, 28, 28, 128)  0           conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         lambda_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_46 (Lambda)              (None, 28, 28, 128)  0           conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       lambda_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_47 (Lambda)              (None, 28, 28, 512)  0           conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        lambda_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_48 (Lambda)              (None, 28, 28, 512)  0           conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 lambda_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_51 (Lambda)              (None, 14, 14, 256)  0           conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        lambda_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_52 (Lambda)              (None, 14, 14, 256)  0           conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      lambda_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_53 (Lambda)              (None, 14, 14, 256)  0           conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        lambda_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_54 (Lambda)              (None, 14, 14, 256)  0           conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      lambda_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_49 (Lambda)              (None, 14, 14, 1024) 0           conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_55 (Lambda)              (None, 14, 14, 1024) 0           conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        lambda_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        lambda_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_50 (Lambda)              (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_56 (Lambda)              (None, 14, 14, 1024) 0           conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           lambda_50[0][0]                  \n",
      "                                                                 lambda_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_57 (Lambda)              (None, 14, 14, 256)  0           conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        lambda_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_58 (Lambda)              (None, 14, 14, 256)  0           conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      lambda_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_59 (Lambda)              (None, 14, 14, 256)  0           conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        lambda_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_60 (Lambda)              (None, 14, 14, 256)  0           conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      lambda_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_61 (Lambda)              (None, 14, 14, 1024) 0           conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        lambda_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_62 (Lambda)              (None, 14, 14, 1024) 0           conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 lambda_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_63 (Lambda)              (None, 14, 14, 256)  0           conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        lambda_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_64 (Lambda)              (None, 14, 14, 256)  0           conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      lambda_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_65 (Lambda)              (None, 14, 14, 256)  0           conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        lambda_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_66 (Lambda)              (None, 14, 14, 256)  0           conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      lambda_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_67 (Lambda)              (None, 14, 14, 1024) 0           conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        lambda_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_68 (Lambda)              (None, 14, 14, 1024) 0           conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 lambda_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_69 (Lambda)              (None, 14, 14, 256)  0           conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        lambda_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_70 (Lambda)              (None, 14, 14, 256)  0           conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      lambda_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_71 (Lambda)              (None, 14, 14, 256)  0           conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        lambda_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_72 (Lambda)              (None, 14, 14, 256)  0           conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      lambda_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_73 (Lambda)              (None, 14, 14, 1024) 0           conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        lambda_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_74 (Lambda)              (None, 14, 14, 1024) 0           conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 lambda_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_75 (Lambda)              (None, 14, 14, 256)  0           conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        lambda_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_76 (Lambda)              (None, 14, 14, 256)  0           conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      lambda_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_77 (Lambda)              (None, 14, 14, 256)  0           conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        lambda_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_78 (Lambda)              (None, 14, 14, 256)  0           conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      lambda_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_79 (Lambda)              (None, 14, 14, 1024) 0           conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        lambda_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_80 (Lambda)              (None, 14, 14, 1024) 0           conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 lambda_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_81 (Lambda)              (None, 14, 14, 256)  0           conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        lambda_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_82 (Lambda)              (None, 14, 14, 256)  0           conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      lambda_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_83 (Lambda)              (None, 14, 14, 256)  0           conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        lambda_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_84 (Lambda)              (None, 14, 14, 256)  0           conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      lambda_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_85 (Lambda)              (None, 14, 14, 1024) 0           conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        lambda_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_86 (Lambda)              (None, 14, 14, 1024) 0           conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 lambda_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_87 (Lambda)              (None, 14, 14, 256)  0           conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 14, 14, 256)  1024        lambda_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 14, 14, 256)  0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_88 (Lambda)              (None, 14, 14, 256)  0           conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 14, 14, 256)  590080      lambda_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_89 (Lambda)              (None, 14, 14, 256)  0           conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_bn (BatchNormali (None, 14, 14, 256)  1024        lambda_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_relu (Activation (None, 14, 14, 256)  0           conv4_block7_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_90 (Lambda)              (None, 14, 14, 256)  0           conv4_block7_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      lambda_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_91 (Lambda)              (None, 14, 14, 1024) 0           conv4_block7_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_3_bn (BatchNormali (None, 14, 14, 1024) 4096        lambda_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_92 (Lambda)              (None, 14, 14, 1024) 0           conv4_block7_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_add (Add)          (None, 14, 14, 1024) 0           conv4_block6_out[0][0]           \n",
      "                                                                 lambda_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_out (Activation)   (None, 14, 14, 1024) 0           conv4_block7_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block7_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_93 (Lambda)              (None, 14, 14, 256)  0           conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 14, 14, 256)  1024        lambda_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 14, 14, 256)  0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_94 (Lambda)              (None, 14, 14, 256)  0           conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 14, 14, 256)  590080      lambda_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_95 (Lambda)              (None, 14, 14, 256)  0           conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_bn (BatchNormali (None, 14, 14, 256)  1024        lambda_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_relu (Activation (None, 14, 14, 256)  0           conv4_block8_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_96 (Lambda)              (None, 14, 14, 256)  0           conv4_block8_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      lambda_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_97 (Lambda)              (None, 14, 14, 1024) 0           conv4_block8_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_3_bn (BatchNormali (None, 14, 14, 1024) 4096        lambda_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_98 (Lambda)              (None, 14, 14, 1024) 0           conv4_block8_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_add (Add)          (None, 14, 14, 1024) 0           conv4_block7_out[0][0]           \n",
      "                                                                 lambda_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_out (Activation)   (None, 14, 14, 1024) 0           conv4_block8_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block8_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_99 (Lambda)              (None, 14, 14, 256)  0           conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 14, 14, 256)  1024        lambda_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 14, 14, 256)  0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_100 (Lambda)             (None, 14, 14, 256)  0           conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 14, 14, 256)  590080      lambda_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_101 (Lambda)             (None, 14, 14, 256)  0           conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_bn (BatchNormali (None, 14, 14, 256)  1024        lambda_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_relu (Activation (None, 14, 14, 256)  0           conv4_block9_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_102 (Lambda)             (None, 14, 14, 256)  0           conv4_block9_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      lambda_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_103 (Lambda)             (None, 14, 14, 1024) 0           conv4_block9_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_3_bn (BatchNormali (None, 14, 14, 1024) 4096        lambda_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_104 (Lambda)             (None, 14, 14, 1024) 0           conv4_block9_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_add (Add)          (None, 14, 14, 1024) 0           conv4_block8_out[0][0]           \n",
      "                                                                 lambda_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_out (Activation)   (None, 14, 14, 1024) 0           conv4_block9_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block9_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_105 (Lambda)             (None, 14, 14, 256)  0           conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 14, 14, 256)  1024        lambda_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_106 (Lambda)             (None, 14, 14, 256)  0           conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 14, 14, 256)  590080      lambda_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_107 (Lambda)             (None, 14, 14, 256)  0           conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_bn (BatchNormal (None, 14, 14, 256)  1024        lambda_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block10_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_108 (Lambda)             (None, 14, 14, 256)  0           conv4_block10_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      lambda_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_109 (Lambda)             (None, 14, 14, 1024) 0           conv4_block10_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_3_bn (BatchNormal (None, 14, 14, 1024) 4096        lambda_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_110 (Lambda)             (None, 14, 14, 1024) 0           conv4_block10_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_add (Add)         (None, 14, 14, 1024) 0           conv4_block9_out[0][0]           \n",
      "                                                                 lambda_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_out (Activation)  (None, 14, 14, 1024) 0           conv4_block10_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block10_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_111 (Lambda)             (None, 14, 14, 256)  0           conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 14, 14, 256)  1024        lambda_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_112 (Lambda)             (None, 14, 14, 256)  0           conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 14, 14, 256)  590080      lambda_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_113 (Lambda)             (None, 14, 14, 256)  0           conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_bn (BatchNormal (None, 14, 14, 256)  1024        lambda_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block11_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_114 (Lambda)             (None, 14, 14, 256)  0           conv4_block11_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      lambda_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_115 (Lambda)             (None, 14, 14, 1024) 0           conv4_block11_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_3_bn (BatchNormal (None, 14, 14, 1024) 4096        lambda_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_116 (Lambda)             (None, 14, 14, 1024) 0           conv4_block11_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_add (Add)         (None, 14, 14, 1024) 0           conv4_block10_out[0][0]          \n",
      "                                                                 lambda_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_out (Activation)  (None, 14, 14, 1024) 0           conv4_block11_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block11_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_117 (Lambda)             (None, 14, 14, 256)  0           conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 14, 14, 256)  1024        lambda_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_118 (Lambda)             (None, 14, 14, 256)  0           conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 14, 14, 256)  590080      lambda_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_119 (Lambda)             (None, 14, 14, 256)  0           conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_bn (BatchNormal (None, 14, 14, 256)  1024        lambda_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block12_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_120 (Lambda)             (None, 14, 14, 256)  0           conv4_block12_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      lambda_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_121 (Lambda)             (None, 14, 14, 1024) 0           conv4_block12_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_3_bn (BatchNormal (None, 14, 14, 1024) 4096        lambda_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_122 (Lambda)             (None, 14, 14, 1024) 0           conv4_block12_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_add (Add)         (None, 14, 14, 1024) 0           conv4_block11_out[0][0]          \n",
      "                                                                 lambda_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_out (Activation)  (None, 14, 14, 1024) 0           conv4_block12_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block12_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_123 (Lambda)             (None, 14, 14, 256)  0           conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 14, 14, 256)  1024        lambda_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_124 (Lambda)             (None, 14, 14, 256)  0           conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 14, 14, 256)  590080      lambda_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_125 (Lambda)             (None, 14, 14, 256)  0           conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_bn (BatchNormal (None, 14, 14, 256)  1024        lambda_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block13_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_126 (Lambda)             (None, 14, 14, 256)  0           conv4_block13_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      lambda_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_127 (Lambda)             (None, 14, 14, 1024) 0           conv4_block13_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_3_bn (BatchNormal (None, 14, 14, 1024) 4096        lambda_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_128 (Lambda)             (None, 14, 14, 1024) 0           conv4_block13_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_add (Add)         (None, 14, 14, 1024) 0           conv4_block12_out[0][0]          \n",
      "                                                                 lambda_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_out (Activation)  (None, 14, 14, 1024) 0           conv4_block13_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block13_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_129 (Lambda)             (None, 14, 14, 256)  0           conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 14, 14, 256)  1024        lambda_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_130 (Lambda)             (None, 14, 14, 256)  0           conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 14, 14, 256)  590080      lambda_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_131 (Lambda)             (None, 14, 14, 256)  0           conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_bn (BatchNormal (None, 14, 14, 256)  1024        lambda_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block14_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_132 (Lambda)             (None, 14, 14, 256)  0           conv4_block14_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      lambda_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_133 (Lambda)             (None, 14, 14, 1024) 0           conv4_block14_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_3_bn (BatchNormal (None, 14, 14, 1024) 4096        lambda_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_134 (Lambda)             (None, 14, 14, 1024) 0           conv4_block14_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_add (Add)         (None, 14, 14, 1024) 0           conv4_block13_out[0][0]          \n",
      "                                                                 lambda_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_out (Activation)  (None, 14, 14, 1024) 0           conv4_block14_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block14_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_135 (Lambda)             (None, 14, 14, 256)  0           conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 14, 14, 256)  1024        lambda_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_136 (Lambda)             (None, 14, 14, 256)  0           conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 14, 14, 256)  590080      lambda_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_137 (Lambda)             (None, 14, 14, 256)  0           conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_bn (BatchNormal (None, 14, 14, 256)  1024        lambda_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block15_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_138 (Lambda)             (None, 14, 14, 256)  0           conv4_block15_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      lambda_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_139 (Lambda)             (None, 14, 14, 1024) 0           conv4_block15_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_3_bn (BatchNormal (None, 14, 14, 1024) 4096        lambda_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_140 (Lambda)             (None, 14, 14, 1024) 0           conv4_block15_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_add (Add)         (None, 14, 14, 1024) 0           conv4_block14_out[0][0]          \n",
      "                                                                 lambda_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_out (Activation)  (None, 14, 14, 1024) 0           conv4_block15_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block15_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_141 (Lambda)             (None, 14, 14, 256)  0           conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 14, 14, 256)  1024        lambda_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_142 (Lambda)             (None, 14, 14, 256)  0           conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 14, 14, 256)  590080      lambda_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_143 (Lambda)             (None, 14, 14, 256)  0           conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_bn (BatchNormal (None, 14, 14, 256)  1024        lambda_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block16_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_144 (Lambda)             (None, 14, 14, 256)  0           conv4_block16_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      lambda_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_145 (Lambda)             (None, 14, 14, 1024) 0           conv4_block16_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_3_bn (BatchNormal (None, 14, 14, 1024) 4096        lambda_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_146 (Lambda)             (None, 14, 14, 1024) 0           conv4_block16_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_add (Add)         (None, 14, 14, 1024) 0           conv4_block15_out[0][0]          \n",
      "                                                                 lambda_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_out (Activation)  (None, 14, 14, 1024) 0           conv4_block16_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block16_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_147 (Lambda)             (None, 14, 14, 256)  0           conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 14, 14, 256)  1024        lambda_147[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_148 (Lambda)             (None, 14, 14, 256)  0           conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 14, 14, 256)  590080      lambda_148[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_149 (Lambda)             (None, 14, 14, 256)  0           conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_bn (BatchNormal (None, 14, 14, 256)  1024        lambda_149[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block17_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_150 (Lambda)             (None, 14, 14, 256)  0           conv4_block17_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      lambda_150[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_151 (Lambda)             (None, 14, 14, 1024) 0           conv4_block17_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_3_bn (BatchNormal (None, 14, 14, 1024) 4096        lambda_151[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_152 (Lambda)             (None, 14, 14, 1024) 0           conv4_block17_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_add (Add)         (None, 14, 14, 1024) 0           conv4_block16_out[0][0]          \n",
      "                                                                 lambda_152[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_out (Activation)  (None, 14, 14, 1024) 0           conv4_block17_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block17_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_153 (Lambda)             (None, 14, 14, 256)  0           conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 14, 14, 256)  1024        lambda_153[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_154 (Lambda)             (None, 14, 14, 256)  0           conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 14, 14, 256)  590080      lambda_154[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_155 (Lambda)             (None, 14, 14, 256)  0           conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_bn (BatchNormal (None, 14, 14, 256)  1024        lambda_155[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block18_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_156 (Lambda)             (None, 14, 14, 256)  0           conv4_block18_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      lambda_156[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_157 (Lambda)             (None, 14, 14, 1024) 0           conv4_block18_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_3_bn (BatchNormal (None, 14, 14, 1024) 4096        lambda_157[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_158 (Lambda)             (None, 14, 14, 1024) 0           conv4_block18_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_add (Add)         (None, 14, 14, 1024) 0           conv4_block17_out[0][0]          \n",
      "                                                                 lambda_158[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_out (Activation)  (None, 14, 14, 1024) 0           conv4_block18_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block18_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_159 (Lambda)             (None, 14, 14, 256)  0           conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 14, 14, 256)  1024        lambda_159[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_160 (Lambda)             (None, 14, 14, 256)  0           conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 14, 14, 256)  590080      lambda_160[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_161 (Lambda)             (None, 14, 14, 256)  0           conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_bn (BatchNormal (None, 14, 14, 256)  1024        lambda_161[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block19_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_162 (Lambda)             (None, 14, 14, 256)  0           conv4_block19_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      lambda_162[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_163 (Lambda)             (None, 14, 14, 1024) 0           conv4_block19_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_3_bn (BatchNormal (None, 14, 14, 1024) 4096        lambda_163[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_164 (Lambda)             (None, 14, 14, 1024) 0           conv4_block19_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_add (Add)         (None, 14, 14, 1024) 0           conv4_block18_out[0][0]          \n",
      "                                                                 lambda_164[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_out (Activation)  (None, 14, 14, 1024) 0           conv4_block19_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block19_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_165 (Lambda)             (None, 14, 14, 256)  0           conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 14, 14, 256)  1024        lambda_165[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_166 (Lambda)             (None, 14, 14, 256)  0           conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 14, 14, 256)  590080      lambda_166[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_167 (Lambda)             (None, 14, 14, 256)  0           conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_bn (BatchNormal (None, 14, 14, 256)  1024        lambda_167[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block20_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_168 (Lambda)             (None, 14, 14, 256)  0           conv4_block20_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      lambda_168[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_169 (Lambda)             (None, 14, 14, 1024) 0           conv4_block20_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_3_bn (BatchNormal (None, 14, 14, 1024) 4096        lambda_169[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_170 (Lambda)             (None, 14, 14, 1024) 0           conv4_block20_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_add (Add)         (None, 14, 14, 1024) 0           conv4_block19_out[0][0]          \n",
      "                                                                 lambda_170[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_out (Activation)  (None, 14, 14, 1024) 0           conv4_block20_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block20_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_171 (Lambda)             (None, 14, 14, 256)  0           conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 14, 14, 256)  1024        lambda_171[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_172 (Lambda)             (None, 14, 14, 256)  0           conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 14, 14, 256)  590080      lambda_172[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_173 (Lambda)             (None, 14, 14, 256)  0           conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_bn (BatchNormal (None, 14, 14, 256)  1024        lambda_173[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block21_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_174 (Lambda)             (None, 14, 14, 256)  0           conv4_block21_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      lambda_174[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_175 (Lambda)             (None, 14, 14, 1024) 0           conv4_block21_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_3_bn (BatchNormal (None, 14, 14, 1024) 4096        lambda_175[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_176 (Lambda)             (None, 14, 14, 1024) 0           conv4_block21_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_add (Add)         (None, 14, 14, 1024) 0           conv4_block20_out[0][0]          \n",
      "                                                                 lambda_176[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_out (Activation)  (None, 14, 14, 1024) 0           conv4_block21_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block21_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_177 (Lambda)             (None, 14, 14, 256)  0           conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 14, 14, 256)  1024        lambda_177[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_178 (Lambda)             (None, 14, 14, 256)  0           conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 14, 14, 256)  590080      lambda_178[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_179 (Lambda)             (None, 14, 14, 256)  0           conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_bn (BatchNormal (None, 14, 14, 256)  1024        lambda_179[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block22_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_180 (Lambda)             (None, 14, 14, 256)  0           conv4_block22_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      lambda_180[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_181 (Lambda)             (None, 14, 14, 1024) 0           conv4_block22_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_3_bn (BatchNormal (None, 14, 14, 1024) 4096        lambda_181[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_182 (Lambda)             (None, 14, 14, 1024) 0           conv4_block22_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_add (Add)         (None, 14, 14, 1024) 0           conv4_block21_out[0][0]          \n",
      "                                                                 lambda_182[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_out (Activation)  (None, 14, 14, 1024) 0           conv4_block22_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 14, 14, 256)  262400      conv4_block22_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_183 (Lambda)             (None, 14, 14, 256)  0           conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 14, 14, 256)  1024        lambda_183[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 14, 14, 256)  0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_184 (Lambda)             (None, 14, 14, 256)  0           conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 14, 14, 256)  590080      lambda_184[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_185 (Lambda)             (None, 14, 14, 256)  0           conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_bn (BatchNormal (None, 14, 14, 256)  1024        lambda_185[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_relu (Activatio (None, 14, 14, 256)  0           conv4_block23_2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lambda_186 (Lambda)             (None, 14, 14, 256)  0           conv4_block23_2_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_conv (Conv2D)   (None, 14, 14, 1024) 263168      lambda_186[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_187 (Lambda)             (None, 14, 14, 1024) 0           conv4_block23_3_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_3_bn (BatchNormal (None, 14, 14, 1024) 4096        lambda_187[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_188 (Lambda)             (None, 14, 14, 1024) 0           conv4_block23_3_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_add (Add)         (None, 14, 14, 1024) 0           conv4_block22_out[0][0]          \n",
      "                                                                 lambda_188[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_out (Activation)  (None, 14, 14, 1024) 0           conv4_block23_add[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block23_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_191 (Lambda)             (None, 7, 7, 512)    0           conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        lambda_191[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_192 (Lambda)             (None, 7, 7, 512)    0           conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     lambda_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_193 (Lambda)             (None, 7, 7, 512)    0           conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        lambda_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_194 (Lambda)             (None, 7, 7, 512)    0           conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block23_out[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     lambda_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_189 (Lambda)             (None, 7, 7, 2048)   0           conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "lambda_195 (Lambda)             (None, 7, 7, 2048)   0           conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        lambda_189[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        lambda_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_190 (Lambda)             (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_196 (Lambda)             (None, 7, 7, 2048)   0           conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           lambda_190[0][0]                 \n",
      "                                                                 lambda_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_197 (Lambda)             (None, 7, 7, 512)    0           conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        lambda_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_198 (Lambda)             (None, 7, 7, 512)    0           conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     lambda_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_199 (Lambda)             (None, 7, 7, 512)    0           conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        lambda_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_200 (Lambda)             (None, 7, 7, 512)    0           conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     lambda_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_201 (Lambda)             (None, 7, 7, 2048)   0           conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        lambda_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_202 (Lambda)             (None, 7, 7, 2048)   0           conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 lambda_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "lambda_203 (Lambda)             (None, 7, 7, 512)    0           conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        lambda_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_204 (Lambda)             (None, 7, 7, 512)    0           conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     lambda_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_205 (Lambda)             (None, 7, 7, 512)    0           conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        lambda_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_206 (Lambda)             (None, 7, 7, 512)    0           conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     lambda_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_207 (Lambda)             (None, 7, 7, 2048)   0           conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        lambda_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "lambda_208 (Lambda)             (None, 7, 7, 2048)   0           conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 lambda_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "probs (Dense)                   (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 44,707,176\n",
      "Trainable params: 44,601,832\n",
      "Non-trainable params: 105,344\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training data pkl\n",
    "fp_name = '../../data/pkl_resnet/'+str(p)+'_'+str(model_name)+'_train_no_lesion_performance.txt'\n",
    "fp = open(fp_name,'a+')\n",
    "im_temp = preprocess_image_batch(im_train,img_size=(256,256), crop_size=(224,224), color_mode=\"rgb\")\n",
    "out = model.predict(im_temp)\n",
    "\n",
    "true_valid_wids = []\n",
    "for i in im_train:\n",
    "        temp1 = i.split('/')[4]\n",
    "        temp = temp1.split('.')[0].split('_')[2]\n",
    "        true_valid_wids.append(truth[int(temp)][1])\n",
    "\n",
    "predicted_valid_wids = []\n",
    "for i in range(len(im_train)):\n",
    "    #print(im_list[i], pprint_output(out[i]), true_wids[i])\n",
    "    predicted_valid_wids.append(pprint_output(out[i]))\n",
    "\n",
    "count, error  = top5accuracy(true_valid_wids, predicted_valid_wids)\n",
    "\n",
    "fp.write(str(p)+' '+str(count)+' '+str(len(im_train))+' '+str(error)+'\\n')\n",
    "\n",
    "\n",
    "print(len(true_valid_wids), len(predicted_valid_wids), len(im_train))\n",
    "print(count, error)\n",
    "\n",
    "\n",
    "#}\n",
    "# Code snippet to get the activation values and saving information{\n",
    "data = np.array([])\n",
    "\n",
    "i = 0\n",
    "result ={}\n",
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    #print(layer.name, len(weights))\n",
    "    if len(weights) > 0:\n",
    "        activations = get_activations(model,i,im_temp)\n",
    "        if result.get(layer.name, None) is None:\n",
    "            result[layer.name] = activations[0]\n",
    "            temp = np.mean(activations[0], axis=0).ravel()\n",
    "            if layer.name != 'probs':\n",
    "                print(layer.name,len(weights),len(activations), activations[0].shape, np.mean(activations[0], axis=0).shape, temp.shape)\n",
    "                data = np.append(data, temp)\n",
    "    i += 1\n",
    "\n",
    "print(data.shape)\n",
    "fp.close()\n",
    "with open('../../data/pkl_resnet/'+str(p)+'_train_'+model_name+'.pkl', 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 39 39\n",
      "36 0.07692307692307687\n",
      "conv1_conv 2 1 (39, 112, 112, 64) (112, 112, 64) (802816,)\n",
      "conv1_bn 4 1 (39, 112, 112, 64) (112, 112, 64) (802816,)\n",
      "conv2_block1_1_conv 2 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block1_1_bn 4 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block1_2_conv 2 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block1_2_bn 4 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block1_0_conv 2 1 (39, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv2_block1_3_conv 2 1 (39, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv2_block1_0_bn 4 1 (39, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv2_block1_3_bn 4 1 (39, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv2_block2_1_conv 2 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block2_1_bn 4 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block2_2_conv 2 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block2_2_bn 4 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block2_3_conv 2 1 (39, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv2_block2_3_bn 4 1 (39, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv2_block3_1_conv 2 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block3_1_bn 4 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block3_2_conv 2 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block3_2_bn 4 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block3_3_conv 2 1 (39, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv2_block3_3_bn 4 1 (39, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv3_block1_1_conv 2 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block1_1_bn 4 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block1_2_conv 2 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block1_2_bn 4 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block1_0_conv 2 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block1_3_conv 2 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block1_0_bn 4 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block1_3_bn 4 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block2_1_conv 2 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block2_1_bn 4 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block2_2_conv 2 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block2_2_bn 4 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block2_3_conv 2 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block2_3_bn 4 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block3_1_conv 2 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block3_1_bn 4 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block3_2_conv 2 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block3_2_bn 4 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block3_3_conv 2 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block3_3_bn 4 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block4_1_conv 2 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block4_1_bn 4 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block4_2_conv 2 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block4_2_bn 4 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block4_3_conv 2 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block4_3_bn 4 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv4_block1_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block1_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block1_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block1_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block1_0_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block1_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block1_0_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block1_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block2_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block2_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block2_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block2_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block2_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block2_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block3_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block3_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block3_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block3_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block3_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block3_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block4_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block4_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block4_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block4_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block4_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block4_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block5_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block5_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block5_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block5_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block5_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block5_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block6_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block6_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block6_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block6_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block6_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block6_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block7_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block7_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block7_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block7_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block7_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block7_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block8_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block8_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block8_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block8_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block8_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block8_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block9_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block9_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block9_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block9_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block9_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block9_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block10_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block10_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block10_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block10_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block10_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block10_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block11_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block11_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block11_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block11_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block11_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block11_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block12_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block12_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block12_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block12_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block12_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block12_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block13_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block13_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block13_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block13_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4_block13_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block13_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block14_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block14_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block14_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block14_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block14_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block14_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block15_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block15_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block15_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block15_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block15_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block15_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block16_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block16_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block16_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block16_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block16_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block16_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block17_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block17_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block17_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block17_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block17_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block17_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block18_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block18_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block18_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block18_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block18_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block18_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block19_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block19_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block19_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block19_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block19_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block19_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block20_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block20_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block20_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block20_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block20_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block20_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block21_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block21_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block21_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block21_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block21_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block21_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block22_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block22_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block22_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block22_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block22_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block22_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block23_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block23_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block23_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block23_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block23_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block23_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv5_block1_1_conv 2 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block1_1_bn 4 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block1_2_conv 2 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block1_2_bn 4 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block1_0_conv 2 1 (39, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "conv5_block1_3_conv 2 1 (39, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "conv5_block1_0_bn 4 1 (39, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "conv5_block1_3_bn 4 1 (39, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "conv5_block2_1_conv 2 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block2_1_bn 4 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block2_2_conv 2 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block2_2_bn 4 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block2_3_conv 2 1 (39, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "conv5_block2_3_bn 4 1 (39, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "conv5_block3_1_conv 2 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block3_1_bn 4 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block3_2_conv 2 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block3_2_bn 4 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block3_3_conv 2 1 (39, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "conv5_block3_3_bn 4 1 (39, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "(31410176,)\n"
     ]
    }
   ],
   "source": [
    "#Testing data pkl\n",
    "fp_name = '../../data/pkl/'+str(p)+'_'+str(model_name)+'_test_no_lesion_performance.txt'\n",
    "fp = open(fp_name,'a+')\n",
    "\n",
    "im_temp = preprocess_image_batch(im_test,img_size=(256,256), crop_size=(224,224), color_mode=\"rgb\")\n",
    "out = model.predict(im_temp,batch_size=64)\n",
    "\n",
    "true_valid_wids = []\n",
    "for i in im_test:\n",
    "        temp1 = i.split('/')[4]\n",
    "        temp = temp1.split('.')[0].split('_')[2]\n",
    "        true_valid_wids.append(truth[int(temp)][1])\n",
    "\n",
    "predicted_valid_wids = []\n",
    "for i in range(len(im_test)):\n",
    "    #print im_list[i], pprint_output(out[i]), true_wids[i]\n",
    "    predicted_valid_wids.append(pprint_output(out[i]))\n",
    "\n",
    "count, error  = top5accuracy(true_valid_wids, predicted_valid_wids)\n",
    "\n",
    "fp.write(str(p)+' '+str(count)+' '+str(len(im_test))+' '+str(error)+'\\n')\n",
    "\n",
    "\n",
    "print(len(true_valid_wids), len(predicted_valid_wids), len(im_test))\n",
    "print(count, error)\n",
    "\n",
    "\n",
    "#}\n",
    "# Code snippet to get the activation values and saving information{\n",
    "data = np.array([])\n",
    "\n",
    "i = 0\n",
    "result ={}\n",
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    if len(weights) > 0:\n",
    "        activations = get_activations(model,i,im_temp)\n",
    "        if result.get(layer.name, None) is None:\n",
    "            result[layer.name] = activations[0]\n",
    "            temp = np.mean(activations[0], axis=0).ravel()\n",
    "            if layer.name != 'probs':\n",
    "                print(layer.name,len(weights),len(activations), activations[0].shape, np.mean(activations[0], axis=0).shape, temp.shape)\n",
    "                data = np.append(data, temp)\n",
    "    i += 1\n",
    "    \n",
    "print(data.shape)\n",
    "fp.close()\n",
    "with open('../../data/pkl/'+str(p)+'_test_'+model_name+'.pkl', 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Fold:  1\n",
      "39 39 39\n",
      "34 0.1282051282051282\n",
      "conv1_conv 2 1 (39, 112, 112, 64) (112, 112, 64) (802816,)\n",
      "conv1_bn 4 1 (39, 112, 112, 64) (112, 112, 64) (802816,)\n",
      "conv2_block1_1_conv 2 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block1_1_bn 4 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block1_2_conv 2 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block1_2_bn 4 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block1_0_conv 2 1 (39, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv2_block1_3_conv 2 1 (39, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv2_block1_0_bn 4 1 (39, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv2_block1_3_bn 4 1 (39, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv2_block2_1_conv 2 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block2_1_bn 4 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block2_2_conv 2 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block2_2_bn 4 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block2_3_conv 2 1 (39, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv2_block2_3_bn 4 1 (39, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv2_block3_1_conv 2 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block3_1_bn 4 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block3_2_conv 2 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block3_2_bn 4 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block3_3_conv 2 1 (39, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv2_block3_3_bn 4 1 (39, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv3_block1_1_conv 2 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block1_1_bn 4 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block1_2_conv 2 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block1_2_bn 4 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block1_0_conv 2 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block1_3_conv 2 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block1_0_bn 4 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block1_3_bn 4 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block2_1_conv 2 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block2_1_bn 4 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block2_2_conv 2 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block2_2_bn 4 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block2_3_conv 2 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block2_3_bn 4 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block3_1_conv 2 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block3_1_bn 4 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block3_2_conv 2 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block3_2_bn 4 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block3_3_conv 2 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block3_3_bn 4 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block4_1_conv 2 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block4_1_bn 4 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block4_2_conv 2 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block4_2_bn 4 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block4_3_conv 2 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block4_3_bn 4 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv4_block1_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block1_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block1_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block1_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block1_0_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block1_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block1_0_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block1_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block2_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block2_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block2_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block2_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block2_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block2_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block3_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block3_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block3_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block3_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block3_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block3_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block4_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block4_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block4_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block4_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block4_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block4_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block5_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block5_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block5_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block5_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block5_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block5_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block6_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block6_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block6_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block6_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block6_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block6_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block7_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block7_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block7_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block7_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block7_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block7_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block8_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block8_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block8_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block8_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block8_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block8_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block9_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block9_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block9_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block9_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block9_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block9_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block10_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block10_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block10_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block10_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block10_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block10_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block11_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block11_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block11_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block11_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block11_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block11_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block12_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block12_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block12_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block12_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block12_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block12_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block13_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block13_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block13_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block13_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4_block13_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block13_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block14_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block14_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block14_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block14_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block14_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block14_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block15_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block15_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block15_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block15_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block15_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block15_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block16_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block16_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block16_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block16_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block16_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block16_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block17_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block17_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block17_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block17_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block17_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block17_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block18_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block18_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block18_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block18_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block18_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block18_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block19_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block19_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block19_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block19_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block19_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block19_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block20_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block20_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block20_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block20_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block20_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block20_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block21_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block21_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block21_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block21_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block21_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block21_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block22_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block22_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block22_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block22_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block22_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block22_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block23_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block23_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block23_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block23_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block23_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block23_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv5_block1_1_conv 2 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block1_1_bn 4 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block1_2_conv 2 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block1_2_bn 4 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block1_0_conv 2 1 (39, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "conv5_block1_3_conv 2 1 (39, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "conv5_block1_0_bn 4 1 (39, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "conv5_block1_3_bn 4 1 (39, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "conv5_block2_1_conv 2 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block2_1_bn 4 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block2_2_conv 2 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block2_2_bn 4 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block2_3_conv 2 1 (39, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "conv5_block2_3_bn 4 1 (39, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "conv5_block3_1_conv 2 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block3_1_bn 4 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block3_2_conv 2 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block3_2_bn 4 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block3_3_conv 2 1 (39, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "conv5_block3_3_bn 4 1 (39, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "(31410176,)\n",
      "Starting Fold:  2\n",
      "39 39 39\n",
      "30 0.23076923076923073\n",
      "conv1_conv 2 1 (39, 112, 112, 64) (112, 112, 64) (802816,)\n",
      "conv1_bn 4 1 (39, 112, 112, 64) (112, 112, 64) (802816,)\n",
      "conv2_block1_1_conv 2 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block1_1_bn 4 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block1_2_conv 2 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block1_2_bn 4 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block1_0_conv 2 1 (39, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv2_block1_3_conv 2 1 (39, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv2_block1_0_bn 4 1 (39, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv2_block1_3_bn 4 1 (39, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv2_block2_1_conv 2 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block2_1_bn 4 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block2_2_conv 2 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block2_2_bn 4 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block2_3_conv 2 1 (39, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv2_block2_3_bn 4 1 (39, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv2_block3_1_conv 2 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block3_1_bn 4 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block3_2_conv 2 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block3_2_bn 4 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block3_3_conv 2 1 (39, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv2_block3_3_bn 4 1 (39, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv3_block1_1_conv 2 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block1_1_bn 4 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block1_2_conv 2 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block1_2_bn 4 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block1_0_conv 2 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block1_3_conv 2 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block1_0_bn 4 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block1_3_bn 4 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block2_1_conv 2 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block2_1_bn 4 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block2_2_conv 2 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block2_2_bn 4 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block2_3_conv 2 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block2_3_bn 4 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block3_1_conv 2 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block3_1_bn 4 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block3_2_conv 2 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block3_2_bn 4 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block3_3_conv 2 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block3_3_bn 4 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block4_1_conv 2 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block4_1_bn 4 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv3_block4_2_conv 2 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block4_2_bn 4 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block4_3_conv 2 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block4_3_bn 4 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv4_block1_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block1_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block1_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block1_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block1_0_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block1_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block1_0_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block1_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block2_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block2_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block2_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block2_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block2_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block2_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block3_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block3_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block3_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block3_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block3_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block3_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block4_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block4_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block4_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block4_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block4_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block4_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block5_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block5_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block5_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block5_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block5_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block5_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block6_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block6_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block6_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block6_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block6_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block6_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block7_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block7_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block7_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block7_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block7_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block7_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block8_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block8_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block8_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block8_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block8_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block8_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block9_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block9_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block9_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block9_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block9_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block9_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block10_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block10_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block10_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block10_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block10_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block10_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block11_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block11_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block11_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block11_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block11_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block11_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block12_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block12_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block12_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block12_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block12_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block12_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block13_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block13_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block13_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block13_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block13_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block13_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block14_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block14_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block14_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block14_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block14_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block14_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block15_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block15_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block15_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block15_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block15_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block15_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block16_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block16_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block16_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block16_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block16_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block16_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block17_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block17_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block17_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block17_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block17_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block17_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block18_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block18_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block18_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block18_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block18_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block18_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block19_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block19_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block19_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block19_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block19_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block19_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block20_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block20_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block20_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block20_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block20_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4_block20_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block21_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block21_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block21_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block21_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block21_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block21_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block22_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block22_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block22_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block22_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block22_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block22_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block23_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block23_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block23_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block23_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block23_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block23_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv5_block1_1_conv 2 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block1_1_bn 4 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block1_2_conv 2 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block1_2_bn 4 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block1_0_conv 2 1 (39, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "conv5_block1_3_conv 2 1 (39, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "conv5_block1_0_bn 4 1 (39, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "conv5_block1_3_bn 4 1 (39, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "conv5_block2_1_conv 2 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block2_1_bn 4 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block2_2_conv 2 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block2_2_bn 4 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block2_3_conv 2 1 (39, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "conv5_block2_3_bn 4 1 (39, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "conv5_block3_1_conv 2 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block3_1_bn 4 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block3_2_conv 2 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block3_2_bn 4 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block3_3_conv 2 1 (39, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "conv5_block3_3_bn 4 1 (39, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "(31410176,)\n",
      "Starting Fold:  3\n",
      "39 39 39\n",
      "37 0.05128205128205132\n",
      "conv1_conv 2 1 (39, 112, 112, 64) (112, 112, 64) (802816,)\n",
      "conv1_bn 4 1 (39, 112, 112, 64) (112, 112, 64) (802816,)\n",
      "conv2_block1_1_conv 2 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block1_1_bn 4 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block1_2_conv 2 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block1_2_bn 4 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block1_0_conv 2 1 (39, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv2_block1_3_conv 2 1 (39, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv2_block1_0_bn 4 1 (39, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv2_block1_3_bn 4 1 (39, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv2_block2_1_conv 2 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block2_1_bn 4 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block2_2_conv 2 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block2_2_bn 4 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block2_3_conv 2 1 (39, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv2_block2_3_bn 4 1 (39, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv2_block3_1_conv 2 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block3_1_bn 4 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block3_2_conv 2 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block3_2_bn 4 1 (39, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block3_3_conv 2 1 (39, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv2_block3_3_bn 4 1 (39, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv3_block1_1_conv 2 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block1_1_bn 4 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block1_2_conv 2 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block1_2_bn 4 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block1_0_conv 2 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block1_3_conv 2 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block1_0_bn 4 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block1_3_bn 4 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block2_1_conv 2 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block2_1_bn 4 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block2_2_conv 2 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block2_2_bn 4 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block2_3_conv 2 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block2_3_bn 4 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block3_1_conv 2 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block3_1_bn 4 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block3_2_conv 2 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block3_2_bn 4 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block3_3_conv 2 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block3_3_bn 4 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block4_1_conv 2 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block4_1_bn 4 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block4_2_conv 2 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block4_2_bn 4 1 (39, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block4_3_conv 2 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block4_3_bn 4 1 (39, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv4_block1_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block1_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block1_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block1_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block1_0_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block1_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block1_0_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block1_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block2_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block2_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block2_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block2_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block2_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block2_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block3_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block3_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block3_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block3_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block3_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block3_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block4_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block4_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block4_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block4_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block4_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block4_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block5_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block5_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block5_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block5_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block5_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block5_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block6_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block6_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block6_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block6_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block6_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block6_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block7_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block7_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4_block7_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block7_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block7_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block7_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block8_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block8_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block8_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block8_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block8_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block8_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block9_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block9_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block9_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block9_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block9_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block9_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block10_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block10_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block10_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block10_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block10_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block10_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block11_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block11_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block11_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block11_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block11_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block11_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block12_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block12_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block12_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block12_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block12_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block12_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block13_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block13_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block13_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block13_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block13_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block13_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block14_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block14_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block14_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block14_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block14_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block14_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block15_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block15_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block15_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block15_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block15_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block15_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block16_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block16_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block16_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block16_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block16_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block16_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block17_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block17_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block17_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block17_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block17_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block17_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block18_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block18_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block18_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block18_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block18_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block18_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block19_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block19_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block19_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block19_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block19_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block19_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block20_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block20_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block20_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block20_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block20_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block20_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block21_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block21_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block21_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block21_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block21_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block21_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block22_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block22_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block22_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block22_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block22_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block22_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block23_1_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block23_1_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block23_2_conv 2 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block23_2_bn 4 1 (39, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block23_3_conv 2 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block23_3_bn 4 1 (39, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv5_block1_1_conv 2 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block1_1_bn 4 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block1_2_conv 2 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block1_2_bn 4 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block1_0_conv 2 1 (39, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "conv5_block1_3_conv 2 1 (39, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "conv5_block1_0_bn 4 1 (39, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "conv5_block1_3_bn 4 1 (39, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "conv5_block2_1_conv 2 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block2_1_bn 4 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block2_2_conv 2 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block2_2_bn 4 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block2_3_conv 2 1 (39, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "conv5_block2_3_bn 4 1 (39, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "conv5_block3_1_conv 2 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block3_1_bn 4 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block3_2_conv 2 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block3_2_bn 4 1 (39, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block3_3_conv 2 1 (39, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "conv5_block3_3_bn 4 1 (39, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "(31410176,)\n",
      "Starting Fold:  4\n",
      "38 38 38\n",
      "31 0.1842105263157895\n",
      "conv1_conv 2 1 (38, 112, 112, 64) (112, 112, 64) (802816,)\n",
      "conv1_bn 4 1 (38, 112, 112, 64) (112, 112, 64) (802816,)\n",
      "conv2_block1_1_conv 2 1 (38, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block1_1_bn 4 1 (38, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block1_2_conv 2 1 (38, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block1_2_bn 4 1 (38, 56, 56, 64) (56, 56, 64) (200704,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2_block1_0_conv 2 1 (38, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv2_block1_3_conv 2 1 (38, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv2_block1_0_bn 4 1 (38, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv2_block1_3_bn 4 1 (38, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv2_block2_1_conv 2 1 (38, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block2_1_bn 4 1 (38, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block2_2_conv 2 1 (38, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block2_2_bn 4 1 (38, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block2_3_conv 2 1 (38, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv2_block2_3_bn 4 1 (38, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv2_block3_1_conv 2 1 (38, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block3_1_bn 4 1 (38, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block3_2_conv 2 1 (38, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block3_2_bn 4 1 (38, 56, 56, 64) (56, 56, 64) (200704,)\n",
      "conv2_block3_3_conv 2 1 (38, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv2_block3_3_bn 4 1 (38, 56, 56, 256) (56, 56, 256) (802816,)\n",
      "conv3_block1_1_conv 2 1 (38, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block1_1_bn 4 1 (38, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block1_2_conv 2 1 (38, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block1_2_bn 4 1 (38, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block1_0_conv 2 1 (38, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block1_3_conv 2 1 (38, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block1_0_bn 4 1 (38, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block1_3_bn 4 1 (38, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block2_1_conv 2 1 (38, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block2_1_bn 4 1 (38, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block2_2_conv 2 1 (38, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block2_2_bn 4 1 (38, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block2_3_conv 2 1 (38, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block2_3_bn 4 1 (38, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block3_1_conv 2 1 (38, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block3_1_bn 4 1 (38, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block3_2_conv 2 1 (38, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block3_2_bn 4 1 (38, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block3_3_conv 2 1 (38, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block3_3_bn 4 1 (38, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block4_1_conv 2 1 (38, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block4_1_bn 4 1 (38, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block4_2_conv 2 1 (38, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block4_2_bn 4 1 (38, 28, 28, 128) (28, 28, 128) (100352,)\n",
      "conv3_block4_3_conv 2 1 (38, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv3_block4_3_bn 4 1 (38, 28, 28, 512) (28, 28, 512) (401408,)\n",
      "conv4_block1_1_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block1_1_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block1_2_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block1_2_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block1_0_conv 2 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block1_3_conv 2 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block1_0_bn 4 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block1_3_bn 4 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block2_1_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block2_1_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block2_2_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block2_2_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block2_3_conv 2 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block2_3_bn 4 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block3_1_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block3_1_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block3_2_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block3_2_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block3_3_conv 2 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block3_3_bn 4 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block4_1_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block4_1_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block4_2_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block4_2_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block4_3_conv 2 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block4_3_bn 4 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block5_1_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block5_1_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block5_2_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block5_2_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block5_3_conv 2 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block5_3_bn 4 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block6_1_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block6_1_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block6_2_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block6_2_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block6_3_conv 2 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block6_3_bn 4 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block7_1_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block7_1_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block7_2_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block7_2_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block7_3_conv 2 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block7_3_bn 4 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block8_1_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block8_1_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block8_2_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block8_2_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block8_3_conv 2 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block8_3_bn 4 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block9_1_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block9_1_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block9_2_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block9_2_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block9_3_conv 2 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block9_3_bn 4 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block10_1_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block10_1_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block10_2_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block10_2_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block10_3_conv 2 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block10_3_bn 4 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block11_1_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block11_1_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block11_2_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block11_2_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block11_3_conv 2 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block11_3_bn 4 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block12_1_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block12_1_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block12_2_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block12_2_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block12_3_conv 2 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block12_3_bn 4 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block13_1_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block13_1_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block13_2_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block13_2_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block13_3_conv 2 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block13_3_bn 4 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block14_1_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block14_1_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block14_2_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block14_2_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv4_block14_3_conv 2 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block14_3_bn 4 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block15_1_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block15_1_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block15_2_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block15_2_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block15_3_conv 2 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block15_3_bn 4 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block16_1_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block16_1_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block16_2_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block16_2_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block16_3_conv 2 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block16_3_bn 4 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block17_1_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block17_1_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block17_2_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block17_2_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block17_3_conv 2 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block17_3_bn 4 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block18_1_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block18_1_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block18_2_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block18_2_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block18_3_conv 2 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block18_3_bn 4 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block19_1_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block19_1_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block19_2_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block19_2_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block19_3_conv 2 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block19_3_bn 4 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block20_1_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block20_1_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block20_2_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block20_2_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block20_3_conv 2 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block20_3_bn 4 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block21_1_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block21_1_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block21_2_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block21_2_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block21_3_conv 2 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block21_3_bn 4 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block22_1_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block22_1_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block22_2_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block22_2_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block22_3_conv 2 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block22_3_bn 4 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block23_1_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block23_1_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block23_2_conv 2 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block23_2_bn 4 1 (38, 14, 14, 256) (14, 14, 256) (50176,)\n",
      "conv4_block23_3_conv 2 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv4_block23_3_bn 4 1 (38, 14, 14, 1024) (14, 14, 1024) (200704,)\n",
      "conv5_block1_1_conv 2 1 (38, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block1_1_bn 4 1 (38, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block1_2_conv 2 1 (38, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block1_2_bn 4 1 (38, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block1_0_conv 2 1 (38, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "conv5_block1_3_conv 2 1 (38, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "conv5_block1_0_bn 4 1 (38, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "conv5_block1_3_bn 4 1 (38, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "conv5_block2_1_conv 2 1 (38, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block2_1_bn 4 1 (38, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block2_2_conv 2 1 (38, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block2_2_bn 4 1 (38, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block2_3_conv 2 1 (38, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "conv5_block2_3_bn 4 1 (38, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "conv5_block3_1_conv 2 1 (38, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block3_1_bn 4 1 (38, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block3_2_conv 2 1 (38, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block3_2_bn 4 1 (38, 7, 7, 512) (7, 7, 512) (25088,)\n",
      "conv5_block3_3_conv 2 1 (38, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "conv5_block3_3_bn 4 1 (38, 7, 7, 2048) (7, 7, 2048) (100352,)\n",
      "(31410176,)\n"
     ]
    }
   ],
   "source": [
    "out_r = []\n",
    "\n",
    "image_list_test = '../../data/pkl/'+p+'_'+str(model_name)+'_image_list_test.txt'\n",
    "with open(image_list_test,'w+') as f:\n",
    "    for i in im_test:\n",
    "        f.write(i+'\\n')\n",
    "\n",
    "kf = KFold(n_splits= k)\n",
    "fold = 1\n",
    "fp_name = '../../data/pkl/'+str(p)+'_no_lesion_performance.txt'\n",
    "fp = open(fp_name,'a+')\n",
    "for train_index, valid_index in kf.split(im_train):\n",
    "    print(\"Starting Fold: \", fold)\n",
    "    im_valid_train = [im_train[i] for i in train_index] \n",
    "    im_valid_test = [im_train[i] for i in valid_index]\n",
    "    \n",
    "    image_list_train = '../../data/pkl/'+p+'_image_list_train_fold_'+str(fold)+'.txt'\n",
    "    with open(image_list_train,'w+') as f:\n",
    "        for i in im_valid_train:\n",
    "            f.write(i+'\\n')\n",
    "    \n",
    "    image_list_valid = '../../data/pkl/'+p+'_image_list_valid_fold_'+str(fold)+'.txt'\n",
    "    with open(image_list_valid,'w+') as f:\n",
    "        for i in im_valid_test:\n",
    "            f.write(i+'\\n')\n",
    "    \n",
    "   \n",
    "    im_temp = preprocess_image_batch(im_valid_test,img_size=(256,256), crop_size=(224,224), color_mode=\"rgb\")\n",
    "    out = model.predict(im_temp,batch_size=64)\n",
    "\n",
    "    true_valid_wids = []\n",
    "    for i in im_valid_test:\n",
    "            temp1 = i.split('/')[4]\n",
    "            temp = temp1.split('.')[0].split('_')[2]\n",
    "            true_valid_wids.append(truth[int(temp)][1])\n",
    "    \n",
    "    predicted_valid_wids = []\n",
    "    for i in range(len(im_valid_test)):\n",
    "        #print im_list[i], pprint_output(out[i]), true_wids[i]\n",
    "        predicted_valid_wids.append(pprint_output(out[i]))\n",
    "        \n",
    "    count, error  = top5accuracy(true_valid_wids, predicted_valid_wids)\n",
    "    \n",
    "    fp.write(str(p)+' '+str(fold)+' '+str(count)+' '+str(len(im_valid_test))+' '+str(error)+'\\n')\n",
    "\n",
    "    \n",
    "    print(len(true_valid_wids), len(predicted_valid_wids), len(im_valid_test))\n",
    "    print(count, error)\n",
    "    \n",
    "    \n",
    "    #}\n",
    "    # Code snippet to get the activation values and saving information{\n",
    "    data = np.array([])\n",
    "\n",
    "    i = 0\n",
    "    result ={}\n",
    "    for layer in model.layers:\n",
    "        weights = layer.get_weights()\n",
    "        if len(weights) > 0:\n",
    "            activations = get_activations(model,i,im_temp)\n",
    "            if result.get(layer.name, None) is None:\n",
    "                result[layer.name] = activations[0]\n",
    "                temp = np.mean(activations[0], axis=0).ravel()\n",
    "                if layer.name != 'probs':\n",
    "                    print(layer.name,len(weights),len(activations), activations[0].shape, np.mean(activations[0], axis=0).shape, temp.shape)\n",
    "                    data = np.append(data, temp)\n",
    "        i += 1\n",
    "    print(data.shape)\n",
    "    out_r.append(data)\n",
    "    fold += 1\n",
    "    \n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inanimate_fold_1_train_ResNet101 31410176\n",
      "inanimate_fold_2_train_ResNet101 31410176\n",
      "inanimate_fold_3_train_ResNet101 31410176\n",
      "inanimate_fold_4_train_ResNet101 31410176\n"
     ]
    }
   ],
   "source": [
    "#Saving all the data into pkl files\n",
    "for i in range(k):\n",
    "    name = p+'_fold_'+str(i+1)+'_train_'+model_name\n",
    "    out_data = out_r[i]\n",
    "    with open('../../data/pkl/'+name+'.pkl', 'wb') as f:\n",
    "        pickle.dump(out_data, f)\n",
    "    print(name, len(out_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from keras import backend as K \n",
    "\n",
    "K.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
