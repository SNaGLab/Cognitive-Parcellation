{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#To hide warnings export PYTHONWARNINGS=\"ignore\"\n",
    "#Imports{\n",
    "\n",
    "import os\n",
    "from os.path import dirname\n",
    "from os.path import join\n",
    "os.environ['KERAS_BACKEND'] = 'theano'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' #Cha\n",
    "\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.io import loadmat\n",
    "from scipy import stats\n",
    "#from scipy.interpolate import spline\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from scipy.stats import percentileofscore\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, MaxPooling2D, Input, ZeroPadding2D,merge,Lambda\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.models import Model\n",
    "from keras.utils.layer_utils import convert_all_kernels_in_model\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "from keras.engine import Layer\n",
    "from keras.layers.core import Lambda\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.layers.core import  Lambda\n",
    "from keras.regularizers import l2\n",
    "import cv2\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code snippet needed to read activation values from each layer of the pre-trained artificial neural networks\n",
    "def get_activations(model, layer, X_batch):\n",
    "    #keras.backend.function(inputs, outputs, updates=None)\n",
    "    get_activations = K.function([model.layers[0].input, K.learning_phase()], [model.layers[layer].output,])\n",
    "    #The learning phase flag is a bool tensor (0 = test, 1 = train)\n",
    "    activations = get_activations([X_batch,0])\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image_paths, image_height=224, image_width=224,color_mode='rgb'):\n",
    "    \"\"\"resize images to the appropriate dimensions\n",
    "    :param image_width:\n",
    "    :param image_height:\n",
    "    :param image: image\n",
    "    :return: image\n",
    "    \"\"\"\n",
    "    img_list = []\n",
    "    \n",
    "    for im_path in image_paths:\n",
    "        image = cv2.imread(im_path)\n",
    "        image = cv2.resize(image, (image_height, image_width))\n",
    "        \n",
    "        image = image.astype('float32')\n",
    "        image[:, :, 0] -= 123.68\n",
    "        image[:, :, 1] -= 116.779\n",
    "        image[:, :, 2] -= 103.939\n",
    "        if color_mode == 'bgr':\n",
    "            image = image.transpose((2, 0, 1))\n",
    "        \n",
    "        img_list.append(image)\n",
    "        \n",
    "    try:\n",
    "        img_batch = np.stack(img_list, axis=0)\n",
    "    except:\n",
    "        print im_path\n",
    "        raise ValueError('when img_size and crop_size are None, images'\n",
    "                ' in image_paths must have the same shapes.')\n",
    "    return img_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function to normalization across channels\n",
    "K.set_image_dim_ordering('th')\n",
    "def crosschannelnormalization(alpha=1e-4, k=2, beta=0.75, n=5, **kwargs):\n",
    "    \"\"\"\n",
    "    This is the function used for cross channel normalization in the original\n",
    "    Alexnet\n",
    "    \"\"\"\n",
    "    def f(X):\n",
    "        if K.image_dim_ordering()=='tf':\n",
    "            b, r, c, ch = X.get_shape()\n",
    "        else:\n",
    "            b, ch, r, c = X.shape\n",
    "\n",
    "        half = n // 2\n",
    "        square = K.square(X)\n",
    "        scale = k\n",
    "        if K.image_dim_ordering() == 'th':\n",
    "            extra_channels = K.spatial_2d_padding(K.permute_dimensions(square, (0, 2, 3, 1)), ((0,0),(half,half)))\n",
    "            extra_channels = K.permute_dimensions(extra_channels, (0, 3, 1, 2))\n",
    "            for i in range(n):\n",
    "                scale += alpha * extra_channels[:, i:i+ch, :, :]\n",
    "        if K.image_dim_ordering() == 'tf':\n",
    "            extra_channels = K.spatial_2d_padding(K.permute_dimensions(square, (0, 3, 1, 2)), (half, 0))\n",
    "            extra_channels = K.permute_dimensions(extra_channels, (0, 2, 3, 1))\n",
    "            for i in range(n):\n",
    "                scale += alpha * extra_channels[:, :, :, i:i+int(ch)]\n",
    "        scale = scale ** beta\n",
    "        return X / scale\n",
    "\n",
    "\n",
    "    return Lambda(f, output_shape=lambda input_shape: input_shape, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Function to split tensor\n",
    "def splittensor(axis=1, ratio_split=1, id_split=0, **kwargs):\n",
    "    def f(X):\n",
    "        div = K.shape(X)[axis] // ratio_split\n",
    "\n",
    "        if axis == 0:\n",
    "            output = X[id_split*div:(id_split+1)*div, :, :, :]\n",
    "        elif axis == 1:\n",
    "            output = X[:, id_split*div:(id_split+1)*div, :, :]\n",
    "        elif axis == 2:\n",
    "            output = X[:, :, id_split*div:(id_split+1)*div, :]\n",
    "        elif axis == 3:\n",
    "            output = X[:, :, :, id_split*div:(id_split+1)*div]\n",
    "        else:\n",
    "            raise ValueError(\"This axis is not possible\")\n",
    "        return output\n",
    "\n",
    "    def g(input_shape):\n",
    "        output_shape = list(input_shape)\n",
    "        output_shape[axis] = output_shape[axis] // ratio_split\n",
    "        return tuple(output_shape)\n",
    "\n",
    "\n",
    "    return Lambda(f, output_shape=lambda input_shape: g(input_shape), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alexnet layer architecture class\n",
    "def AlexNet(img_shape=(3, 227, 227), n_classes=1000, l2_reg=0.,weights_path=None, lambda_mask=None):\n",
    "\n",
    "    dim_ordering = K.image_dim_ordering()\n",
    "    print(dim_ordering)\n",
    "    if dim_ordering == 'th':\n",
    "        batch_index = 0\n",
    "        channel_index = 1\n",
    "        row_index = 2\n",
    "        col_index = 3\n",
    "    if dim_ordering == 'tf':\n",
    "        batch_index = 0\n",
    "        channel_index = 3\n",
    "        row_index = 1\n",
    "        col_index = 2\n",
    "        \n",
    "    \n",
    "    inputs = Input(img_shape)\n",
    "\n",
    "    conv_1 = Convolution2D(96, 11, 11, subsample=(4, 4), activation='relu',\n",
    "                           name='conv_1', W_regularizer=l2(l2_reg))(inputs)\n",
    "\n",
    "    if lambda_mask is not None:\n",
    "        conv_1_mask  = np.reshape(lambda_mask[0:290400], (96,55,55))\n",
    "    else:\n",
    "        conv_1_mask = np.ones(shape=((96, 55, 55)))\n",
    "    \n",
    "    conv_1_mask  = K.variable(conv_1_mask)\n",
    "    conv_1_lambda = Lambda(lambda x: x * conv_1_mask)(conv_1)\n",
    "\n",
    "    conv_2 = MaxPooling2D((3, 3), strides=(2, 2))(conv_1_lambda)\n",
    "    conv_2 = crosschannelnormalization(name=\"convpool_1\")(conv_2)\n",
    "    conv_2 = ZeroPadding2D((2, 2))(conv_2)\n",
    "    conv_2 = merge([\n",
    "        Convolution2D(128, 5, 5, activation=\"relu\", name='conv_2_'+str(i+1),\n",
    "                      W_regularizer=l2(l2_reg))(\n",
    "            splittensor(axis=channel_index, ratio_split=2, id_split=i)(conv_2)\n",
    "        ) for i in range(2)], mode='concat', concat_axis=channel_index, name=\"conv_2\")\n",
    "\n",
    "    if lambda_mask is not None:\n",
    "        conv_2_mask  = np.reshape(lambda_mask[290400:477024],(256, 27, 27) )\n",
    "    else:\n",
    "        conv_2_mask = np.ones(shape=((256, 27, 27)))\n",
    "        \n",
    "    conv_2_mask = K.variable(conv_2_mask)\n",
    "    conv_2_lambda = Lambda(lambda x: x * conv_2_mask)(conv_2)\n",
    "\n",
    "    conv_3 = MaxPooling2D((3, 3), strides=(2, 2))(conv_2_lambda)\n",
    "    conv_3 = crosschannelnormalization()(conv_3)\n",
    "    conv_3 = ZeroPadding2D((1, 1))(conv_3)\n",
    "    conv_3 = Convolution2D(384, 3, 3, activation='relu', name='conv_3',\n",
    "                           W_regularizer=l2(l2_reg))(conv_3)\n",
    "\n",
    "    if lambda_mask is not None:\n",
    "        conv_3_mask  = np.reshape(lambda_mask[477024:541920],(384, 13, 13))\n",
    "    else:\n",
    "        conv_3_mask = np.ones(shape=((384, 13, 13)))\n",
    "    \n",
    "    conv_3_mask = K.variable(conv_3_mask)\n",
    "    conv_3_lambda = Lambda(lambda x: x * conv_3_mask)(conv_3)\n",
    "\n",
    "    conv_4 = ZeroPadding2D((1, 1))(conv_3_lambda)\n",
    "    conv_4 = merge([\n",
    "        Convolution2D(192, 3, 3, activation=\"relu\", name='conv_4_'+str(i+1),\n",
    "                      W_regularizer=l2(l2_reg))(\n",
    "            splittensor(axis=channel_index, ratio_split=2, id_split=i)(conv_4)\n",
    "        ) for i in range(2)], mode='concat', concat_axis=channel_index, name=\"conv_4\")\n",
    "\n",
    "    if lambda_mask is not None:\n",
    "        conv_4_mask  = np.reshape(lambda_mask[541920:606816],(384, 13, 13))\n",
    "    else:\n",
    "        conv_4_mask = np.ones(shape=((384, 13, 13)))\n",
    "        \n",
    "    conv_4_mask = K.variable(conv_4_mask)\n",
    "    conv_4_lambda = Lambda(lambda x: x * conv_4_mask)(conv_4)\n",
    "\n",
    "    conv_5 = ZeroPadding2D((1, 1))(conv_4_lambda)\n",
    "    conv_5 = merge([\n",
    "        Convolution2D(128, 3, 3, activation=\"relu\", name='conv_5_'+str(i+1),\n",
    "                      W_regularizer=l2(l2_reg))(\n",
    "            splittensor(axis=channel_index, ratio_split=2, id_split=i)(conv_5)\n",
    "        ) for i in range(2)], mode='concat', concat_axis=channel_index, name=\"conv_5\")\n",
    "\n",
    "    if lambda_mask is not None:\n",
    "        conv_5_mask  = np.reshape(lambda_mask[606816:650080],(256, 13, 13))\n",
    "    else:\n",
    "        conv_5_mask = np.ones(shape=((256, 13, 13)))\n",
    "    \n",
    "    conv_5_mask = K.variable(conv_5_mask)\n",
    "    conv_5_lambda = Lambda(lambda x: x * conv_5_mask)(conv_5)\n",
    "\n",
    "    dense_1 = MaxPooling2D((3, 3), strides=(2, 2), name=\"convpool_5\")(conv_5_lambda)\n",
    "\n",
    "    dense_1 = Flatten(name=\"flatten\")(dense_1)\n",
    "    dense_1 = Dense(4096, activation='relu', name='dense_1',\n",
    "                    W_regularizer=l2(l2_reg))(dense_1)\n",
    "\n",
    "    if lambda_mask is not None:\n",
    "        dense_1_mask  = np.reshape(lambda_mask[650080:654176],(4096,))\n",
    "    else:\n",
    "        dense_1_mask = np.ones(shape=((4096,)))\n",
    "    \n",
    "    \n",
    "    dense_1_mask = K.variable(dense_1_mask)\n",
    "    dense_1_lambda = Lambda(lambda x: x * dense_1_mask)(dense_1)\n",
    "\n",
    "    dense_2 = Dropout(0.5)(dense_1_lambda)\n",
    "    dense_2 = Dense(4096, activation='relu', name='dense_2',\n",
    "                    W_regularizer=l2(l2_reg))(dense_2)\n",
    "\n",
    "    if lambda_mask is not None:\n",
    "        dense_2_mask  = np.reshape(lambda_mask[654176:658272],(4096,))\n",
    "    else:\n",
    "        dense_2_mask = np.ones(shape=((4096,)))\n",
    "    \n",
    "    dense_2_mask = K.variable(dense_2_mask)\n",
    "    dense_2_lambda = Lambda(lambda x: x * dense_2_mask)(dense_2)\n",
    "\n",
    "    dense_3 = Dropout(0.5)(dense_2_lambda)\n",
    "    if n_classes == 1000:\n",
    "        dense_3 = Dense(n_classes, name='dense_3',\n",
    "                        W_regularizer=l2(l2_reg))(dense_3)\n",
    "    else:\n",
    "        # We change the name so when loading the weights_file from a\n",
    "        # Imagenet pretrained model does not crash\n",
    "        dense_3 = Dense(n_classes, name='dense_3_new',\n",
    "                        W_regularizer=l2(l2_reg))(dense_3)\n",
    "\n",
    "\n",
    "    prediction = Activation(\"softmax\", name=\"softmax\")(dense_3)\n",
    "\n",
    "    model = Model(input=inputs, output=prediction)\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the details of all the 1000 classes and the function to conver the synset id to words{\n",
    "meta_clsloc_file = '../../data/meta_clsloc.mat'\n",
    "synsets = loadmat(meta_clsloc_file)['synsets'][0]\n",
    "synsets_imagenet_sorted = sorted([(int(s[0]), str(s[1][0])) for s in synsets[:1000]],key=lambda v: v[1])\n",
    "corr = {}\n",
    "for j in range(1000):\n",
    "    corr[synsets_imagenet_sorted[j][0]] = j\n",
    "\n",
    "corr_inv = {}\n",
    "for j in range(1, 1001):\n",
    "    corr_inv[corr[j]] = j\n",
    "\n",
    "def id_to_words(id_):\n",
    "    return synsets[corr_inv[id_] - 1][2][0]\n",
    "\n",
    "def pprint_output(out, n_max_synsets=10):\n",
    "    wids = []\n",
    "    best_ids = out.argsort()[::-1][:10]\n",
    "    for u in best_ids:\n",
    "        wids.append(str(synsets[corr_inv[u] - 1][1][0]))\n",
    "    #print('%.2f' % round(100 * out[u], 2) + ' : ' + id_to_words(u)+' '+ str(synsets[corr_inv[u] - 1][1][0]))\n",
    "    return wids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code snippet to load the ground truth labels to measure the performance{\n",
    "truth = {}\n",
    "with open('../../data/ILSVRC2014_clsloc_validation_ground_truth.txt') as f:\n",
    "    line_num = 1\n",
    "    for line in f.readlines():\n",
    "        ind_ = int(line)\n",
    "        temp  = None\n",
    "        for i in synsets_imagenet_sorted:\n",
    "            if i[0] == ind_:\n",
    "                temp = i\n",
    "        #print ind_,temp\n",
    "        if temp != None:\n",
    "            truth[line_num] = temp\n",
    "        else:\n",
    "            print('##########', ind_)\n",
    "            pass\n",
    "        line_num += 1\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to predict the top 5 accuracy\n",
    "def top5accuracy(true, predicted):\n",
    "    assert len(true) == len(predicted)\n",
    "    result = []\n",
    "    flag  = 0\n",
    "    for i in range(len(true)):\n",
    "        flag  = 0\n",
    "        temp = true[i]\n",
    "        for j in predicted[i][0:5]:\n",
    "            if j == temp:\n",
    "                flag = 1\n",
    "                break\n",
    "        if flag == 1:\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(0)\n",
    "    counter = 0.\n",
    "    for i in result:\n",
    "        if i == 1:\n",
    "            counter += 1.\n",
    "    error = 1.0 - counter/float(len(result))\n",
    "    #print len(np.where(np.asarray(result) == 1)[0])\n",
    "    return len(np.where(np.asarray(result) == 1)[0]), error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23\n",
      "set([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22])\n",
      "('Cluster: ', 23, 'Label: ', 0)\n",
      "th\n",
      "animate 0 39 1.0 0.0\n",
      "inanimate 18 39 0.538461538462 0.461538461538\n",
      "('Cluster: ', 23, 'Label: ', 1)\n",
      "th\n",
      "animate 30 39 0.230769230769 0.769230769231\n",
      "inanimate 28 39 0.282051282051 0.717948717949\n",
      "('Cluster: ', 23, 'Label: ', 2)\n",
      "th\n",
      "animate 31 39 0.205128205128 0.794871794872\n",
      "inanimate 28 39 0.282051282051 0.717948717949\n",
      "('Cluster: ', 23, 'Label: ', 3)\n",
      "th\n",
      "animate 33 39 0.153846153846 0.846153846154\n",
      "inanimate 27 39 0.307692307692 0.692307692308\n",
      "('Cluster: ', 23, 'Label: ', 4)\n",
      "th\n",
      "animate 31 39 0.205128205128 0.794871794872\n",
      "inanimate 27 39 0.307692307692 0.692307692308\n",
      "('Cluster: ', 23, 'Label: ', 5)\n",
      "th\n",
      "animate 33 39 0.153846153846 0.846153846154\n",
      "inanimate 27 39 0.307692307692 0.692307692308\n",
      "('Cluster: ', 23, 'Label: ', 6)\n",
      "th\n",
      "animate 32 39 0.179487179487 0.820512820513\n",
      "inanimate 26 39 0.333333333333 0.666666666667\n",
      "('Cluster: ', 23, 'Label: ', 7)\n",
      "th\n",
      "animate 30 39 0.230769230769 0.769230769231\n",
      "inanimate 29 39 0.25641025641 0.74358974359\n",
      "('Cluster: ', 23, 'Label: ', 8)\n",
      "th\n",
      "animate 22 39 0.435897435897 0.564102564103\n",
      "inanimate 1 39 0.974358974359 0.025641025641\n",
      "('Cluster: ', 23, 'Label: ', 9)\n",
      "th\n",
      "animate 5 39 0.871794871795 0.128205128205\n",
      "inanimate 21 39 0.461538461538 0.538461538462\n",
      "('Cluster: ', 23, 'Label: ', 10)\n",
      "th\n",
      "animate 26 39 0.333333333333 0.666666666667\n",
      "inanimate 9 39 0.769230769231 0.230769230769\n",
      "('Cluster: ', 23, 'Label: ', 11)\n",
      "th\n",
      "animate 31 39 0.205128205128 0.794871794872\n",
      "inanimate 27 39 0.307692307692 0.692307692308\n",
      "('Cluster: ', 23, 'Label: ', 12)\n",
      "th\n",
      "animate 32 39 0.179487179487 0.820512820513\n",
      "inanimate 28 39 0.282051282051 0.717948717949\n",
      "('Cluster: ', 23, 'Label: ', 13)\n",
      "th\n",
      "animate 30 39 0.230769230769 0.769230769231\n",
      "inanimate 27 39 0.307692307692 0.692307692308\n",
      "('Cluster: ', 23, 'Label: ', 14)\n",
      "th\n",
      "animate 33 39 0.153846153846 0.846153846154\n",
      "inanimate 27 39 0.307692307692 0.692307692308\n",
      "('Cluster: ', 23, 'Label: ', 15)\n",
      "th\n",
      "animate 31 39 0.205128205128 0.794871794872\n",
      "inanimate 27 39 0.307692307692 0.692307692308\n",
      "('Cluster: ', 23, 'Label: ', 16)\n",
      "th\n",
      "animate 32 39 0.179487179487 0.820512820513\n",
      "inanimate 27 39 0.307692307692 0.692307692308\n",
      "('Cluster: ', 23, 'Label: ', 17)\n",
      "th\n",
      "animate 31 39 0.205128205128 0.794871794872\n",
      "inanimate 27 39 0.307692307692 0.692307692308\n",
      "('Cluster: ', 23, 'Label: ', 18)\n",
      "th\n",
      "animate 33 39 0.153846153846 0.846153846154\n",
      "inanimate 26 39 0.333333333333 0.666666666667\n",
      "('Cluster: ', 23, 'Label: ', 19)\n",
      "th\n",
      "animate 32 39 0.179487179487 0.820512820513\n",
      "inanimate 27 39 0.307692307692 0.692307692308\n",
      "('Cluster: ', 23, 'Label: ', 20)\n",
      "th\n",
      "animate 30 39 0.230769230769 0.769230769231\n",
      "inanimate 26 39 0.333333333333 0.666666666667\n",
      "('Cluster: ', 23, 'Label: ', 21)\n",
      "th\n",
      "animate 0 39 1.0 0.0\n",
      "inanimate 0 39 1.0 0.0\n",
      "('Cluster: ', 23, 'Label: ', 22)\n",
      "th\n",
      "animate 33 39 0.153846153846 0.846153846154\n",
      "inanimate 28 39 0.282051282051 0.717948717949\n"
     ]
    }
   ],
   "source": [
    "#Testing on test data{\n",
    "data_path = '../../data/pkl/'\n",
    "classes = ['animate','inanimate']\n",
    "\n",
    "result = {}\n",
    "\n",
    "with open(data_path+classes[0]+'_test.pkl','rb') as f:\n",
    "    X_fold = pickle.load(f)\n",
    "with open(data_path+classes[1]+'_test.pkl','rb') as f:\n",
    "    y_fold = pickle.load(f)\n",
    "\n",
    "X = np.column_stack((X_fold,y_fold))  \n",
    "if os.path.exists('../../data/pkl/kmeans_first_test.pickle'):\n",
    "    with open('../../data/pkl/kmeans_first_test.pickle',\"rb\") as f:\n",
    "        X_new,pred_kmeans,kmeans = pickle.load(f)\n",
    "else:   \n",
    "   \n",
    "    kmeans = MiniBatchKMeans(n_clusters=65827,\n",
    "                             random_state=0,\n",
    "                             batch_size=6,\n",
    "                             max_iter=10).fit(X)\n",
    "    #print kmeans.cluster_centers_\n",
    "    pred_kmeans = kmeans.predict(X)\n",
    "    X_new = kmeans.cluster_centers_\n",
    "\n",
    "\n",
    "#DO CLUSTERING AND GET CLUSTERS\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import Birch\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "#import genieclust\n",
    "#import hdbscan\n",
    "#import smm\n",
    "\n",
    "j = 23 #Set this value from scree plot!\n",
    "method = 'GMM'\n",
    "print(j)\n",
    "#clf = hdbscan.HDBSCAN(min_cluster_size=j, gen_min_span_tree=True)\n",
    "#clf = DBSCAN(eps=5.443)\n",
    "#clf = KMeans(n_clusters=j,random_state=143)\n",
    "#clf= SpectralClustering(n_clusters=j,random_state=143)\n",
    "#clf =  AgglomerativeClustering(n_clusters=j, linkage='ward')\n",
    "#clf = Birch(branching_factor=50, n_clusters=j, threshold=0.5,compute_labels=True)\n",
    "clf = GaussianMixture(n_components=j, covariance_type='full',max_iter=1000, random_state=42)\n",
    "#clf= genieclust.genie.Genie(n_clusters=j)\n",
    "#clf= smm.SMM(n_components=j, covariance_type='full', random_state=143, tol=1e-12,min_covar=1e-6, n_iter=1000, n_init=1, params='wmcd', init_params='wmcd')\n",
    "temp = clf.fit(X_new)\n",
    "y_pred = clf.predict(X_new)\n",
    "#y_pred = clf.fit_predict(X_new)\n",
    "print(set(y_pred))\n",
    "#Z = clf.predict(X)\n",
    "\n",
    "for label in set(y_pred):\n",
    "    print('Cluster: ',j,'Label: ', label)\n",
    "\n",
    "    #Lesioning and measuring performance\n",
    "    #pred = clf.fit_predict(X_new)\n",
    "    temp = clf.fit(X_new)\n",
    "    pred = clf.predict(X_new)\n",
    "    loc = np.where(pred==label)\n",
    "    loc_temp = kmeans.predict(X_new[loc[0]])\n",
    "    loc_new =[]\n",
    "    for entry in set(loc_temp):\n",
    "        temp = np.where(pred_kmeans==entry)[0]\n",
    "        loc_new.extend(temp)\n",
    "\n",
    "    lambda_mask = np.ones(shape=((658272,)))\n",
    "    lambda_mask[loc_new] = 0.\n",
    "\n",
    "    #plt.scatter(X[:,0],X[:,1], c=y_pred) \n",
    "\n",
    "    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model = AlexNet(weights_path=\"../../data/weights/alexnet_weights.h5\",lambda_mask=lambda_mask)\n",
    "    model.compile(optimizer=sgd, loss='mse')\n",
    "\n",
    "    flag = 0\n",
    "    dprime = 0.\n",
    "    for p in classes:\n",
    "        im_valid_test = []\n",
    "        image_list_valid = '../../data/pkl/'+p+'_image_list_test.txt'\n",
    "        with open(image_list_valid,'rb') as f:\n",
    "            for line in f.readlines():\n",
    "                im_valid_test.append(line.strip('\\n'))\n",
    "        im_temp = preprocess_image(im_valid_test,227,227, color_mode=\"bgr\")\n",
    "        out = model.predict(im_temp,batch_size=64)\n",
    "        \n",
    "        true_valid_wids = []\n",
    "        for i in im_valid_test:\n",
    "                temp1 = i.split('/')[4]\n",
    "                temp = temp1.split('.')[0].split('_')[2]\n",
    "                true_valid_wids.append(truth[int(temp)][1])\n",
    "\n",
    "        predicted_valid_wids = []\n",
    "        for i in range(len(im_valid_test)):\n",
    "            #print im_list[i], pprint_output(out[i]), true_wids[i]\n",
    "            predicted_valid_wids.append(pprint_output(out[i]))\n",
    "\n",
    "        count, error  = top5accuracy(true_valid_wids, predicted_valid_wids)\n",
    "\n",
    "        print(str(p)+' '+str(count)+' '+str(len(im_valid_test))+' '+str(error)+' '+str(1-error))\n",
    "\n",
    "        if flag == 0:\n",
    "            dprime = error\n",
    "            flag = 1\n",
    "        else:\n",
    "            dprime -= error\n",
    "\n",
    "    result[label] = dprime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    }
   ],
   "source": [
    "print(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.46153846153846156,\n",
       "  -0.05128205128205132,\n",
       "  -0.07692307692307687,\n",
       "  -0.15384615384615385,\n",
       "  -0.10256410256410253,\n",
       "  -0.15384615384615385,\n",
       "  -0.15384615384615385,\n",
       "  -0.02564102564102566,\n",
       "  -0.5384615384615384,\n",
       "  0.41025641025641024,\n",
       "  -0.4358974358974358,\n",
       "  -0.10256410256410253,\n",
       "  -0.10256410256410253,\n",
       "  -0.07692307692307698,\n",
       "  -0.15384615384615385,\n",
       "  -0.10256410256410253,\n",
       "  -0.1282051282051282,\n",
       "  -0.10256410256410253,\n",
       "  -0.17948717948717952,\n",
       "  -0.1282051282051282,\n",
       "  -0.10256410256410264,\n",
       "  0.0,\n",
       "  -0.1282051282051282],\n",
       " (658272, 2))"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.values(),X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = result.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65827, 65827)\n"
     ]
    }
   ],
   "source": [
    "z_temp = []\n",
    "for item in y_pred:\n",
    "    z_temp.append(result[item])\n",
    "print(len(z_temp),len(X_new))\n",
    "loc_z = kmeans.predict(X_new)\n",
    "z = np.ones(shape=((658272,)))\n",
    "for i in range(len(loc_z)):\n",
    "    temp = np.where(pred_kmeans==loc_z[i])[0]\n",
    "    z[temp] = z_temp[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((658272, 2), (658272,))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, z.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X[:,0]\n",
    "y = X[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8\n",
      "0.461538461538 0.538461538462\n"
     ]
    }
   ],
   "source": [
    "print result.values().index(max(result.values())), result.values().index(min(result.values()))\n",
    "ana = int(result.values().index(max(result.values())))\n",
    "ina = int(result.values().index(min(result.values())))\n",
    "print result[ana], -1*(result[ina])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "spax = []\n",
    "spay = []\n",
    "spix = []\n",
    "spiy = []\n",
    "for i in range(0,len(z)):\n",
    "    if z[i] == result[ana]:\n",
    "        spax.append(x[i])\n",
    "        spay.append(y[i])\n",
    "    elif z[i] == result[ina]:\n",
    "        spix.append(x[i])\n",
    "        spiy.append(y[i])\n",
    "spax = np.asarray(spax)\n",
    "spay = np.asarray(spay)\n",
    "spix = np.asarray(spix)\n",
    "spiy = np.asarray(spiy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th\n"
     ]
    }
   ],
   "source": [
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model = AlexNet(weights_path=\"../../data/weights/alexnet_weights.h5\",lambda_mask=lambda_mask)\n",
    "model.compile(optimizer=sgd, loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 39 39\n",
      "33 0.153846153846\n",
      "conv_1 2 1 (39, 96, 55, 55) (96, 55, 55) (39, 290400)\n",
      "conv_2_1 2 1 (39, 128, 27, 27) (128, 27, 27) (39, 93312)\n",
      "conv_2_2 2 1 (39, 128, 27, 27) (128, 27, 27) (39, 93312)\n",
      "conv_3 2 1 (39, 384, 13, 13) (384, 13, 13) (39, 64896)\n",
      "conv_4_1 2 1 (39, 192, 13, 13) (192, 13, 13) (39, 32448)\n",
      "conv_4_2 2 1 (39, 192, 13, 13) (192, 13, 13) (39, 32448)\n",
      "conv_5_1 2 1 (39, 128, 13, 13) (128, 13, 13) (39, 21632)\n",
      "conv_5_2 2 1 (39, 128, 13, 13) (128, 13, 13) (39, 21632)\n",
      "dense_1 2 1 (39, 4096) (4096,) (39, 4096)\n",
      "dense_2 2 1 (39, 4096) (4096,) (39, 4096)\n"
     ]
    }
   ],
   "source": [
    "#Testing data pkl - animate\n",
    "im_test = []\n",
    "image_list_test = '../../data/pkl/animate_image_list_test.txt'\n",
    "with open(image_list_test,'rb') as f:\n",
    "    for line in f.readlines():\n",
    "        im_test.append(line.strip('\\n'))\n",
    "\n",
    "im_temp = preprocess_image(im_test,227,227, color_mode=\"bgr\")\n",
    "out = model.predict(im_temp,batch_size=64)\n",
    "\n",
    "true_valid_wids = []\n",
    "for i in im_test:\n",
    "        temp1 = i.split('/')[4]\n",
    "        temp = temp1.split('.')[0].split('_')[2]\n",
    "        true_valid_wids.append(truth[int(temp)][1])\n",
    "\n",
    "predicted_valid_wids = []\n",
    "for i in range(len(im_test)):\n",
    "    #print im_list[i], pprint_output(out[i]), true_wids[i]\n",
    "    predicted_valid_wids.append(pprint_output(out[i]))\n",
    "\n",
    "count, error  = top5accuracy(true_valid_wids, predicted_valid_wids)\n",
    "\n",
    "\n",
    "\n",
    "print len(true_valid_wids), len(predicted_valid_wids), len(im_test)\n",
    "print count, error\n",
    "\n",
    "\n",
    "#}\n",
    "# Code snippet to get the activation values and saving information{\n",
    "data = np.array([])\n",
    "\n",
    "i = 0\n",
    "result ={}\n",
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    if len(weights) > 0:\n",
    "        activations = get_activations(model,i,im_temp)\n",
    "        if result.get(layer.name, None) is None:\n",
    "            result[layer.name] = activations[0]\n",
    "            if len(activations[0].shape) == 4:\n",
    "                temp = activations[0].reshape(activations[0].shape[0], activations[0].shape[1]*activations[0].shape[2]*activations[0].shape[2])\n",
    "            else:\n",
    "                temp = activations[0].reshape(activations[0].shape[0], activations[0].shape[1])\n",
    "            if layer.name != 'dense_3':\n",
    "                print layer.name,len(weights),len(activations), activations[0].shape, np.mean(activations[0], axis=0).shape, temp.shape\n",
    "                if len(data) == 0:\n",
    "                    data = temp\n",
    "                else:\n",
    "                    shape = data.shape\n",
    "                    data = np.append(data, temp)\n",
    "                    data = data.reshape(shape[0], shape[1] + temp.shape[1])\n",
    "                #print(data.shape)\n",
    "    i += 1\n",
    "    \n",
    "data_animate_activations = data.copy()\n",
    "correlation_mat= 1 - np.corrcoef(data)\n",
    "data_shape = correlation_mat.shape\n",
    "arr_sorted =  sorted(correlation_mat.ravel())\n",
    "s = pd.Series(correlation_mat.ravel())\n",
    "percentiles = np.asarray(s.apply(lambda x: percentileofscore(arr_sorted, x)))\n",
    "data = np.reshape(percentiles, data_shape)\n",
    "data_full_animate = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 39 39\n",
      "28 0.282051282051\n",
      "conv_1 2 1 (39, 96, 55, 55) (96, 55, 55) (39, 290400)\n",
      "conv_2_1 2 1 (39, 128, 27, 27) (128, 27, 27) (39, 93312)\n",
      "conv_2_2 2 1 (39, 128, 27, 27) (128, 27, 27) (39, 93312)\n",
      "conv_3 2 1 (39, 384, 13, 13) (384, 13, 13) (39, 64896)\n",
      "conv_4_1 2 1 (39, 192, 13, 13) (192, 13, 13) (39, 32448)\n",
      "conv_4_2 2 1 (39, 192, 13, 13) (192, 13, 13) (39, 32448)\n",
      "conv_5_1 2 1 (39, 128, 13, 13) (128, 13, 13) (39, 21632)\n",
      "conv_5_2 2 1 (39, 128, 13, 13) (128, 13, 13) (39, 21632)\n",
      "dense_1 2 1 (39, 4096) (4096,) (39, 4096)\n",
      "dense_2 2 1 (39, 4096) (4096,) (39, 4096)\n"
     ]
    }
   ],
   "source": [
    "#Testing data pkl - Inanimate\n",
    "im_test = []\n",
    "image_list_test = '../../data/pkl/inanimate_image_list_test.txt'\n",
    "with open(image_list_test,'rb') as f:\n",
    "    for line in f.readlines():\n",
    "        im_test.append(line.strip('\\n'))\n",
    "\n",
    "im_temp = preprocess_image(im_test,227,227, color_mode=\"bgr\")\n",
    "out = model.predict(im_temp,batch_size=64)\n",
    "\n",
    "true_valid_wids = []\n",
    "for i in im_test:\n",
    "        temp1 = i.split('/')[4]\n",
    "        temp = temp1.split('.')[0].split('_')[2]\n",
    "        true_valid_wids.append(truth[int(temp)][1])\n",
    "\n",
    "predicted_valid_wids = []\n",
    "for i in range(len(im_test)):\n",
    "    #print im_list[i], pprint_output(out[i]), true_wids[i]\n",
    "    predicted_valid_wids.append(pprint_output(out[i]))\n",
    "\n",
    "count, error  = top5accuracy(true_valid_wids, predicted_valid_wids)\n",
    "\n",
    "\n",
    "\n",
    "print len(true_valid_wids), len(predicted_valid_wids), len(im_test)\n",
    "print count, error\n",
    "\n",
    "\n",
    "#}\n",
    "# Code snippet to get the activation values and saving information{\n",
    "data = np.array([])\n",
    "\n",
    "i = 0\n",
    "result ={}\n",
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    if len(weights) > 0:\n",
    "        activations = get_activations(model,i,im_temp)\n",
    "        if result.get(layer.name, None) is None:\n",
    "            result[layer.name] = activations[0]\n",
    "            if len(activations[0].shape) == 4:\n",
    "                temp = activations[0].reshape(activations[0].shape[0], activations[0].shape[1]*activations[0].shape[2]*activations[0].shape[2])\n",
    "            else:\n",
    "                temp = activations[0].reshape(activations[0].shape[0], activations[0].shape[1])\n",
    "            if layer.name != 'dense_3':\n",
    "                print layer.name,len(weights),len(activations), activations[0].shape, np.mean(activations[0], axis=0).shape, temp.shape\n",
    "                if len(data) == 0:\n",
    "                    data = temp\n",
    "                else:\n",
    "                    shape = data.shape\n",
    "                    data = np.append(data, temp)\n",
    "                    data = data.reshape(shape[0], shape[1] + temp.shape[1])\n",
    "                #print(data.shape)\n",
    "    i += 1\n",
    "\n",
    "data_inanimate_activations = data.copy()\n",
    "correlation_mat= 1 - np.corrcoef(data)\n",
    "data_shape = correlation_mat.shape\n",
    "arr_sorted =  sorted(correlation_mat.ravel())\n",
    "s = pd.Series(correlation_mat.ravel())\n",
    "percentiles = np.asarray(s.apply(lambda x: percentileofscore(arr_sorted, x)))\n",
    "data = np.reshape(percentiles, data_shape)\n",
    "data_full_inanimate = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 39)"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_full_inanimate.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(78, 658272)\n",
      "(78, 78)\n"
     ]
    }
   ],
   "source": [
    "data_total = np.concatenate((data_animate_activations, data_inanimate_activations))\n",
    "print(data_total.shape)\n",
    "correlation_mat= 1 - np.corrcoef(data_total)\n",
    "data_shape = correlation_mat.shape\n",
    "arr_sorted =  sorted(correlation_mat.ravel())\n",
    "s = pd.Series(correlation_mat.ravel())\n",
    "percentiles = np.asarray(s.apply(lambda x: percentileofscore(arr_sorted, x)))\n",
    "data = np.reshape(percentiles, data_shape)\n",
    "data_total_all = data\n",
    "print(data_total_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cluster_animate = {}\n",
    "data_cluster_inanimate = {}\n",
    "data_cluster = {}\n",
    "\n",
    "\n",
    "for label in range(len(labels)):\n",
    "    pred = clf.predict(X_new)\n",
    "    loc = np.where(pred==label)[0]\n",
    "    loc_new =[]\n",
    "    for i in range(len(loc)):\n",
    "        temp = np.where(pred_kmeans==loc[i])[0]\n",
    "        loc_new.extend(temp)\n",
    "\n",
    "    \n",
    "    index_cluster = loc_new\n",
    "    \n",
    "    #Animate\n",
    "    data_temp = data_animate_activations[:,loc_new]\n",
    "    correlation_mat= 1 - np.corrcoef(data_temp)\n",
    "    data_shape = correlation_mat.shape\n",
    "    arr_sorted =  sorted(correlation_mat.ravel())\n",
    "    s = pd.Series(correlation_mat.ravel())\n",
    "    percentiles = np.asarray(s.apply(lambda x: percentileofscore(arr_sorted, x)))\n",
    "    data_temp = np.reshape(percentiles, data_shape)\n",
    "    data_cluster_animate[label] = data_temp\n",
    "    \n",
    "    #InAnimate\n",
    "    data_temp = data_inanimate_activations[:,loc_new]\n",
    "    correlation_mat= 1 - np.corrcoef(data_temp)\n",
    "    data_shape = correlation_mat.shape\n",
    "    arr_sorted =  sorted(correlation_mat.ravel())\n",
    "    s = pd.Series(correlation_mat.ravel())\n",
    "    percentiles = np.asarray(s.apply(lambda x: percentileofscore(arr_sorted, x)))\n",
    "    data_temp = np.reshape(percentiles, data_shape)\n",
    "    data_cluster_inanimate[label] = data_temp\n",
    "    \n",
    "    #Total\n",
    "    data_temp = np.concatenate((data_animate_activations[:,loc_new],data_inanimate_activations[:,loc_new]))\n",
    "    correlation_mat= 1 - np.corrcoef(data_temp)\n",
    "    data_shape = correlation_mat.shape\n",
    "    arr_sorted =  sorted(correlation_mat.ravel())\n",
    "    s = pd.Series(correlation_mat.ravel())\n",
    "    percentiles = np.asarray(s.apply(lambda x: percentileofscore(arr_sorted, x)))\n",
    "    data_temp = np.reshape(percentiles, data_shape)\n",
    "    data_cluster[label] = data_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 0.46153846153846156, 0.5364215136956896, 0.47270211248053845, 0.06371940121515113)\n",
      "(1, -0.05128205128205132, 0.17850434511522223, 0.1796758397915715, -0.0011714946763492773)\n",
      "(2, -0.07692307692307687, 0.3292610273784932, 0.2991349590790416, 0.030126068299451636)\n",
      "(3, -0.15384615384615385, 0.1068375198725745, 0.08324446170815161, 0.023593058164422892)\n",
      "(4, -0.10256410256410253, 0.09953101004966683, 0.06456303031264808, 0.03496797973701875)\n",
      "(5, -0.15384615384615385, 0.22049758832021912, 0.24636980244748038, -0.02587221412726126)\n",
      "(6, -0.15384615384615385, 0.12800633202635398, 0.10660809481505362, 0.021398237211300353)\n",
      "(7, -0.02564102564102566, 0.23153376985190668, 0.2612816195155701, -0.029747849663663423)\n",
      "(8, -0.5384615384615384, 0.5321787252186083, 0.4899768491073624, 0.04220187611124593)\n",
      "(9, 0.41025641025641024, 0.45085476779939154, 0.4665271334989147, -0.015672365699523183)\n",
      "(10, -0.4358974358974358, 0.43983168563768255, 0.44235155603352955, -0.0025198703958470015)\n",
      "(11, -0.10256410256410253, 0.2886628292380682, 0.26685359587280716, 0.021809233365261027)\n",
      "(12, -0.10256410256410253, 0.14420076001925103, 0.1498333001404426, -0.005632540121191576)\n",
      "(13, -0.07692307692307698, 0.20026039789306754, 0.20954216754639413, -0.009281769653326583)\n",
      "(14, -0.15384615384615385, 0.1798939966828662, 0.09461208933207055, 0.08528190735079566)\n",
      "(15, -0.10256410256410253, 0.10483335310713822, 0.07777578606758415, 0.027057567039554073)\n",
      "(16, -0.1282051282051282, 0.10643915679376412, 0.11725935865829755, -0.010820201864533432)\n",
      "(17, -0.10256410256410253, 0.11240693736637765, 0.12436510101140473, -0.011958163645027081)\n",
      "(18, -0.17948717948717952, 0.3474967973197992, 0.2991319441517416, 0.04836485316805761)\n",
      "(19, -0.1282051282051282, 0.17054358927496502, 0.18243907932491815, -0.011895490049953134)\n",
      "(20, -0.10256410256410264, 0.383966115038159, 0.3436708071836951, 0.04029530785446389)\n",
      "(22, -0.1282051282051282, 0.17681871283724673, 0.20342410295312618, -0.02660539011587945)\n"
     ]
    }
   ],
   "source": [
    "rdm_impact ={}\n",
    "\n",
    "for label in range(len(labels)):\n",
    "    if labels[label] != 0.:\n",
    "        t_ana, p_ana = stats.kendalltau(data_full_animate, data_cluster_animate[label])\n",
    "        t_ina, p_ina = stats.kendalltau(data_full_inanimate, data_cluster_inanimate[label])\n",
    "        t, p = stats.kendalltau(data_cluster_animate[label], data_cluster_inanimate[label])\n",
    "        diff = float(t_ana - t_ina)\n",
    "        rdm_impact[label] = p_ina\n",
    "        print(label, labels[label], t_ana, t_ina, diff)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdm_impact.values().index(min(rdm_impact.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 2\n",
      "4.3114011115919363e-05 -2.4585038523670634e-218\n"
     ]
    }
   ],
   "source": [
    "print rdm_impact.values().index(max(rdm_impact.values())), rdm_impact.values().index(min(rdm_impact.values()))\n",
    "rdm_ana = int(rdm_impact.values().index(max(rdm_impact.values())))\n",
    "rdm_ina = int(rdm_impact.values().index(min(rdm_impact.values())))\n",
    "print rdm_impact[rdm_ana], -1*(rdm_impact[rdm_ina])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.kendalltau(data_full_animate, data_full_inanimate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in range(len(labels)):\n",
    "    print(label, stats.kendalltau(data_total_all, data_cluster[label]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot figure of these correlations\n",
    "f, ax = plt.subplots(1,1, figsize=(8, 7))\n",
    "\n",
    "plt.imshow(\n",
    "    data_cluster[8],\n",
    "    origin='lower',\n",
    "    cmap='jet', \n",
    ")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot figure of these correlations\n",
    "f, ax = plt.subplots(1,1, figsize=(8, 7))\n",
    "\n",
    "plt.imshow(\n",
    "    data_total_all,\n",
    "    origin ='lower',\n",
    "    cmap='jet', \n",
    ")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
