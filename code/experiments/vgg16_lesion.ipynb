{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/abhijit/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/abhijit/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/abhijit/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/abhijit/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/abhijit/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/abhijit/anaconda3/envs/py37/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "#To hide warnings export PYTHONWARNINGS=\"ignore\"\n",
    "#Imports{\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "from keras import layers\n",
    "from keras import models\n",
    "import keras.utils as keras_utils\n",
    "from keras.layers import Lambda\n",
    "\n",
    "from  keras.applications import imagenet_utils\n",
    "from  keras.applications.imagenet_utils import decode_predictions\n",
    "from  keras_applications.imagenet_utils import _obtain_input_shape\n",
    "\n",
    "import os\n",
    "from os.path import dirname\n",
    "from os.path import join\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' #Cha\n",
    "\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from imageio import imread\n",
    "from skimage.transform import resize\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "\n",
    "import gc\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import PIL.Image\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm TensorFlow sees the GPU\n",
    "from tensorflow.python.client import device_lib\n",
    "print(str(device_lib.list_local_devices()))\n",
    "assert 'GPU' in str(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'VGG16'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code snippet needed to read activation values from each layer of the pre-trained artificial neural networks\n",
    "def get_activations(model, layer, X_batch):\n",
    "    #keras.backend.function(inputs, outputs, updates=None)\n",
    "    get_activations = keras.backend.function([model.layers[0].input, keras.backend.learning_phase()], [model.layers[layer].output,])\n",
    "    #The learning phase flag is a bool tensor (0 = test, 1 = train)\n",
    "    activations = get_activations([X_batch,0])\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_input = imagenet_utils.preprocess_input\n",
    "\n",
    "WEIGHTS_PATH = ('https://github.com/fchollet/deep-learning-models/'\n",
    "                'releases/download/v0.1/'\n",
    "                'vgg16_weights_tf_dim_ordering_tf_kernels.h5')\n",
    "WEIGHTS_PATH_NO_TOP = ('https://github.com/fchollet/deep-learning-models/'\n",
    "                       'releases/download/v0.1/'\n",
    "                       'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5')\n",
    "\n",
    "\n",
    "def VGG16(include_top=True,\n",
    "          weights='imagenet',\n",
    "          input_tensor=None,\n",
    "          input_shape=None,\n",
    "          pooling=None,\n",
    "          classes=1000,\n",
    "          lambda_mask=None,\n",
    "          **kwargs):\n",
    "    \n",
    "    backend= keras.backend\n",
    "    layers = keras.layers\n",
    "    models = keras.models\n",
    "    keras_utils = tf.keras.utils\n",
    "    \n",
    "    if not (weights in {'imagenet', None} or os.path.exists(weights)):\n",
    "        raise ValueError('The `weights` argument should be either '\n",
    "                         '`None` (random initialization), `imagenet` '\n",
    "                         '(pre-training on ImageNet), '\n",
    "                         'or the path to the weights file to be loaded.')\n",
    "\n",
    "    if weights == 'imagenet' and include_top and classes != 1000:\n",
    "        raise ValueError('If using `weights` as `\"imagenet\"` with `include_top`'\n",
    "                         ' as true, `classes` should be 1000')\n",
    "    # Determine proper input shape\n",
    "    input_shape = _obtain_input_shape(input_shape,\n",
    "                                      default_size=224,\n",
    "                                      min_size=32,\n",
    "                                      data_format=backend.image_data_format(),\n",
    "                                      require_flatten=include_top,\n",
    "                                      weights=weights)\n",
    "\n",
    "    if input_tensor is None:\n",
    "        img_input = layers.Input(shape=input_shape)\n",
    "    else:\n",
    "        if not backend.is_keras_tensor(input_tensor):\n",
    "            img_input = layers.Input(tensor=input_tensor, shape=input_shape)\n",
    "        else:\n",
    "            img_input = input_tensor\n",
    "    # Block 1\n",
    "    x = layers.Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block1_conv1')(img_input)\n",
    "    ####################\n",
    "    if lambda_mask is not None:\n",
    "        block_1_conv_1_mask  = np.reshape(lambda_mask[0:3211264], (224, 224,64))\n",
    "    else:\n",
    "        block_1_conv_1_mask = np.ones(shape=((224, 224, 64)))\n",
    "    \n",
    "    block_1_conv_1_mask  = backend.variable(block_1_conv_1_mask)\n",
    "    block_1_conv_1_lambda = Lambda(lambda x: x * block_1_conv_1_mask)(x)\n",
    "    ####################\n",
    "    x = layers.Conv2D(64, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block1_conv2')(block_1_conv_1_lambda)\n",
    "    ####################\n",
    "    if lambda_mask is not None:\n",
    "        block_1_conv_2_mask  = np.reshape(lambda_mask[3211264:6422528], (224, 224, 64))\n",
    "    else:\n",
    "        block_1_conv_2_mask = np.ones(shape=((224, 224, 64)))\n",
    "    \n",
    "    block_1_conv_2_mask  = backend.variable(block_1_conv_2_mask)\n",
    "    block_1_conv_2_lambda = Lambda(lambda x: x * block_1_conv_2_mask)(x)\n",
    "    ####################\n",
    "    \n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(block_1_conv_2_lambda)\n",
    "\n",
    "    # Block 2\n",
    "    x = layers.Conv2D(128, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv1')(x)\n",
    "    ####################\n",
    "    if lambda_mask is not None:\n",
    "        block_2_conv_1_mask  = np.reshape(lambda_mask[6422528:8028160], (112, 112, 128))\n",
    "    else:\n",
    "        block_2_conv_1_mask = np.ones(shape=((112, 112, 128)))\n",
    "    \n",
    "    block_2_conv_1_mask  = backend.variable(block_2_conv_1_mask)\n",
    "    block_2_conv_1_lambda = Lambda(lambda x: x * block_2_conv_1_mask)(x)\n",
    "    ####################\n",
    "    x = layers.Conv2D(128, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block2_conv2')(block_2_conv_1_lambda)\n",
    "    \n",
    "    ####################\n",
    "    if lambda_mask is not None:\n",
    "        block_2_conv_2_mask  = np.reshape(lambda_mask[8028160:9633792], (112, 112, 128))\n",
    "    else:\n",
    "        block_2_conv_2_mask = np.ones(shape=((112, 112, 128)))\n",
    "    \n",
    "    block_2_conv_2_mask  = backend.variable(block_2_conv_2_mask)\n",
    "    block_2_conv_2_lambda = Lambda(lambda x: x * block_2_conv_2_mask)(x)\n",
    "    ####################\n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(block_2_conv_2_lambda)\n",
    "\n",
    "    # Block 3\n",
    "    x = layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv1')(x)\n",
    "    ####################\n",
    "    if lambda_mask is not None:\n",
    "        block_3_conv_1_mask  = np.reshape(lambda_mask[9633792:10436608], (56, 56, 256))\n",
    "    else:\n",
    "        block_3_conv_1_mask = np.ones(shape=((56, 56, 256)))\n",
    "    \n",
    "    block_3_conv_1_mask  = backend.variable(block_3_conv_1_mask)\n",
    "    block_3_conv_1_lambda = Lambda(lambda x: x * block_3_conv_1_mask)(x)\n",
    "    ####################\n",
    "    \n",
    "    x = layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv2')(block_3_conv_1_lambda)\n",
    "    ####################\n",
    "    if lambda_mask is not None:\n",
    "        block_3_conv_2_mask  = np.reshape(lambda_mask[10436608:11239424], (56, 56, 256))\n",
    "    else:\n",
    "        block_3_conv_2_mask = np.ones(shape=((56, 56, 256)))\n",
    "    ####################\n",
    "    block_3_conv_2_mask  = backend.variable(block_3_conv_2_mask)\n",
    "    block_3_conv_2_lambda = Lambda(lambda x: x * block_3_conv_2_mask)(x)\n",
    "    \n",
    "    x = layers.Conv2D(256, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block3_conv3')( block_3_conv_2_lambda)\n",
    "    ####################\n",
    "    if lambda_mask is not None:\n",
    "        block_3_conv_3_mask  = np.reshape(lambda_mask[11239424:12042240], (56, 56, 256))\n",
    "    else:\n",
    "        block_3_conv_3_mask = np.ones(shape=((56, 56, 256)))\n",
    "    ####################\n",
    "    block_3_conv_3_mask  = backend.variable(block_3_conv_3_mask)\n",
    "    block_3_conv_3_lambda = Lambda(lambda x: x * block_3_conv_3_mask)(x)\n",
    "    \n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(block_3_conv_3_lambda)\n",
    "\n",
    "    # Block 4\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv1')(x)\n",
    "    ####################\n",
    "    if lambda_mask is not None:\n",
    "        block_4_conv_1_mask  = np.reshape(lambda_mask[12042240:12443648], (28, 28, 512))\n",
    "    else:\n",
    "        block_4_conv_1_mask = np.ones(shape=((28, 28, 512)))\n",
    "    \n",
    "    block_4_conv_1_mask  = backend.variable(block_4_conv_1_mask)\n",
    "    block_4_conv_1_lambda = Lambda(lambda x: x * block_4_conv_1_mask)(x)\n",
    "    ####################\n",
    "    \n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv2')(block_4_conv_1_lambda)\n",
    "    ####################\n",
    "    if lambda_mask is not None:\n",
    "        block_4_conv_2_mask  = np.reshape(lambda_mask[12443648:12845056], (28, 28, 512))\n",
    "    else:\n",
    "        block_4_conv_2_mask = np.ones(shape=((28, 28, 512)))\n",
    "    \n",
    "    block_4_conv_2_mask  = backend.variable(block_4_conv_2_mask)\n",
    "    block_4_conv_2_lambda = Lambda(lambda x: x * block_4_conv_2_mask)(x)\n",
    "    ####################\n",
    "    \n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block4_conv3')(block_4_conv_2_lambda)\n",
    "    \n",
    "    ####################\n",
    "    if lambda_mask is not None:\n",
    "        block_4_conv_3_mask  = np.reshape(lambda_mask[12845056:13246464], (28, 28, 512))\n",
    "    else:\n",
    "        block_4_conv_3_mask = np.ones(shape=((28, 28, 512)))\n",
    "    \n",
    "    block_4_conv_3_mask  = backend.variable(block_4_conv_3_mask)\n",
    "    block_4_conv_3_lambda = Lambda(lambda x: x * block_4_conv_3_mask)(x)\n",
    "    ####################\n",
    "    \n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')( block_4_conv_3_lambda)\n",
    "\n",
    "    # Block 5\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv1')(x)\n",
    "    ####################\n",
    "    if lambda_mask is not None:\n",
    "        block_5_conv_1_mask  = np.reshape(lambda_mask[13246464:13346816], (14, 14, 512))\n",
    "    else:\n",
    "        block_5_conv_1_mask = np.ones(shape=((14, 14, 512)))\n",
    "    \n",
    "    block_5_conv_1_mask  = backend.variable(block_5_conv_1_mask)\n",
    "    block_5_conv_1_lambda = Lambda(lambda x: x * block_5_conv_1_mask)(x)\n",
    "    ####################\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv2')(block_5_conv_1_lambda)\n",
    "    ####################\n",
    "    if lambda_mask is not None:\n",
    "        block_5_conv_2_mask  = np.reshape(lambda_mask[13346816:13447168], (14, 14, 512))\n",
    "    else:\n",
    "        block_5_conv_2_mask = np.ones(shape=((14, 14, 512)))\n",
    "    \n",
    "    block_5_conv_2_mask  = backend.variable(block_5_conv_2_mask)\n",
    "    block_5_conv_2_lambda = Lambda(lambda x: x * block_5_conv_2_mask)(x)\n",
    "    ####################\n",
    "    x = layers.Conv2D(512, (3, 3),\n",
    "                      activation='relu',\n",
    "                      padding='same',\n",
    "                      name='block5_conv3')(block_5_conv_2_lambda)\n",
    "    ####################\n",
    "    if lambda_mask is not None:\n",
    "        block_5_conv_3_mask  = np.reshape(lambda_mask[13447168:13547520], (14, 14, 512))\n",
    "    else:\n",
    "        block_5_conv_3_mask = np.ones(shape=((14, 14, 512)))\n",
    "\n",
    "    block_5_conv_3_mask  = backend.variable(block_5_conv_3_mask)\n",
    "    block_5_conv_3_lambda = Lambda(lambda x: x * block_5_conv_3_mask)(x)\n",
    "    ####################\n",
    "    \n",
    "    x = layers.MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')( block_5_conv_3_lambda)\n",
    "\n",
    "    if include_top:\n",
    "        # Classification block\n",
    "        x = layers.Flatten(name='flatten')(x)\n",
    "        x = layers.Dense(4096, activation='relu', name='fc1')(x)\n",
    "        ####################\n",
    "        if lambda_mask is not None:\n",
    "            block_fc1_mask  = np.reshape(lambda_mask[13547520:13551616], (4096,))\n",
    "        else:\n",
    "            block_fc1_mask = np.ones(shape=((4096,)))\n",
    "        block_fc1_mask  = backend.variable(block_fc1_mask)\n",
    "        block_fc1_lambda = Lambda(lambda x: x * block_fc1_mask)(x)\n",
    "        ####################\n",
    "        x = layers.Dense(4096, activation='relu', name='fc2')(block_fc1_lambda)\n",
    "        ####################\n",
    "        if lambda_mask is not None:\n",
    "            block_fc2_mask  = np.reshape(lambda_mask[13551616:13555712], (4096,))\n",
    "        else:\n",
    "            block_fc2_mask = np.ones(shape=((4096,)))\n",
    "        block_fc2_mask  = backend.variable(block_fc2_mask)\n",
    "        block_fc2_lambda = Lambda(lambda x: x * block_fc2_mask)(x)\n",
    "        ####################\n",
    "        x = layers.Dense(classes, activation='softmax', name='predictions')(block_fc2_lambda)\n",
    "    else:\n",
    "        if pooling == 'avg':\n",
    "            x = layers.GlobalAveragePooling2D()(x)\n",
    "        elif pooling == 'max':\n",
    "            x = layers.GlobalMaxPooling2D()(x)\n",
    "\n",
    "    # Ensure that the model takes into account\n",
    "    # any potential predecessors of `input_tensor`.\n",
    "    if input_tensor is not None:\n",
    "        inputs = keras_utils.get_source_inputs(input_tensor)\n",
    "    else:\n",
    "        inputs = img_input\n",
    "    # Create model.\n",
    "    model = models.Model(inputs, x, name='vgg16')\n",
    "\n",
    "    # Load weights.\n",
    "    if weights == 'imagenet':\n",
    "        if include_top:\n",
    "            weights_path = keras_utils.get_file(\n",
    "                'vgg16_weights_tf_dim_ordering_tf_kernels.h5',\n",
    "                WEIGHTS_PATH,\n",
    "                cache_subdir='models',\n",
    "                file_hash='64373286793e3c8b2b4e3219cbf3544b')\n",
    "        else:\n",
    "            weights_path = keras_utils.get_file(\n",
    "                'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "                WEIGHTS_PATH_NO_TOP,\n",
    "                cache_subdir='models',\n",
    "                file_hash='6d6bbae143d832006294945121d1f1fc')\n",
    "        model.load_weights(weights_path)\n",
    "        if backend.backend() == 'theano':\n",
    "            keras_utils.convert_all_kernels_in_model(model)\n",
    "    elif weights is not None:\n",
    "        model.load_weights(weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to pre-process the input image to ensure uniform size and color\n",
    "def preprocess_image_batch(image_paths, img_size=None, crop_size=None, color_mode='rgb', out=None):\n",
    "    \"\"\"\n",
    "    Consistent preprocessing of images batches\n",
    "    :param image_paths: iterable: images to process\n",
    "    :param crop_size: tuple: crop images if specified\n",
    "    :param img_size: tuple: resize images if specified\n",
    "    :param color_mode: Use rgb or change to bgr mode based on type of model you want to use\n",
    "    :param out: append output to this iterable if specified\n",
    "    \"\"\"\n",
    "    img_list = []\n",
    "\n",
    "    for im_path in image_paths:\n",
    "        size = 224\n",
    "        ret = PIL.Image.open(im_path)\n",
    "        ret = ret.resize((size, size))\n",
    "        ret = np.asarray(ret, dtype=np.uint8).astype(np.float32)\n",
    "        #ret[:, :, 0] -= 123.68\n",
    "        #ret[:, :, 1] -= 116.779\n",
    "        #ret[:, :, 2] -= 103.939\n",
    "        if ret.ndim == 2:\n",
    "            ret.resize((size, size, 1))\n",
    "            ret = np.repeat(ret, 3, axis=-1)\n",
    "        #ret = ret.transpose((2, 0, 1))\n",
    "        #ret = np.flip(ret,0)\n",
    "        x = preprocess_input(ret)\n",
    "        #print(x.shape)\n",
    "        img_list.append(x)\n",
    "        \n",
    "\n",
    "    try:\n",
    "        img_batch = np.stack(img_list, axis=0)\n",
    "    except:\n",
    "        print(im_path)\n",
    "        raise ValueError('when img_size and crop_size are None, images'\n",
    "                ' in image_paths must have the same shapes.')\n",
    "\n",
    "    if out is not None and hasattr(out, 'append'):\n",
    "        out.append(img_batch)\n",
    "    else:\n",
    "        return img_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to predict the top 5 accuracy\n",
    "def top5accuracy(true, predicted):\n",
    "    assert len(true) == len(predicted)\n",
    "    result = []\n",
    "    flag  = 0\n",
    "    for i in range(len(true)):\n",
    "        flag  = 0\n",
    "        temp = true[i]\n",
    "        for j in predicted[i][0:5]:\n",
    "            if j == temp:\n",
    "                flag = 1\n",
    "                break\n",
    "        if flag == 1:\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(0)\n",
    "    counter = 0.\n",
    "    for i in result:\n",
    "        if i == 1:\n",
    "            counter += 1.\n",
    "    error = 1.0 - counter/float(len(result))\n",
    "    #print len(np.where(np.asarray(result) == 1)[0])\n",
    "    return len(np.where(np.asarray(result) == 1)[0]), error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the details of all the 1000 classes and the function to conver the synset id to words{\n",
    "meta_clsloc_file = '../../data/meta_clsloc.mat'\n",
    "synsets = loadmat(meta_clsloc_file)['synsets'][0]\n",
    "synsets_imagenet_sorted = sorted([(int(s[0]), str(s[1][0])) for s in synsets[:1000]],key=lambda v: v[1])\n",
    "corr = {}\n",
    "for j in range(1000):\n",
    "    corr[synsets_imagenet_sorted[j][0]] = j\n",
    "\n",
    "corr_inv = {}\n",
    "for j in range(1, 1001):\n",
    "    corr_inv[corr[j]] = j\n",
    "\n",
    "def id_to_words(id_):\n",
    "    return synsets[corr_inv[id_] - 1][2][0]\n",
    "\n",
    "def pprint_output(out, n_max_synsets=10):\n",
    "    wids = []\n",
    "    best_ids = out.argsort()[::-1][:10]\n",
    "    for u in best_ids:\n",
    "        wids.append(str(synsets[corr_inv[u] - 1][1][0]))\n",
    "    #print('%.2f' % round(100 * out[u], 2) + ' : ' + id_to_words(u)+' '+ str(synsets[corr_inv[u] - 1][1][0]))\n",
    "    return wids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code snippet to load the ground truth labels to measure the performance{\n",
    "truth = {}\n",
    "with open('../../data/ILSVRC2014_clsloc_validation_ground_truth.txt') as f:\n",
    "    line_num = 1\n",
    "    for line in f.readlines():\n",
    "        ind_ = int(line)\n",
    "        temp  = None\n",
    "        for i in synsets_imagenet_sorted:\n",
    "            if i[0] == ind_:\n",
    "                temp = i\n",
    "        #print ind_,temp\n",
    "        if temp != None:\n",
    "            truth[line_num] = temp\n",
    "        else:\n",
    "            print('##########', ind_)\n",
    "            pass\n",
    "        line_num += 1\n",
    "#}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0 - Getting activations and saving them into pkl files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the folder to be procesed from command line{\n",
    "p = 'animate'\n",
    "tmp = p.replace('/','_')\n",
    "print(tmp)\n",
    "\n",
    "\n",
    "p_num = 1\n",
    "url_path = '../../data/'+p+'/'\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the image list and pre-process them{\n",
    "true_wids = []\n",
    "im_list = []\n",
    "for i in os.listdir(url_path):\n",
    "    if not i.startswith('~') and not i.startswith('.'):\n",
    "        #print i, truth\n",
    "        temp = i.split('.')[0].split('_')[2]\n",
    "        true_wids.append(truth[int(temp)][1])\n",
    "        im_list.append(url_path+i)\n",
    "\n",
    "im = preprocess_image_batch(im_list,img_size=(256,256), crop_size=(224,224), color_mode=\"rgb\")\n",
    "#}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parmeters and running the model from the loaded weights{\n",
    "model_name = 'VGG16'\n",
    "model = VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000)\n",
    "#KFold\n",
    "k = 4\n",
    "\n",
    "im_train, im_test = train_test_split(im_list, test_size=0.2, random_state=42)\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training data pkl\n",
    "fp_name = '../../data/pkl_vgg16/'+str(p)+'_train_no_lesion_performance.txt'\n",
    "fp = open(fp_name,'a+')\n",
    "im_temp = preprocess_image_batch(im_train,img_size=(256,256), crop_size=(224,224), color_mode=\"rgb\")\n",
    "out = model.predict(im_temp)\n",
    "\n",
    "true_valid_wids = []\n",
    "for i in im_train:\n",
    "        temp1 = i.split('/')[4]\n",
    "        temp = temp1.split('.')[0].split('_')[2]\n",
    "        true_valid_wids.append(truth[int(temp)][1])\n",
    "\n",
    "predicted_valid_wids = []\n",
    "for i in range(len(im_train)):\n",
    "    #print(im_list[i], pprint_output(out[i]), true_wids[i])\n",
    "    predicted_valid_wids.append(pprint_output(out[i]))\n",
    "\n",
    "count, error  = top5accuracy(true_valid_wids, predicted_valid_wids)\n",
    "\n",
    "fp.write(str(p)+' '+str(count)+' '+str(len(im_train))+' '+str(error)+'\\n')\n",
    "\n",
    "\n",
    "print(len(true_valid_wids), len(predicted_valid_wids), len(im_train))\n",
    "print(count, error)\n",
    "\n",
    "\n",
    "#}\n",
    "# Code snippet to get the activation values and saving information{\n",
    "data = np.array([])\n",
    "\n",
    "i = 0\n",
    "result ={}\n",
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    if len(weights) > 0:\n",
    "        activations = get_activations(model,i,im_temp)\n",
    "        if result.get(layer.name, None) is None:\n",
    "            result[layer.name] = activations[0]\n",
    "            temp = np.mean(activations[0], axis=0).ravel()\n",
    "            if layer.name != 'predictions':\n",
    "                print(layer.name,len(weights),len(activations), activations[0].shape, np.mean(activations[0], axis=0).shape, temp.shape)\n",
    "                data = np.append(data, temp)\n",
    "    i += 1\n",
    "\n",
    "fp.close()\n",
    "with open('../../data/pkl_vgg16/'+str(p)+'_train_'+model_name+'.pkl', 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing data pkl\n",
    "fp_name = '../../data/pkl_vgg16/'+str(p)+'_test_no_lesion_performance.txt'\n",
    "fp = open(fp_name,'a+')\n",
    "\n",
    "im_temp = preprocess_image_batch(im_test,img_size=(256,256), crop_size=(224,224), color_mode=\"rgb\")\n",
    "out = model.predict(im_temp,batch_size=64)\n",
    "\n",
    "true_valid_wids = []\n",
    "for i in im_test:\n",
    "        temp1 = i.split('/')[4]\n",
    "        temp = temp1.split('.')[0].split('_')[2]\n",
    "        true_valid_wids.append(truth[int(temp)][1])\n",
    "\n",
    "predicted_valid_wids = []\n",
    "for i in range(len(im_test)):\n",
    "    #print im_list[i], pprint_output(out[i]), true_wids[i]\n",
    "    predicted_valid_wids.append(pprint_output(out[i]))\n",
    "\n",
    "count, error  = top5accuracy(true_valid_wids, predicted_valid_wids)\n",
    "\n",
    "fp.write(str(p)+' '+str(count)+' '+str(len(im_test))+' '+str(error)+'\\n')\n",
    "\n",
    "\n",
    "print(len(true_valid_wids), len(predicted_valid_wids), len(im_test))\n",
    "print(count, error)\n",
    "\n",
    "\n",
    "#}\n",
    "# Code snippet to get the activation values and saving information{\n",
    "data = np.array([])\n",
    "\n",
    "i = 0\n",
    "result ={}\n",
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    if len(weights) > 0:\n",
    "        activations = get_activations(model,i,im_temp)\n",
    "        if result.get(layer.name, None) is None:\n",
    "            result[layer.name] = activations[0]\n",
    "            temp = np.mean(activations[0], axis=0).ravel()\n",
    "            if layer.name != 'predictions':\n",
    "                print(layer.name,len(weights),len(activations), activations[0].shape, np.mean(activations[0], axis=0).shape, temp.shape)\n",
    "                data = np.append(data, temp)\n",
    "    i += 1\n",
    "\n",
    "fp.close()\n",
    "with open('../../data/pkl_vgg16/'+str(p)+'_test_'+model_name+'.pkl', 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_r = []\n",
    "\n",
    "image_list_test = '../../data/pkl_vgg16/'+p+'_image_list_test.txt'\n",
    "with open(image_list_test,'w+') as f:\n",
    "    for i in im_test:\n",
    "        f.write(i+'\\n')\n",
    "\n",
    "kf = KFold(n_splits= k)\n",
    "fold = 1\n",
    "fp_name = '../../data/pkl_vgg16/'+str(p)+'_no_lesion_performance.txt'\n",
    "fp = open(fp_name,'a+')\n",
    "for train_index, valid_index in kf.split(im_train):\n",
    "    print(\"Starting Fold: \", fold)\n",
    "    im_valid_train = [im_train[i] for i in train_index] \n",
    "    im_valid_test = [im_train[i] for i in valid_index]\n",
    "    \n",
    "    image_list_train = '../../data/pkl_vgg16/'+p+'_image_list_train_fold_'+str(fold)+'.txt'\n",
    "    with open(image_list_train,'w+') as f:\n",
    "        for i in im_valid_train:\n",
    "            f.write(i+'\\n')\n",
    "    \n",
    "    image_list_valid = '../../data/pkl_vgg16/'+p+'_image_list_valid_fold_'+str(fold)+'.txt'\n",
    "    with open(image_list_valid,'w+') as f:\n",
    "        for i in im_valid_test:\n",
    "            f.write(i+'\\n')\n",
    "    \n",
    "   \n",
    "    im_temp = preprocess_image_batch(im_valid_test,img_size=(256,256), crop_size=(224,224), color_mode=\"rgb\")\n",
    "    out = model.predict(im_temp,batch_size=64)\n",
    "\n",
    "    true_valid_wids = []\n",
    "    for i in im_valid_test:\n",
    "            temp1 = i.split('/')[4]\n",
    "            temp = temp1.split('.')[0].split('_')[2]\n",
    "            true_valid_wids.append(truth[int(temp)][1])\n",
    "    \n",
    "    predicted_valid_wids = []\n",
    "    for i in range(len(im_valid_test)):\n",
    "        #print im_list[i], pprint_output(out[i]), true_wids[i]\n",
    "        predicted_valid_wids.append(pprint_output(out[i]))\n",
    "        \n",
    "    count, error  = top5accuracy(true_valid_wids, predicted_valid_wids)\n",
    "    \n",
    "    fp.write(str(p)+' '+str(fold)+' '+str(count)+' '+str(len(im_valid_test))+' '+str(error)+'\\n')\n",
    "\n",
    "    \n",
    "    print(len(true_valid_wids), len(predicted_valid_wids), len(im_valid_test))\n",
    "    print(count, error)\n",
    "    \n",
    "    \n",
    "    #}\n",
    "    # Code snippet to get the activation values and saving information{\n",
    "    data = np.array([])\n",
    "\n",
    "    i = 0\n",
    "    result ={}\n",
    "    for layer in model.layers:\n",
    "        weights = layer.get_weights()\n",
    "        if len(weights) > 0:\n",
    "            activations = get_activations(model,i,im_temp)\n",
    "            if result.get(layer.name, None) is None:\n",
    "                result[layer.name] = activations[0]\n",
    "                temp = np.mean(activations[0], axis=0).ravel()\n",
    "                if layer.name != 'predictions':\n",
    "                    print(layer.name,len(weights),len(activations), activations[0].shape, np.mean(activations[0], axis=0).shape, temp.shape)\n",
    "                    data = np.append(data, temp)\n",
    "        i += 1\n",
    "    print(data.shape)\n",
    "    out_r.append(data)\n",
    "    fold += 1\n",
    "    \n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving all the data into pkl files\n",
    "for i in range(k):\n",
    "    name = p+'_fold_'+str(i+1)+'_train_'+model_name\n",
    "    out_data = out_r[i]\n",
    "    with open('../../data/pkl_vgg16/'+name+'.pkl', 'wb') as f:\n",
    "        pickle.dump(out_data, f)\n",
    "    print(name, len(out_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from keras import backend as K \n",
    "\n",
    "#del model\n",
    "K.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 - Cross-Validation to find best value of k and corresponding indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#Version 1 - Reading pkl files from step 0 and clustering it{\n",
    "data_path = '../../data/pkl_vgg16/'\n",
    "classes = ['animate','inanimate']\n",
    "\n",
    "from sklearn.cluster import KMeans,MiniBatchKMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "result= {}\n",
    "\n",
    "model_name = 'VGG16'\n",
    "k = 4 #Total Number of folds\n",
    "fold = 1\n",
    "\n",
    "for i in range(k):\n",
    "    \n",
    "    if fold == 1:\n",
    "        fold +=1\n",
    "        continue\n",
    "    print('Perfoming Fold: ', fold)\n",
    "    clf_result = {}\n",
    "    \n",
    "    if os.path.exists('../../data/pkl_vgg16/kmeans_first_'+str(fold)+'_'+model_name+'.pkl'):\n",
    "        with open('../../data/pkl_vgg16/kmeans_first_'+str(fold)+'_'+model_name+'.pkl',\"rb\") as f:\n",
    "            X_new,pred_kmeans,kmeans = pickle.load(f)\n",
    "    else:   \n",
    "        with open(data_path+classes[0]+'_fold_'+str(fold)+'_train_'+model_name+'.pkl','rb') as f:\n",
    "            X_fold = pickle.load(f)\n",
    "        with open(data_path+classes[1]+'_fold_'+str(fold)+'_train_'+model_name+'.pkl','rb') as f:\n",
    "            y_fold = pickle.load(f)\n",
    "\n",
    "        X = np.column_stack((X_fold,y_fold))\n",
    "        kmeans = MiniBatchKMeans(n_clusters=67783, random_state=42).fit(X) #200x Reduction in cluster size\n",
    "        #print kmeans.cluster_centers_\n",
    "        pred_kmeans = kmeans.predict(X)\n",
    "        X_new = kmeans.cluster_centers_\n",
    "\n",
    "        with open('../../data/pkl_vgg16/kmeans_first_'+str(fold)+'_'+model_name+'.pkl', 'wb') as handle:\n",
    "            pickle.dump([X_new,pred_kmeans,kmeans], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    #DO CLUSTERING AND GET CLUSTERS\n",
    "    \n",
    "    \n",
    "    method ='GMM'\n",
    "    print(method)\n",
    "    for j in range(1,14,1):\n",
    " \n",
    "        clf_result[j] = {}\n",
    "        print(j,2**j)\n",
    "        #clf = KMeans(n_clusters=j)    \n",
    "        clf = GaussianMixture(n_components=2**j, covariance_type='full', random_state=42)\n",
    "        y_pred = clf.fit_predict(X_new)\n",
    "        #print clf.cluster_centers_\n",
    "\n",
    "        for label in set(y_pred):\n",
    "            print('Cluster: ',j,'Label: ', label)\n",
    "            \n",
    "            #Lesioning and measuring performance\n",
    "            pred = y_pred.copy()\n",
    "            loc = np.where(pred==label)\n",
    "            loc_temp = kmeans.predict(X_new[loc[0]])\n",
    "            loc_new =[]\n",
    "            for entry in set(loc_temp):\n",
    "                temp = np.where(pred_kmeans==entry)[0]\n",
    "                loc_new.extend(temp)\n",
    "\n",
    "            lambda_mask = np.ones(shape=((13555712,)))\n",
    "            lambda_mask[loc_new] = 0.\n",
    "\n",
    "            #plt.scatter(X[:,0],X[:,1], c=y_pred) \n",
    "            #Change Model\n",
    "            model = VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000,lambda_mask=lambda_mask)\n",
    "\n",
    "            flag = 0\n",
    "            dprime = 0.\n",
    "            for p in classes:\n",
    "                im_valid_test = []\n",
    "                image_list_valid = '../../data/pkl_vgg16/'+p+'_image_list_valid_fold_'+str(fold)+'.txt'\n",
    "                with open(image_list_valid,'r') as f:\n",
    "                    for line in f.readlines():\n",
    "                        im_valid_test.append(line.strip('\\n'))\n",
    "                im_temp = preprocess_image_batch(im_valid_test,img_size=(256,256), crop_size=(224,224), color_mode=\"rgb\")\n",
    "                out = model.predict(im_temp,batch_size=64)\n",
    "\n",
    "                true_valid_wids = []\n",
    "                for i in im_valid_test:\n",
    "                        temp1 = i.split('/')[4]\n",
    "                        temp = temp1.split('.')[0].split('_')[2]\n",
    "                        true_valid_wids.append(truth[int(temp)][1])\n",
    "\n",
    "                predicted_valid_wids = []\n",
    "                for i in range(len(im_valid_test)):\n",
    "                    #print im_list[i], pprint_output(out[i]), true_wids[i]\n",
    "                    predicted_valid_wids.append(pprint_output(out[i]))\n",
    "\n",
    "                count, error  = top5accuracy(true_valid_wids, predicted_valid_wids)\n",
    "\n",
    "                print(str(p)+' '+str(fold)+' '+str(count)+' '+str(len(im_valid_test))+' '+str(error))\n",
    "                \n",
    "                if flag == 0:\n",
    "                    dprime = error\n",
    "                    flag = 1\n",
    "                else:\n",
    "                    dprime -= error\n",
    "                    \n",
    "            keras.backend.clear_session()\n",
    "            gc.collect()\n",
    "            del model\n",
    "            clf_result[j][label] = [dprime,loc_new]\n",
    "    \n",
    "    with open('../../data/pkl_vgg16/'+str(method)+'_multi_scree_fold_'+str(fold)+'_'+model_name+'.pkl', 'wb') as handle:\n",
    "        pickle.dump(clf_result, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    result[fold] = clf_result\n",
    "    fold += 1\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to generate average scree plot\n",
    "model_name = 'VGG16'\n",
    "method = 'GMM'\n",
    "folder_name='pkl_vgg16'\n",
    "number_of_neurons = 13555712\n",
    "k = 4\n",
    "result ={}\n",
    "for i in range(1,k+1,1):\n",
    "    name = '../../data/'+folder_name+'/'+str(method)+'_multi_scree_fold_'+str(i)+'_'+model_name+'.pkl'   #CHANGE\n",
    "    with open(name,\"rb\") as f:\n",
    "        result[i] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code to generate average scree plot\n",
    "model_name = 'ResNet101'\n",
    "method = 'GMM'\n",
    "folder_name='pkl_resnet'\n",
    "number_of_neurons = 31410176\n",
    "k = 4\n",
    "result ={}\n",
    "for i in range(1,k+1,1):\n",
    "    name = '../../data/'+folder_name+'/'+str(method)+'_multi_scree_fold_'+str(i)+'_'+model_name+'.pkl'   #CHANGE\n",
    "    with open(name,\"rb\") as f:\n",
    "        result[i] = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.20512820512820518,\n",
       " 1: -0.05128205128205121,\n",
       " 2: -0.02564102564102566,\n",
       " 3: -0.05128205128205132,\n",
       " 4: -0.05128205128205121,\n",
       " 5: -0.02564102564102566,\n",
       " 6: 0.17948717948717952,\n",
       " 7: -0.02564102564102566,\n",
       " 8: -0.02564102564102566,\n",
       " 9: -0.05128205128205121,\n",
       " 10: -0.02564102564102566,\n",
       " 11: -0.05128205128205121,\n",
       " 12: -0.02564102564102566,\n",
       " 13: -0.02564102564102566,\n",
       " 14: -0.02564102564102566,\n",
       " 15: -0.05128205128205121,\n",
       " 16: -0.05128205128205132,\n",
       " 17: 0.0,\n",
       " 18: -0.02564102564102566,\n",
       " 19: -0.02564102564102566,\n",
       " 20: -0.02564102564102566,\n",
       " 21: 0.23076923076923073,\n",
       " 22: -0.02564102564102566,\n",
       " 23: -0.02564102564102566,\n",
       " 24: -0.02564102564102566,\n",
       " 25: 0.0,\n",
       " 26: -0.02564102564102566,\n",
       " 27: -0.02564102564102566,\n",
       " 28: -0.02564102564102566,\n",
       " 29: -0.07692307692307698,\n",
       " 30: -0.02564102564102566,\n",
       " 31: -0.05128205128205132,\n",
       " 32: -0.05128205128205121,\n",
       " 33: -0.05128205128205121,\n",
       " 34: 0.0,\n",
       " 35: 0.46153846153846156,\n",
       " 36: -0.02564102564102566,\n",
       " 37: -0.02564102564102566,\n",
       " 38: -0.05128205128205121,\n",
       " 39: -0.02564102564102566,\n",
       " 40: -0.05128205128205121,\n",
       " 41: -0.02564102564102566,\n",
       " 42: -0.02564102564102566,\n",
       " 43: 0.0,\n",
       " 44: -0.02564102564102566,\n",
       " 45: -0.05128205128205121,\n",
       " 46: -0.02564102564102566,\n",
       " 47: -0.02564102564102566,\n",
       " 48: 0.28205128205128205,\n",
       " 49: -0.02564102564102566,\n",
       " 50: -0.05128205128205132,\n",
       " 51: -0.02564102564102566,\n",
       " 52: 0.23076923076923073,\n",
       " 53: -0.02564102564102566,\n",
       " 54: 0.23076923076923073,\n",
       " 55: -0.02564102564102566,\n",
       " 56: -0.02564102564102566,\n",
       " 57: -0.02564102564102566,\n",
       " 58: -0.05128205128205121,\n",
       " 59: -0.02564102564102566,\n",
       " 60: -0.02564102564102566,\n",
       " 61: -0.02564102564102566,\n",
       " 62: -0.02564102564102566,\n",
       " 63: -0.02564102564102566,\n",
       " 64: -0.02564102564102566,\n",
       " 65: -0.02564102564102566,\n",
       " 66: -0.02564102564102566,\n",
       " 67: -0.02564102564102566,\n",
       " 68: -0.02564102564102566,\n",
       " 69: -0.02564102564102566,\n",
       " 70: -0.02564102564102566,\n",
       " 71: 0.0,\n",
       " 72: -0.02564102564102566,\n",
       " 73: 0.0,\n",
       " 74: -0.05128205128205121,\n",
       " 75: -0.05128205128205132,\n",
       " 76: -0.02564102564102566,\n",
       " 77: -0.02564102564102566,\n",
       " 78: -0.05128205128205121,\n",
       " 79: 0.0,\n",
       " 80: -0.15384615384615385,\n",
       " 81: -0.02564102564102566,\n",
       " 82: -0.02564102564102566,\n",
       " 83: -0.02564102564102566,\n",
       " 84: 0.0,\n",
       " 85: -0.02564102564102566,\n",
       " 86: 0.1282051282051282,\n",
       " 87: -0.02564102564102566,\n",
       " 88: -0.02564102564102566,\n",
       " 89: 0.0,\n",
       " 90: -0.02564102564102566,\n",
       " 91: -0.02564102564102566,\n",
       " 92: -0.05128205128205121,\n",
       " 93: -0.02564102564102566,\n",
       " 94: -0.02564102564102566,\n",
       " 95: -0.02564102564102566,\n",
       " 96: -0.02564102564102566,\n",
       " 97: -0.02564102564102566,\n",
       " 98: -0.02564102564102566,\n",
       " 99: -0.02564102564102566,\n",
       " 100: 0.0,\n",
       " 101: -0.02564102564102555,\n",
       " 102: -0.02564102564102566,\n",
       " 103: -0.02564102564102566,\n",
       " 104: -0.02564102564102566,\n",
       " 105: 0.0,\n",
       " 106: -0.02564102564102566,\n",
       " 107: -0.02564102564102566,\n",
       " 108: -0.02564102564102566,\n",
       " 109: -0.02564102564102566,\n",
       " 110: -0.05128205128205132,\n",
       " 111: 0.0,\n",
       " 112: -0.02564102564102566,\n",
       " 113: -0.02564102564102566,\n",
       " 114: -0.05128205128205121,\n",
       " 115: -0.02564102564102566,\n",
       " 116: -0.05128205128205121,\n",
       " 117: 0.05128205128205121,\n",
       " 118: -0.02564102564102566,\n",
       " 119: -0.05128205128205121,\n",
       " 120: -0.41025641025641024,\n",
       " 121: -0.05128205128205121,\n",
       " 122: -0.02564102564102566,\n",
       " 123: -0.02564102564102566,\n",
       " 124: -0.02564102564102566,\n",
       " 125: -0.02564102564102566,\n",
       " 126: -0.02564102564102555,\n",
       " 127: -0.02564102564102566,\n",
       " 128: -0.02564102564102566,\n",
       " 129: -0.02564102564102566,\n",
       " 130: -0.02564102564102566,\n",
       " 131: -0.02564102564102566,\n",
       " 132: -0.02564102564102566,\n",
       " 133: -0.02564102564102566,\n",
       " 134: -0.02564102564102566,\n",
       " 135: -0.02564102564102566,\n",
       " 136: -0.02564102564102555,\n",
       " 137: -0.02564102564102566,\n",
       " 138: 0.07692307692307687,\n",
       " 139: -0.02564102564102566,\n",
       " 140: 0.0,\n",
       " 141: -0.02564102564102566,\n",
       " 142: -0.05128205128205121,\n",
       " 143: -0.02564102564102566,\n",
       " 144: -0.02564102564102566,\n",
       " 145: -0.05128205128205132,\n",
       " 146: -0.02564102564102566,\n",
       " 147: -0.02564102564102566,\n",
       " 148: -0.05128205128205121,\n",
       " 149: -0.02564102564102566,\n",
       " 150: -0.02564102564102566,\n",
       " 151: -0.02564102564102566,\n",
       " 152: -0.05128205128205121,\n",
       " 153: 0.23076923076923073,\n",
       " 154: -0.02564102564102566,\n",
       " 155: 0.0,\n",
       " 156: -0.02564102564102566,\n",
       " 157: -0.05128205128205121,\n",
       " 158: -0.05128205128205121,\n",
       " 159: -0.02564102564102566,\n",
       " 160: -0.02564102564102566,\n",
       " 161: 0.0,\n",
       " 162: -0.02564102564102566,\n",
       " 163: -0.02564102564102566,\n",
       " 164: -0.05128205128205121,\n",
       " 165: 0.0,\n",
       " 166: 0.0,\n",
       " 167: -0.02564102564102566,\n",
       " 168: -0.05128205128205121,\n",
       " 169: -0.05128205128205121,\n",
       " 170: -0.02564102564102566,\n",
       " 171: -0.02564102564102566,\n",
       " 172: -0.02564102564102566,\n",
       " 173: -0.02564102564102566,\n",
       " 174: -0.02564102564102566,\n",
       " 175: -0.02564102564102566,\n",
       " 176: -0.05128205128205121,\n",
       " 177: -0.05128205128205121,\n",
       " 178: -0.02564102564102566,\n",
       " 179: -0.02564102564102566,\n",
       " 180: -0.02564102564102566,\n",
       " 181: -0.02564102564102566,\n",
       " 182: -0.02564102564102566,\n",
       " 183: -0.05128205128205121,\n",
       " 184: 0.0,\n",
       " 185: -0.05128205128205121,\n",
       " 186: -0.02564102564102566,\n",
       " 187: -0.05128205128205121,\n",
       " 188: -0.05128205128205132,\n",
       " 189: 0.0,\n",
       " 190: -0.02564102564102566,\n",
       " 191: -0.02564102564102566,\n",
       " 192: -0.02564102564102566,\n",
       " 193: -0.02564102564102566,\n",
       " 194: -0.02564102564102566,\n",
       " 195: -0.02564102564102566,\n",
       " 196: -0.02564102564102566,\n",
       " 197: 0.02564102564102555,\n",
       " 198: -0.02564102564102566,\n",
       " 199: -0.02564102564102566,\n",
       " 200: -0.02564102564102566,\n",
       " 201: -0.05128205128205121,\n",
       " 202: -0.05128205128205121,\n",
       " 203: -0.02564102564102566,\n",
       " 204: -0.02564102564102566,\n",
       " 205: -0.02564102564102566,\n",
       " 206: -0.02564102564102555,\n",
       " 207: -0.02564102564102566,\n",
       " 208: 0.5128205128205128,\n",
       " 209: -0.02564102564102566,\n",
       " 210: -0.02564102564102566,\n",
       " 211: -0.05128205128205121,\n",
       " 212: -0.02564102564102566,\n",
       " 213: -0.02564102564102566,\n",
       " 214: -0.02564102564102566,\n",
       " 215: -0.10256410256410264,\n",
       " 216: -0.05128205128205132,\n",
       " 217: -0.05128205128205132,\n",
       " 218: -0.02564102564102566,\n",
       " 219: 0.0,\n",
       " 220: -0.05128205128205121,\n",
       " 221: -0.05128205128205121,\n",
       " 222: -0.05128205128205121,\n",
       " 223: -0.02564102564102566,\n",
       " 224: -0.02564102564102566,\n",
       " 225: -0.02564102564102566,\n",
       " 226: -0.05128205128205121,\n",
       " 227: -0.05128205128205121,\n",
       " 228: -0.05128205128205121,\n",
       " 229: -0.02564102564102566,\n",
       " 230: -0.02564102564102566,\n",
       " 231: -0.02564102564102566,\n",
       " 232: -0.02564102564102566,\n",
       " 233: -0.02564102564102566,\n",
       " 234: 0.2564102564102564,\n",
       " 235: -0.05128205128205132,\n",
       " 236: -0.05128205128205121,\n",
       " 237: 0.02564102564102555,\n",
       " 238: -0.02564102564102566,\n",
       " 239: -0.05128205128205121,\n",
       " 240: 0.0,\n",
       " 241: -0.2564102564102564,\n",
       " 242: -0.02564102564102566,\n",
       " 243: -0.02564102564102566,\n",
       " 244: -0.02564102564102566,\n",
       " 245: -0.02564102564102566,\n",
       " 246: -0.05128205128205132,\n",
       " 247: -0.02564102564102566,\n",
       " 248: -0.02564102564102566,\n",
       " 249: -0.05128205128205121,\n",
       " 250: -0.02564102564102566,\n",
       " 251: -0.02564102564102566,\n",
       " 252: -0.02564102564102566,\n",
       " 253: -0.05128205128205121,\n",
       " 254: -0.02564102564102566,\n",
       " 255: -0.02564102564102566}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[1][8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'float' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-8dc4551b3cd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m#print('####',fold, ina, ina_mppi_score)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;31m#print(fold, ina, [result_validate[fold][256][i][1] for i in ina])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0mloc_ana\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mana\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mloc_ina\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mina\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mfold\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not iterable"
     ]
    }
   ],
   "source": [
    "from functools import reduce\n",
    "import itertools\n",
    "fold = 1\n",
    "loc_ana = {}\n",
    "loc_ina = {}\n",
    "pi_ana = {}\n",
    "pi_ina = {}\n",
    "loc_ana_avg = []\n",
    "loc_ina_avg = []\n",
    "for i in range(4):\n",
    "    pi_scores = [i[0] for i in result[fold][8].values()]\n",
    "    pi_scores_ina = [i[0] for i in result[fold][9].values()]\n",
    "    #ana = int(list(pi_scores).index(max(pi_scores)))\n",
    "    #ina = int(list(pi_scores).index(min(pi_scores)))\n",
    "    ana = sorted(range(len(pi_scores)), key=lambda i: pi_scores[i],reverse=True)[0:12]\n",
    "    ina = sorted(range(len(pi_scores)), key=lambda i: pi_scores_ina[i])[0:50]\n",
    "    pi_ana[fold] = [result[fold][8][i][0] for i in ana]\n",
    "    pi_ina[fold] = [result[fold][9][i][0] for i in ina]\n",
    "    #print(fold, ana, ana_mppi_score)\n",
    "    #print('####',fold, ina, ina_mppi_score)\n",
    "    #print(fold, ina, [result_validate[fold][256][i][1] for i in ina])\n",
    "    loc_ana[fold] =  list(itertools.chain.from_iterable([result[fold][8][i][1] for i in ana]))\n",
    "    loc_ina[fold] = list(itertools.chain.from_iterable([result[fold][9][i][1] for i in ina]))\n",
    "    fold+=1\n",
    "loc_ana_avg = list(reduce(set.intersection, [set(item) for item in loc_ana.values()]))\n",
    "loc_ina_avg = list(reduce(set.intersection, [set(item) for item in loc_ina.values()]))\n",
    "print(len(loc_ana_avg),len(loc_ina_avg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(1,figsize=(9,9))\n",
    "ax1 = fig.add_subplot(111)\n",
    "anat_avg = np.zeros(13,)\n",
    "inat_avg = np.zeros(13,)\n",
    "for f in range(1,5,1):\n",
    "    clf_result = result[f]\n",
    "    X = range(1,14,1)\n",
    "    xticks = []\n",
    "    x2ticks = []\n",
    "    anat = []\n",
    "    inat = []\n",
    "    for cl in X:\n",
    "        xticks.append(2**cl)\n",
    "        x2ticks.append(number_of_neurons//2**cl)\n",
    "        i = 0\n",
    "        temp = []\n",
    "        for item in clf_result[cl].keys():\n",
    "            if cl == 8:\n",
    "                if clf_result[cl][item][0] in pi_ana[f]:\n",
    "                    plt.plot(cl,clf_result[cl][item][0],'go',color='#800080')\n",
    "                elif clf_result[cl][item][0] in pi_ina[f]:\n",
    "                    plt.plot(cl,clf_result[cl][item][0],'go',color='#15CF5F')\n",
    "                else:\n",
    "                    plt.plot(cl,clf_result[cl][item][0],'go',color='grey',alpha=0.2)\n",
    "            else:\n",
    "                plt.plot(cl,clf_result[cl][item][0],'go',color='grey',alpha=0.2)\n",
    "            temp.append(clf_result[cl][item][0])\n",
    "            i += 1\n",
    "        anat.append(np.max(temp))\n",
    "        inat.append(np.min(temp))\n",
    "     \n",
    "    anat_avg = np.add(anat_avg,anat)\n",
    "    inat_avg = np.add(inat_avg,inat)\n",
    "    plt.plot(X,anat, color='b',linewidth=1, alpha=0.4,linestyle='dotted')\n",
    "    plt.plot(X,inat, color='C1',linewidth=1,alpha=0.4,linestyle='dotted')\n",
    "\n",
    "for i in range(13):\n",
    "    anat_avg[i] = anat_avg[i] / 4.\n",
    "    inat_avg[i] = inat_avg[i] / 4.\n",
    "    \n",
    "plt.plot(X,anat_avg, color='#800080',linewidth=3,label='Animate')\n",
    "plt.plot(X,inat_avg, color='#15CF5F',linewidth=3, label ='Inanimate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,9))\n",
    "matplotlib.rcParams[\"font.size\"] = 23\n",
    "fig.suptitle('Cross-validation to choose k', fontsize=25)\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1,14,1), anat_avg, color='#800080', linewidth=2, label='Animate')\n",
    "plt.grid(axis='x', color='0.95')\n",
    "plt.xticks(range(1,14,1),xticks, rotation=90)\n",
    "plt.axhline(y=max(anat_avg), color='black', linestyle='--', xmin=0, xmax=0.58)\n",
    "plt.ylim([0,1])\n",
    "plt.ylabel('animate relative impact')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "\n",
    "for f in range(1,5,1):\n",
    "    clf_result = result[f]\n",
    "    X = range(1,14,1)\n",
    "    anat = []\n",
    "    for cl in X:\n",
    "        i = 0\n",
    "        temp =[]\n",
    "        for item in clf_result[cl].keys():\n",
    "            if cl == 8:\n",
    "                if clf_result[cl][item][0] in pi_ana[f]:\n",
    "                    plt.plot(cl,clf_result[cl][item][0],'go',color='#800080')\n",
    "                else:\n",
    "                    plt.plot(cl,clf_result[cl][item][0],'go',color='grey',alpha=0.2)\n",
    "            else:\n",
    "                plt.plot(cl,clf_result[cl][item][0],'go',color='grey',alpha=0.2)\n",
    "            i += 1\n",
    "            temp.append(clf_result[cl][item][0])\n",
    "        anat.append(np.max(temp))\n",
    "    plt.plot(range(1,14,1),anat, color='#800080',linewidth=1, alpha=0.4,linestyle='dotted')\n",
    "plt.legend()\n",
    "\n",
    "inat_avg_pos = -1 * inat_avg\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1,14,1), inat_avg_pos, color='#15CF5F', linewidth=2, label='Inanimate')\n",
    "plt.grid(axis='x', color='0.95')\n",
    "plt.xticks(range(1,14,1),xticks, rotation=90)\n",
    "plt.axhline(y=max(inat_avg_pos), color='black', linestyle='--', xmin=0, xmax=0.65)\n",
    "plt.ylabel('inanimate relative impact')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylim([0,1])\n",
    "\n",
    "for f in range(1,5,1):\n",
    "    clf_result = result[f]\n",
    "    X = range(1,14,1)\n",
    "    inat = []\n",
    "    for cl in X:\n",
    "        i = 0\n",
    "        temp =[]\n",
    "        for item in clf_result[cl].keys():\n",
    "            if cl == 9:\n",
    "                if clf_result[cl][item][0] in pi_ina[f]:\n",
    "                    plt.plot(cl,-1*clf_result[cl][item][0],'go',color='#15CF5F')\n",
    "                else:\n",
    "                    plt.plot(cl,-1*clf_result[cl][item][0],'go',color='grey',alpha=0.2)\n",
    "            else:\n",
    "                plt.plot(cl,-1*clf_result[cl][item][0],'go',color='grey',alpha=0.2)\n",
    "            i += 1\n",
    "            temp.append(-1*clf_result[cl][item][0])\n",
    "        inat.append(np.max(temp))\n",
    "    plt.plot(range(1,14,1),inat, color='#15CF5F',linewidth=1, alpha=0.4,linestyle='dotted')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "#plt.savefig('../../results/mobile_cross_fold.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from keras import backend as K \n",
    "del model\n",
    "K.clear_session()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 - Using the k from Step 1 to do the final groupings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'pkl_vgg16'\n",
    "model_name = 'VGG16'\n",
    "debug = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%time\n",
    "#Testing on test data{\n",
    "data_path = '../../data/pkl_vgg16/'\n",
    "classes = ['animate','inanimate']\n",
    "\n",
    "result = {}\n",
    "\n",
    "with open(data_path+classes[0]+'_test_'+model_name+'.pkl','rb') as f:\n",
    "        X_fold = pickle.load(f)\n",
    "with open(data_path+classes[1]+'_test_'+model_name+'.pkl','rb') as f:\n",
    "        y_fold = pickle.load(f)\n",
    "\n",
    "X = np.column_stack((X_fold,y_fold))  \n",
    "if os.path.exists('../../data/pkl_vgg16/kmeans_first_test_'+model_name+'.pkl'):\n",
    "    with open('../../data/pkl_vgg16/kmeans_first_test_'+model_name+'.pkl',\"rb\") as f:\n",
    "        X_new,pred_kmeans,kmeans = pickle.load(f)\n",
    "else:   \n",
    "   \n",
    "    kmeans = MiniBatchKMeans(n_clusters=65827,\n",
    "                             random_state=42,\n",
    "                             batch_size=6,\n",
    "                             max_iter=10).fit(X)\n",
    "    #print kmeans.cluster_centers_\n",
    "    pred_kmeans = kmeans.predict(X)\n",
    "    X_new = kmeans.cluster_centers_\n",
    "    with open('../../data/pkl_vgg16/kmeans_first_test_'+model_name+'.pkl', 'wb') as handle:\n",
    "        pickle.dump([X_new,pred_kmeans,kmeans], handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#DO CLUSTERING AND GET CLUSTERS\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import Birch\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.mixture import GaussianMixture\n",
    "#import genieclust\n",
    "#import hdbscan\n",
    "#import smm\n",
    "\n",
    "j = 16  #Set this value from scree plot!\n",
    "method = 'GMM'\n",
    "print(j)\n",
    "#clf = hdbscan.HDBSCAN(min_cluster_size=j, gen_min_span_tree=True)\n",
    "#clf = DBSCAN(eps=5.443)\n",
    "#clf = KMeans(n_clusters=j,random_state=143)\n",
    "#clf= SpectralClustering(n_clusters=j,random_state=143)\n",
    "#clf =  AgglomerativeClustering(n_clusters=j, linkage='ward')\n",
    "#clf = Birch(branching_factor=50, n_clusters=j, threshold=0.5,compute_labels=True)\n",
    "clf = GaussianMixture(n_components=j, covariance_type='full',random_state=42)\n",
    "#clf= genieclust.genie.Genie(n_clusters=j)\n",
    "#clf= smm.SMM(n_components=j, covariance_type='full', random_state=143, tol=1e-12,min_covar=1e-6, n_iter=1000, n_init=1, params='wmcd', init_params='wmcd')\n",
    "temp = clf.fit(X_new)\n",
    "y_pred = clf.predict(X_new)\n",
    "#y_pred = clf.fit_predict(X_new)\n",
    "print(set(y_pred))\n",
    "#Z = clf.predict(X)\n",
    "\n",
    "for label in set(y_pred):\n",
    "    print('Cluster: ',j,'Label: ', label)\n",
    "\n",
    "    #Lesioning and measuring performance\n",
    "    pred = y_pred.copy()\n",
    "    loc = np.where(pred==label)\n",
    "    loc_temp = kmeans.predict(X_new[loc[0]])\n",
    "    loc_new =[]\n",
    "    for entry in set(loc_temp):\n",
    "        temp = np.where(pred_kmeans==entry)[0]\n",
    "        loc_new.extend(temp)\n",
    "\n",
    "    lambda_mask = np.ones(shape=((13555712,)))\n",
    "    lambda_mask[loc_new] = 0.\n",
    "\n",
    "    #plt.scatter(X[:,0],X[:,1], c=y_pred) \n",
    "    model = VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000,lambda_mask=lambda_mask)\n",
    "    \n",
    "    flag = 0\n",
    "    dprime = 0.\n",
    "    for p in classes:\n",
    "        im_valid_test = []\n",
    "        image_list_valid = '../../data/pkl_vgg16/'+p+'_image_list_test.txt'\n",
    "        with open(image_list_valid,'r') as f:\n",
    "            for line in f.readlines():\n",
    "                im_valid_test.append(line.strip('\\n'))\n",
    "        im_temp = preprocess_image_batch(im_valid_test,img_size=(256,256), crop_size=(224,224), color_mode=\"rgb\")\n",
    "\n",
    "        out = model.predict(im_temp,batch_size=32)\n",
    "       \n",
    "        true_valid_wids = []\n",
    "        for i in im_valid_test:\n",
    "                temp1 = i.split('/')[4]\n",
    "                temp = temp1.split('.')[0].split('_')[2]\n",
    "                true_valid_wids.append(truth[int(temp)][1])\n",
    "\n",
    "        predicted_valid_wids = []\n",
    "        for i in range(len(im_valid_test)):\n",
    "            #print im_list[i], pprint_output(out[i]), true_wids[i]\n",
    "            predicted_valid_wids.append(pprint_output(out[i]))\n",
    "\n",
    "        count, error  = top5accuracy(true_valid_wids, predicted_valid_wids)\n",
    "\n",
    "        print(str(p)+' '+str(count)+' '+str(len(im_valid_test))+' '+str(error)+' '+str(1-error))\n",
    "\n",
    "        if flag == 0:\n",
    "            dprime = error\n",
    "            flag = 1\n",
    "        else:\n",
    "            dprime -= error\n",
    "    keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    del model\n",
    "\n",
    "    result[label] = dprime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(result.values()),X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X[:,0]\n",
    "y = X[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_temp = []\n",
    "for item in y_pred:\n",
    "    z_temp.append(result[item])\n",
    "print(len(z_temp),len(X_new))\n",
    "loc_z = kmeans.predict(X_new)\n",
    "z = np.ones(shape=((13555712,)))\n",
    "for i in range(len(loc_z)):\n",
    "    temp = np.where(pred_kmeans==loc_z[i])[0]\n",
    "    z[temp] = z_temp[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(result.values()).index(max(result.values())), list(result.values()).index(min(result.values())))\n",
    "ana = int(list(result.values()).index(max(result.values())))\n",
    "ina = int(list(result.values()).index(min(result.values())))\n",
    "print(result[ana], -1*(result[ina]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spax = []\n",
    "spay = []\n",
    "for i in range(0,len(z)):\n",
    "    if z[i] == result[ana]:\n",
    "        spax.append(x[i])\n",
    "        spay.append(y[i])\n",
    "        loc_ana_avg.append(i)\n",
    "\n",
    "spax = np.asarray(spax)\n",
    "spay = np.asarray(spay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spix = []\n",
    "spiy = []\n",
    "for i in range(0,len(z)):\n",
    "    if z[i] == result[ina]:\n",
    "        spix.append(x[i])\n",
    "        spiy.append(y[i])\n",
    "        loc_ina_avg.append(i)\n",
    "spix = np.asarray(spix)\n",
    "spiy = np.asarray(spiy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(16,9))\n",
    "matplotlib.rcParams[\"font.size\"] = 23\n",
    "fig.suptitle('Ablated units', fontsize=25)\n",
    "\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(x,y, c='lightgray', s=10,vmin=-1, vmax=1)\n",
    "plt.scatter(spax, spay, label='Animate',color='#800080')\n",
    "plt.plot([-40,40],[-40,40], 'k--', color='black', alpha=0.75)\n",
    "plt.xlim([-40,40])\n",
    "plt.ylim([-40,40])\n",
    "plt.ylabel('inanimate activation')\n",
    "plt.xlabel('animate activation')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter( x,y, c='lightgray', s=10,vmin=-1, vmax=1)\n",
    "plt.scatter(spix, spiy, color='#15CF5F', label='Inanimate')\n",
    "plt.plot([-40,40],[-40,40], 'k--', color='black', alpha=0.75)\n",
    "plt.xlim([-40,40])\n",
    "plt.ylim([-40,40])\n",
    "plt.ylabel('inanimate activation')\n",
    "plt.xlabel('animate activation')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('../../results/mobile_scatter.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_info = {}\n",
    "#Comparing Layer lesions\n",
    "classes = ['animate','inanimate']\n",
    "%time\n",
    "for label in [ana,ina]:\n",
    "    layer_info[label] = {}\n",
    "    for layer in [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15]:\n",
    "        if layer == 1:\n",
    "            start = 0\n",
    "            end = 3211264\n",
    "        elif layer == 2:\n",
    "            start = 3211264\n",
    "            end = 6422528\n",
    "        elif layer == 3:\n",
    "            start = 6422528\n",
    "            end = 8028160\n",
    "        elif layer == 4:\n",
    "            start = 8028160\n",
    "            end = 9633792\n",
    "        elif layer == 5:\n",
    "            start = 9633792\n",
    "            end = 10436608\n",
    "        elif layer == 6:\n",
    "            start = 10436608\n",
    "            end = 11239424\n",
    "        elif layer == 7:\n",
    "            start = 11239424\n",
    "            end = 12042240\n",
    "        elif layer == 8:\n",
    "            start = 12042240\n",
    "            end = 12443648\n",
    "        elif layer == 9:\n",
    "            start = 12443648\n",
    "            end = 12845056\n",
    "        elif layer == 10:\n",
    "            start = 12845056\n",
    "            end = 13246464\n",
    "        elif layer == 11:\n",
    "            start = 13246464\n",
    "            end = 13346816\n",
    "        elif layer == 12:\n",
    "            start = 13346816\n",
    "            end = 13447168\n",
    "        elif layer == 13:\n",
    "            start = 13447168\n",
    "            end = 13547520\n",
    "        elif layer == 14:\n",
    "            start = 13547520\n",
    "            end = 13551616\n",
    "        elif layer == 15:\n",
    "            start = 13551616\n",
    "            end = 13555712\n",
    "\n",
    "        layer_info[label][layer] = {}\n",
    "    \n",
    "        #No lesion\n",
    "        #print('No-lesioning')\n",
    "        #print('Label:',label)\n",
    "        #print('Layer:',layer)\n",
    "\n",
    "        pred = clf.predict(X_new)\n",
    "        lambda_mask = np.ones(shape=((13555712,)))\n",
    "       \n",
    "\n",
    "        model = VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000,lambda_mask=lambda_mask)\n",
    "\n",
    "        flag = 0\n",
    "        dprime = 0.\n",
    "        for p in classes:\n",
    "            im_valid_test = []\n",
    "            image_list_valid = '../../data/pkl/'+p+'_image_list_test.txt'\n",
    "            with open(image_list_valid,'r') as f:\n",
    "                for line in f.readlines():\n",
    "                    im_valid_test.append(line.strip('\\n'))\n",
    "            im_temp = preprocess_image_batch(im_valid_test,img_size=(256,256), crop_size=(224,224), color_mode=\"rgb\")\n",
    "            out = model.predict(im_temp,batch_size=64)\n",
    "\n",
    "            true_valid_wids = []\n",
    "            for i in im_valid_test:\n",
    "                    temp1 = i.split('/')[4]\n",
    "                    temp = temp1.split('.')[0].split('_')[2]\n",
    "                    true_valid_wids.append(truth[int(temp)][1])\n",
    "\n",
    "            predicted_valid_wids = []\n",
    "            for i in range(len(im_valid_test)):\n",
    "                #print im_list[i], pprint_output(out[i]), true_wids[i]\n",
    "                predicted_valid_wids.append(pprint_output(out[i]))\n",
    "\n",
    "            count, error  = top5accuracy(true_valid_wids, predicted_valid_wids)\n",
    "\n",
    "            print(str(p)+' '+str(count)+' '+str(len(im_valid_test))+' '+str(error)+' '+str(1-error))\n",
    "              \n",
    "            if flag == 0:\n",
    "                dprime = error\n",
    "                flag = 1\n",
    "            else:\n",
    "                dprime -= error\n",
    "        print('Layer: ',layer,'Label: ', label)\n",
    "        print('No lesion: ',dprime)\n",
    "        layer_info[label][layer]['no'] = dprime\n",
    "        \n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "        del model\n",
    "        #Before lesion\n",
    "        #print('Pre-layer-lesioning')\n",
    "        #print('Label:',label)\n",
    "        #print('Layer:',layer)\n",
    "\n",
    "        pred = clf.predict(X_new)\n",
    "        loc = np.where(pred==label)[0]\n",
    "        loc_new =[]\n",
    "        for i in range(len(loc)):\n",
    "            temp = np.where(pred_kmeans==loc[i])[0]\n",
    "            loc_new.extend(temp)\n",
    "\n",
    "        lambda_mask = np.ones(shape=((13555712,)))\n",
    "        lambda_mask[loc_new] = 0.\n",
    "        print('pre-loc', len(loc_new))\n",
    "        model = VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000,lambda_mask=lambda_mask)\n",
    "\n",
    "        flag = 0\n",
    "        dprime = 0.\n",
    "        for p in classes:\n",
    "            im_valid_test = []\n",
    "            image_list_valid = '../../data/pkl/'+p+'_image_list_test.txt'\n",
    "            with open(image_list_valid,'r') as f:\n",
    "                for line in f.readlines():\n",
    "                    im_valid_test.append(line.strip('\\n'))\n",
    "            im_temp = preprocess_image_batch(im_valid_test,img_size=(256,256), crop_size=(224,224), color_mode=\"rgb\")\n",
    "            out = model.predict(im_temp,batch_size=64)\n",
    "\n",
    "            true_valid_wids = []\n",
    "            for i in im_valid_test:\n",
    "                    temp1 = i.split('/')[4]\n",
    "                    temp = temp1.split('.')[0].split('_')[2]\n",
    "                    true_valid_wids.append(truth[int(temp)][1])\n",
    "\n",
    "            predicted_valid_wids = []\n",
    "            for i in range(len(im_valid_test)):\n",
    "                #print im_list[i], pprint_output(out[i]), true_wids[i]\n",
    "                predicted_valid_wids.append(pprint_output(out[i]))\n",
    "\n",
    "            count, error  = top5accuracy(true_valid_wids, predicted_valid_wids)\n",
    "\n",
    "            print(str(p)+' '+str(count)+' '+str(len(im_valid_test))+' '+str(error)+' '+str(1-error))\n",
    "\n",
    "            if flag == 0:\n",
    "                dprime = error\n",
    "                flag = 1\n",
    "            else:\n",
    "                dprime -= error\n",
    "        print('Cluster Only: ',dprime)\n",
    "        layer_info[label][layer]['pre'] = dprime   \n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "        del model\n",
    "             \n",
    "            \n",
    "        #After Lesion\n",
    "       # print('Post-layer-lesioning')\n",
    "        #print('Label:',label)\n",
    "        #print('Layer:',layer)\n",
    "        pred = clf.predict(X_new)\n",
    "        loc = np.where(pred==label)[0]\n",
    "        loc_new =[]\n",
    "        for i in range(len(loc)):\n",
    "            temp = np.where(pred_kmeans==loc[i])[0]\n",
    "            temp2 = temp[np.asarray(np.where((temp >end) | (temp <=start))[0])]\n",
    "            #print(len(temp), len(temp2))\n",
    "            loc_new.extend(temp2)\n",
    "\n",
    "\n",
    "        lambda_mask = np.ones(shape=((13555712,)))\n",
    "        lambda_mask[loc_new] = 0.\n",
    "        print('post-loc', len(loc_new))\n",
    "        model = VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000,lambda_mask=lambda_mask)\n",
    "\n",
    "        flag = 0\n",
    "        dprime = 0.\n",
    "        for p in classes:\n",
    "            im_valid_test = []\n",
    "            image_list_valid = '../../data/pkl/'+p+'_image_list_test.txt'\n",
    "            with open(image_list_valid,'r') as f:\n",
    "                for line in f.readlines():\n",
    "                    im_valid_test.append(line.strip('\\n'))\n",
    "            im_temp = preprocess_image_batch(im_valid_test,img_size=(256,256), crop_size=(224,224), color_mode=\"rgb\")\n",
    "            out = model.predict(im_temp,batch_size=64)\n",
    "\n",
    "            true_valid_wids = []\n",
    "            for i in im_valid_test:\n",
    "                    temp1 = i.split('/')[4]\n",
    "                    temp = temp1.split('.')[0].split('_')[2]\n",
    "                    true_valid_wids.append(truth[int(temp)][1])\n",
    "\n",
    "            predicted_valid_wids = []\n",
    "            for i in range(len(im_valid_test)):\n",
    "                #print im_list[i], pprint_output(out[i]), true_wids[i]\n",
    "                predicted_valid_wids.append(pprint_output(out[i]))\n",
    "\n",
    "            count, error  = top5accuracy(true_valid_wids, predicted_valid_wids)\n",
    "\n",
    "            print(str(p)+' '+str(count)+' '+str(len(im_valid_test))+' '+str(error)+' '+str(1-error))\n",
    "\n",
    "            if flag == 0:\n",
    "                dprime = error\n",
    "                flag = 1\n",
    "            else:\n",
    "                dprime -= error\n",
    "        print('Cluster - layer: ',dprime)\n",
    "        layer_info[label][layer]['post'] = dprime\n",
    "        \n",
    "        \n",
    "         #Random Lesion\n",
    "       # print('Post-layer-lesioning')\n",
    "        #print('Label:',label)\n",
    "        #print('Layer:',layer)\n",
    "        pred = clf.predict(X_new)\n",
    "        loc = np.where(pred==label)[0]\n",
    "        loc_new =[]\n",
    "        for i in range(len(loc)):\n",
    "            temp = np.where(pred_kmeans==loc[i])[0]\n",
    "            temp2 = temp[np.asarray(np.where((temp >end) | (temp <=start))[0])]\n",
    "            #print(len(temp), len(temp2))\n",
    "            loc_new.extend(temp2)\n",
    "\n",
    "        loc_new2 = np.random.randint(start,end,len(loc_new))\n",
    "        lambda_mask = np.ones(shape=((13555712,)))\n",
    "        lambda_mask[loc_new2] = 0.\n",
    "        print('post-rand-loc', len(loc_new))\n",
    "        model = VGG16(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling=None, classes=1000,lambda_mask=lambda_mask)\n",
    "\n",
    "        flag = 0\n",
    "        dprime = 0.\n",
    "        for p in classes:\n",
    "            im_valid_test = []\n",
    "            image_list_valid = '../../data/pkl/'+p+'_image_list_test.txt'\n",
    "            with open(image_list_valid,'r') as f:\n",
    "                for line in f.readlines():\n",
    "                    im_valid_test.append(line.strip('\\n'))\n",
    "            im_temp = preprocess_image_batch(im_valid_test,img_size=(256,256), crop_size=(224,224), color_mode=\"rgb\")\n",
    "            out = model.predict(im_temp,batch_size=64)\n",
    "\n",
    "            true_valid_wids = []\n",
    "            for i in im_valid_test:\n",
    "                    temp1 = i.split('/')[4]\n",
    "                    temp = temp1.split('.')[0].split('_')[2]\n",
    "                    true_valid_wids.append(truth[int(temp)][1])\n",
    "\n",
    "            predicted_valid_wids = []\n",
    "            for i in range(len(im_valid_test)):\n",
    "                #print im_list[i], pprint_output(out[i]), true_wids[i]\n",
    "                predicted_valid_wids.append(pprint_output(out[i]))\n",
    "\n",
    "            count, error  = top5accuracy(true_valid_wids, predicted_valid_wids)\n",
    "\n",
    "            print(str(p)+' '+str(count)+' '+str(len(im_valid_test))+' '+str(error)+' '+str(1-error))\n",
    "\n",
    "            if flag == 0:\n",
    "                dprime = error\n",
    "                flag = 1\n",
    "            else:\n",
    "                dprime -= error\n",
    "        print('Random: ',dprime)\n",
    "        layer_info[label][layer]['rand'] = dprime\n",
    "        tf.keras.backend.clear_session()\n",
    "        gc.collect()\n",
    "        del model\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "keras.backend.clear_session()\n",
    "gc.collect()\n",
    "if 'model' in locals():\n",
    "    del model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 - Generating Salience figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-trained model - Without lesion\n",
    "model = MobileNetV2( input_shape=None, alpha=0.35,include_top=True, \n",
    "                    weights=\"imagenet\",input_tensor=None, pooling=None, \n",
    "                    classifier_activation=\"softmax\", classes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-trained model - With lesion\n",
    "'''\n",
    "label=ana\n",
    "#print(label,result[label])\n",
    "pred = clf.predict(X_new)\n",
    "loc = np.where(pred==label)\n",
    "loc_temp = kmeans.predict(X_new[loc[0]])\n",
    "loc_new =[]\n",
    "for entry in set(loc_temp):\n",
    "    temp = np.where(pred_kmeans==entry)[0]\n",
    "    loc_new.extend(temp)\n",
    "'''\n",
    "lambda_mask = np.ones(shape=((5725552,)))\n",
    "print(len(loc_ana_avg),' out of 5725552')\n",
    "lambda_mask[loc_ana_avg] = 0.\n",
    "model = MobileNetV2( input_shape=None, alpha=0.35,include_top=True, \n",
    "                    weights=\"imagenet\",input_tensor=None, pooling=None, \n",
    "                    classes=1000, classifier_activation=\"softmax\", lambda_mask=lambda_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_list_valid = '../../data/pkl_mobile/animate_MobileNetV2_image_list_test.txt'\n",
    "im_valid_test = []\n",
    "with open(image_list_valid,'r') as f:\n",
    "    for line in f.readlines():\n",
    "        im_valid_test.append(line.strip('\\n'))\n",
    "        \n",
    "im_temp = preprocess_image_batch(im_valid_test,img_size=(256,256), crop_size=(224,224), color_mode=\"rgb\")\n",
    "out = model.predict(im_temp,batch_size=64)\n",
    "\n",
    "true_valid_wids = []\n",
    "for i in im_valid_test:\n",
    "        temp1 = i.split('/')[4]\n",
    "        temp = temp1.split('.')[0].split('_')[2]\n",
    "        true_valid_wids.append(truth[int(temp)][1])\n",
    "\n",
    "predicted_valid_wids = []\n",
    "for i in range(len(im_valid_test)):\n",
    "    #print im_list[i], pprint_output(out[i]), true_wids[i]\n",
    "    predicted_valid_wids.append(pprint_output(out[i]))\n",
    "\n",
    "count, error  = top5accuracy(true_valid_wids, predicted_valid_wids)\n",
    "\n",
    "print(len(true_valid_wids), len(predicted_valid_wids), len(im_valid_test))\n",
    "print(count, error)\n",
    "c=0\n",
    "w=0\n",
    "flag  = 0\n",
    "for i in range(len(true_valid_wids)):\n",
    "    flag  = 0\n",
    "    temp = true_valid_wids[i]\n",
    "    for j in predicted_valid_wids[i][0:5]:\n",
    "        if j == temp:\n",
    "            flag = 1\n",
    "            break\n",
    "    if flag == 1:\n",
    "        c +=1\n",
    "        print(i,'1 - Correct')\n",
    "    else:\n",
    "        w+=1\n",
    "        print(i,'0 - Wrong')\n",
    "print(c,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_name = im_valid_test[9]\n",
    "_img = load_img(image_name,target_size=(224,224))\n",
    "plt.imshow(_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_idx = vis_utils.find_layer_idx(model, 'Logits')\n",
    "model.layers[layer_idx].activation = keras.activations.linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model\n",
    "# Strip softmax layer\n",
    "#model = innvestigate.utils.model_wo_softmax(model)\n",
    "\n",
    "# Create analyzer\n",
    "analyzer = innvestigate.create_analyzer(\"gradient\", model,reverse_keep_tensors=True,allow_lambda_layers =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add batch axis and preprocess\n",
    "image_name = im_valid_test[9]\n",
    "x = preprocess_image_batch([image_name],img_size=(256,256), crop_size=(224,224), color_mode=\"rgb\")\n",
    "print(x.shape)\n",
    "# Apply analyzer w.r.t. maximum activated output-neuron\n",
    "a = analyzer.analyze(x)\n",
    "\n",
    "# Aggregate along color channels and normalize to [-1, 1]\n",
    "a = a.sum(axis=np.argmax(np.asarray(a.shape) == 3))\n",
    "a /= np.max(np.abs(a))\n",
    "# Plot\n",
    "plt.imshow(a[0], cmap=\"seismic\", clim=(-1, 1))\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_specific_impact_idx = 4\n",
    "no_impact_idx = 5\n",
    "animate_impact_idx = 1\n",
    "inanimate_impact_idx = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "#fig = plt.figure(figsize=(8, 24),constrained_layout=True) #figsize - width,height\n",
    "fig = plt.figure(figsize=(16, 8),constrained_layout=True)\n",
    "fig.set_constrained_layout_pads(w_pad=4/72,h_pad=4/72, hspace=0, wspace=0)\n",
    "spec = gridspec.GridSpec(ncols=4, nrows=2, figure=fig)\n",
    "original_flag = 0\n",
    "row= column = 0\n",
    "for high_impact_cluster in [-1,1,2]:\n",
    "    if high_impact_cluster == -1:\n",
    "        row = 0\n",
    "        column = 1 \n",
    "        #Pre-trained model - Without lesion\n",
    "        model = MobileNetV2( input_shape=None, alpha=0.35,include_top=True, \n",
    "                            weights=\"imagenet\",input_tensor=None, pooling=None, \n",
    "                    classifier_activation=\"softmax\", classes=1000)\n",
    "    elif high_impact_cluster == 1:\n",
    "        row = 0\n",
    "        column = 2\n",
    "        lambda_mask = np.ones(shape=((5725552,)))\n",
    "        #print(len(loc_new),' out of 5725552')\n",
    "        lambda_mask[loc_ana_avg] = 0.\n",
    "        model = MobileNetV2( input_shape=None, alpha=0.35,include_top=True, \n",
    "                            weights=\"imagenet\",input_tensor=None, pooling=None, \n",
    "                            classes=1000, classifier_activation=\"softmax\", lambda_mask=lambda_mask)\n",
    "    elif high_impact_cluster == 2:\n",
    "        row = 0\n",
    "        column = 3\n",
    "        lambda_mask = np.ones(shape=((5725552,)))\n",
    "        #print(len(loc_new),' out of 5725552')\n",
    "        lambda_mask[loc_ina_avg] = 0.\n",
    "        model = MobileNetV2( input_shape=None, alpha=0.35,include_top=True, \n",
    "                            weights=\"imagenet\",input_tensor=None, pooling=None, \n",
    "                            classes=1000, classifier_activation=\"softmax\", lambda_mask=lambda_mask)\n",
    "    else:\n",
    "        #Pre-trained model - With lesion\n",
    "        row =  0\n",
    "        if high_impact_cluster == 1:\n",
    "            column = 2\n",
    "        elif high_impact_cluster == 2:\n",
    "            column = 3\n",
    "        elif high_impact_cluster == no_impact_idx:\n",
    "            column = 2\n",
    "        elif high_impact_cluster == no_specific_impact_idx:\n",
    "            column = 3\n",
    "        elif high_impact_cluster == animate_impact_idx:\n",
    "            column = 4\n",
    "        else:\n",
    "            column = 5\n",
    "        label=high_impact_cluster\n",
    "        print(label,result[label])\n",
    "        pred = clf.predict(X_new)\n",
    "        loc = np.where(pred==label)\n",
    "        loc_temp = kmeans.predict(X_new[loc[0]])\n",
    "        loc_new =[]\n",
    "        for entry in set(loc_temp):\n",
    "            temp = np.where(pred_kmeans==entry)[0]\n",
    "            loc_new.extend(temp)\n",
    "\n",
    "        lambda_mask = np.ones(shape=((5725552,)))\n",
    "        #print(len(loc_new),' out of 5725552')\n",
    "        lambda_mask[loc_new] = 0.\n",
    "        model = MobileNetV2( input_shape=None, alpha=0.35,include_top=True, \n",
    "                            weights=\"imagenet\",input_tensor=None, pooling=None, \n",
    "                            classes=1000, classifier_activation=\"softmax\", lambda_mask=lambda_mask)\n",
    "        \n",
    "    layer_idx = vis_utils.find_layer_idx(model, 'Logits')\n",
    "    model.layers[layer_idx].activation = keras.activations.linear\n",
    "    \n",
    "    # Create analyzer\n",
    "    analyzer = innvestigate.create_analyzer(\"gradient\", model,reverse_keep_tensors=True,allow_lambda_layers =True)\n",
    "    \n",
    "    for class_label in ['animate','inanimate']:\n",
    "        image_list_valid = '../../data/pkl_mobile/'+class_label+'_MobileNetV2_image_list_test.txt'\n",
    "        im_valid_test = []\n",
    "        with open(image_list_valid,'r') as f:\n",
    "            for line in f.readlines():\n",
    "                im_valid_test.append(line.strip('\\n'))\n",
    "\n",
    "        im_temp = preprocess_image_batch(im_valid_test,img_size=(256,256), crop_size=(224,224), color_mode=\"rgb\")\n",
    "        out = model.predict(im_temp,batch_size=64)\n",
    "\n",
    "        true_valid_wids = []\n",
    "        for i in im_valid_test:\n",
    "                temp1 = i.split('/')[4]\n",
    "                temp = temp1.split('.')[0].split('_')[2]\n",
    "                true_valid_wids.append(truth[int(temp)][1])\n",
    "\n",
    "        predicted_valid_wids = []\n",
    "        for i in range(len(im_valid_test)):\n",
    "            #print im_list[i], pprint_output(out[i]), true_wids[i]\n",
    "            predicted_valid_wids.append(pprint_output(out[i]))\n",
    "\n",
    "        count, error  = top5accuracy(true_valid_wids, predicted_valid_wids)\n",
    "        print(high_impact_cluster, class_label)\n",
    "        \n",
    "        color = []\n",
    "        line_style = []\n",
    "        c=0\n",
    "        w=0\n",
    "        flag  = 0\n",
    "        for i in range(len(true_valid_wids)):\n",
    "            flag  = 0\n",
    "            temp = true_valid_wids[i]\n",
    "            for j in predicted_valid_wids[i][0:5]:\n",
    "                if j == temp:\n",
    "                    flag = 1\n",
    "                    break\n",
    "            if flag == 1:\n",
    "                c +=1\n",
    "                color.append('green')\n",
    "                line_style.append('-.')\n",
    "                #print(i,'1 - Correct')\n",
    "            else:\n",
    "                w+=1\n",
    "                color.append('red')\n",
    "                line_style.append('-')\n",
    "                #print(i,'0 - Wrong')\n",
    "        #print(c,w)\n",
    "        \n",
    "        for image_idx in range(23,24): #2,3 - 6,7 - 7,8\n",
    "            _img = load_img(im_valid_test[image_idx],target_size=(224,224))\n",
    "            if original_flag < 2:\n",
    "                ax = fig.add_subplot(spec[row,0])\n",
    "                ax.imshow(_img)\n",
    "                ax.axis('off')\n",
    "                ax.set_aspect('equal')     \n",
    "                \n",
    "            x = preprocess_image_batch([im_valid_test[image_idx]],img_size=(256,256), crop_size=(224,224), color_mode=\"rgb\")\n",
    "            #print(x.shape)\n",
    "            # Apply analyzer w.r.t. maximum activated output-neuron\n",
    "            a = analyzer.analyze(x)\n",
    "\n",
    "            # Aggregate along color channels and normalize to [-1, 1]\n",
    "            a = a.sum(axis=np.argmax(np.asarray(a.shape) == 3))\n",
    "            a /= np.max(np.abs(a))\n",
    "            # Plot\n",
    "            #print(row,column)\n",
    "            ax = fig.add_subplot(spec[row,column])\n",
    "            ax.imshow(a[0], cmap=\"seismic\", clim=(-1, 1))\n",
    "            ax.set_xticks([])\n",
    "            ax.set_yticks([])\n",
    "            for spine in ax.spines.values():\n",
    "                spine.set_edgecolor(color[image_idx])\n",
    "                spine.set_linestyle(line_style[image_idx])\n",
    "                spine.set_linewidth(4.)\n",
    "            ax.set_aspect('equal')\n",
    "            row += 1\n",
    "            if high_impact_cluster == -1:\n",
    "                column = 1\n",
    "            elif high_impact_cluster == 1:\n",
    "                column = 2\n",
    "            elif high_impact_cluster == 2:\n",
    "                column = 3\n",
    "            elif high_impact_cluster == -1:\n",
    "                column = 1\n",
    "            elif high_impact_cluster == no_specific_impact_idx:\n",
    "                column = 3\n",
    "            elif high_impact_cluster == animate_impact_idx:\n",
    "                column = 4\n",
    "            elif high_impact_cluster == inanimate_impact_idx:\n",
    "                column = 5\n",
    "            else:\n",
    "                column = 1\n",
    "           \n",
    "  \n",
    "        if original_flag < 2:\n",
    "            original_flag += 1\n",
    "        '''\n",
    "        print(len(true_valid_wids), len(predicted_valid_wids), len(im_valid_test))\n",
    "        print(count, error)\n",
    "        '''\n",
    "        \n",
    "        \n",
    "    keras.backend.clear_session()\n",
    "    gc.collect()\n",
    "    del model\n",
    "#plt.savefig('../../results/row-6.png', format='png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
