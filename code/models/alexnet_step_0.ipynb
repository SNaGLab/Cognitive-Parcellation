{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "#To hide warnings export PYTHONWARNINGS=\"ignore\"\n",
    "#Imports{\n",
    "\n",
    "import os\n",
    "from os.path import dirname\n",
    "from os.path import join\n",
    "os.environ['KERAS_BACKEND'] = 'theano'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' #Cha\n",
    "\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy.misc import imread\n",
    "from scipy.misc import imresize\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, MaxPooling2D, Input, ZeroPadding2D,merge,Lambda\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.models import Model\n",
    "from keras.utils.layer_utils import convert_all_kernels_in_model\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "from keras.engine import Layer\n",
    "from keras.layers.core import Lambda\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.layers.core import  Lambda\n",
    "from keras.regularizers import l2\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code snippet needed to read activation values from each layer of the pre-trained artificial neural networks\n",
    "def get_activations(model, layer, X_batch):\n",
    "    #keras.backend.function(inputs, outputs, updates=None)\n",
    "    get_activations = K.function([model.layers[0].input, K.learning_phase()], [model.layers[layer].output,])\n",
    "    #The learning phase flag is a bool tensor (0 = test, 1 = train)\n",
    "    activations = get_activations([X_batch,0])\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to pre-process the input image to ensure uniform size and color\n",
    "def preprocess_image_batch(image_paths, img_size=None, crop_size=None, color_mode='rgb', out=None):\n",
    "    \"\"\"\n",
    "    Consistent preprocessing of images batches\n",
    "    :param image_paths: iterable: images to process\n",
    "    :param crop_size: tuple: crop images if specified\n",
    "    :param img_size: tuple: resize images if specified\n",
    "    :param color_mode: Use rgb or change to bgr mode based on type of model you want to use\n",
    "    :param out: append output to this iterable if specified\n",
    "    \"\"\"\n",
    "    img_list = []\n",
    "\n",
    "    for im_path in image_paths:\n",
    "        img = imread(im_path, mode='RGB')\n",
    "        #print im_path\n",
    "        #print img.shape\n",
    "        if img_size:\n",
    "            img = imresize(img, img_size)\n",
    "\n",
    "        img = img.astype('float32')\n",
    "        # We normalize the colors (in RGB space) with the empirical means on the training set\n",
    "        img[:, :, 0] -= 123.68\n",
    "        img[:, :, 1] -= 116.779\n",
    "        img[:, :, 2] -= 103.939\n",
    "        # We permute the colors to get them in the BGR order\n",
    "        if color_mode == 'bgr':\n",
    "            img[:, :, [0, 1, 2]] = img[:, :, [2, 1, 0]]\n",
    "        img = img.transpose((2, 0, 1))\n",
    "\n",
    "        if crop_size:\n",
    "            img = img[:, (img_size[0] - crop_size[0]) // 2:(img_size[0] + crop_size[0]) // 2\n",
    "            , (img_size[1] - crop_size[1]) // 2:(img_size[1] + crop_size[1]) // 2]\n",
    "\n",
    "        img_list.append(img)\n",
    "\n",
    "    try:\n",
    "        img_batch = np.stack(img_list, axis=0)\n",
    "    except:\n",
    "        print im_path\n",
    "        raise ValueError('when img_size and crop_size are None, images'\n",
    "                ' in image_paths must have the same shapes.')\n",
    "\n",
    "    if out is not None and hasattr(out, 'append'):\n",
    "        out.append(img_batch)\n",
    "    else:\n",
    "        return img_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function to normalization across channels\n",
    "K.set_image_dim_ordering('th')\n",
    "def crosschannelnormalization(alpha=1e-4, k=2, beta=0.75, n=5, **kwargs):\n",
    "    \"\"\"\n",
    "    This is the function used for cross channel normalization in the original\n",
    "    Alexnet\n",
    "    \"\"\"\n",
    "    def f(X):\n",
    "        if K.image_dim_ordering()=='tf':\n",
    "            b, r, c, ch = X.get_shape()\n",
    "        else:\n",
    "            b, ch, r, c = X.shape\n",
    "\n",
    "        half = n // 2\n",
    "        square = K.square(X)\n",
    "        scale = k\n",
    "        if K.image_dim_ordering() == 'th':\n",
    "            extra_channels = K.spatial_2d_padding(K.permute_dimensions(square, (0, 2, 3, 1)), ((0,0),(half,half)))\n",
    "            extra_channels = K.permute_dimensions(extra_channels, (0, 3, 1, 2))\n",
    "            for i in range(n):\n",
    "                scale += alpha * extra_channels[:, i:i+ch, :, :]\n",
    "        if K.image_dim_ordering() == 'tf':\n",
    "            extra_channels = K.spatial_2d_padding(K.permute_dimensions(square, (0, 3, 1, 2)), (half, 0))\n",
    "            extra_channels = K.permute_dimensions(extra_channels, (0, 2, 3, 1))\n",
    "            for i in range(n):\n",
    "                scale += alpha * extra_channels[:, :, :, i:i+int(ch)]\n",
    "        scale = scale ** beta\n",
    "        return X / scale\n",
    "\n",
    "\n",
    "    return Lambda(f, output_shape=lambda input_shape: input_shape, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Function to split tensor\n",
    "def splittensor(axis=1, ratio_split=1, id_split=0, **kwargs):\n",
    "    def f(X):\n",
    "        div = K.shape(X)[axis] // ratio_split\n",
    "\n",
    "        if axis == 0:\n",
    "            output = X[id_split*div:(id_split+1)*div, :, :, :]\n",
    "        elif axis == 1:\n",
    "            output = X[:, id_split*div:(id_split+1)*div, :, :]\n",
    "        elif axis == 2:\n",
    "            output = X[:, :, id_split*div:(id_split+1)*div, :]\n",
    "        elif axis == 3:\n",
    "            output = X[:, :, :, id_split*div:(id_split+1)*div]\n",
    "        else:\n",
    "            raise ValueError(\"This axis is not possible\")\n",
    "        return output\n",
    "\n",
    "    def g(input_shape):\n",
    "        output_shape = list(input_shape)\n",
    "        output_shape[axis] = output_shape[axis] // ratio_split\n",
    "        return tuple(output_shape)\n",
    "\n",
    "\n",
    "    return Lambda(f, output_shape=lambda input_shape: g(input_shape), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alexnet layer architecture class\n",
    "def AlexNet(img_shape=(3, 227, 227), n_classes=1000, l2_reg=0.,weights_path=None):\n",
    "\n",
    "    dim_ordering = K.image_dim_ordering()\n",
    "    print dim_ordering\n",
    "    if dim_ordering == 'th':\n",
    "        batch_index = 0\n",
    "        channel_index = 1\n",
    "        row_index = 2\n",
    "        col_index = 3\n",
    "    if dim_ordering == 'tf':\n",
    "        batch_index = 0\n",
    "        channel_index = 3\n",
    "        row_index = 1\n",
    "        col_index = 2\n",
    "\n",
    "    inputs = Input(img_shape)\n",
    "\n",
    "    conv_1 = Convolution2D(96, 11, 11, subsample=(4, 4), activation='relu',\n",
    "                           name='conv_1', W_regularizer=l2(l2_reg))(inputs)\n",
    "\n",
    "    conv_1_mask = np.ones(shape=((96, 55, 55)))\n",
    "    conv_1_mask  = K.variable(conv_1_mask)\n",
    "    conv_1_lambda = Lambda(lambda x: x * conv_1_mask)(conv_1)\n",
    "\n",
    "    conv_2 = MaxPooling2D((3, 3), strides=(2, 2))(conv_1_lambda)\n",
    "    conv_2 = crosschannelnormalization(name=\"convpool_1\")(conv_2)\n",
    "    conv_2 = ZeroPadding2D((2, 2))(conv_2)\n",
    "    conv_2 = merge([\n",
    "        Convolution2D(128, 5, 5, activation=\"relu\", name='conv_2_'+str(i+1),\n",
    "                      W_regularizer=l2(l2_reg))(\n",
    "            splittensor(axis=channel_index, ratio_split=2, id_split=i)(conv_2)\n",
    "        ) for i in range(2)], mode='concat', concat_axis=channel_index, name=\"conv_2\")\n",
    "\n",
    "    conv_2_mask = np.ones(shape=((256, 27, 27)))\n",
    "    conv_2_mask = K.variable(conv_2_mask)\n",
    "    conv_2_lambda = Lambda(lambda x: x * conv_2_mask)(conv_2)\n",
    "\n",
    "    conv_3 = MaxPooling2D((3, 3), strides=(2, 2))(conv_2_lambda)\n",
    "    conv_3 = crosschannelnormalization()(conv_3)\n",
    "    conv_3 = ZeroPadding2D((1, 1))(conv_3)\n",
    "    conv_3 = Convolution2D(384, 3, 3, activation='relu', name='conv_3',\n",
    "                           W_regularizer=l2(l2_reg))(conv_3)\n",
    "\n",
    "    conv_3_mask = np.ones(shape=((384, 13, 13)))\n",
    "    conv_3_mask = K.variable(conv_3_mask)\n",
    "    conv_3_lambda = Lambda(lambda x: x * conv_3_mask)(conv_3)\n",
    "\n",
    "    conv_4 = ZeroPadding2D((1, 1))(conv_3_lambda)\n",
    "    conv_4 = merge([\n",
    "        Convolution2D(192, 3, 3, activation=\"relu\", name='conv_4_'+str(i+1),\n",
    "                      W_regularizer=l2(l2_reg))(\n",
    "            splittensor(axis=channel_index, ratio_split=2, id_split=i)(conv_4)\n",
    "        ) for i in range(2)], mode='concat', concat_axis=channel_index, name=\"conv_4\")\n",
    "\n",
    "    conv_4_mask = np.ones(shape=((384, 13, 13)))\n",
    "    conv_4_mask = K.variable(conv_4_mask)\n",
    "    conv_4_lambda = Lambda(lambda x: x * conv_4_mask)(conv_4)\n",
    "\n",
    "    conv_5 = ZeroPadding2D((1, 1))(conv_4_lambda)\n",
    "    conv_5 = merge([\n",
    "        Convolution2D(128, 3, 3, activation=\"relu\", name='conv_5_'+str(i+1),\n",
    "                      W_regularizer=l2(l2_reg))(\n",
    "            splittensor(axis=channel_index, ratio_split=2, id_split=i)(conv_5)\n",
    "        ) for i in range(2)], mode='concat', concat_axis=channel_index, name=\"conv_5\")\n",
    "\n",
    "    conv_5_mask = np.ones(shape=((256, 13, 13)))\n",
    "    conv_5_mask = K.variable(conv_5_mask)\n",
    "    conv_5_lambda = Lambda(lambda x: x * conv_5_mask)(conv_5)\n",
    "\n",
    "    dense_1 = MaxPooling2D((3, 3), strides=(2, 2), name=\"convpool_5\")(conv_5_lambda)\n",
    "\n",
    "    dense_1 = Flatten(name=\"flatten\")(dense_1)\n",
    "    dense_1 = Dense(4096, activation='relu', name='dense_1',\n",
    "                    W_regularizer=l2(l2_reg))(dense_1)\n",
    "\n",
    "    dense_1_mask = np.ones(shape=((4096,)))\n",
    "    dense_1_mask = K.variable(dense_1_mask)\n",
    "    dense_1_lambda = Lambda(lambda x: x * dense_1_mask)(dense_1)\n",
    "\n",
    "    dense_2 = Dropout(0.5)(dense_1_lambda)\n",
    "    dense_2 = Dense(4096, activation='relu', name='dense_2',\n",
    "                    W_regularizer=l2(l2_reg))(dense_2)\n",
    "\n",
    "    dense_2_mask = np.ones(shape=((4096,)))\n",
    "    dense_2_mask = K.variable(dense_2_mask)\n",
    "    dense_2_lambda = Lambda(lambda x: x * dense_2_mask)(dense_2)\n",
    "\n",
    "    dense_3 = Dropout(0.5)(dense_2_lambda)\n",
    "    if n_classes == 1000:\n",
    "        dense_3 = Dense(n_classes, name='dense_3',\n",
    "                        W_regularizer=l2(l2_reg))(dense_3)\n",
    "        dense_3_mask = np.ones(shape=((1000,)))\n",
    "        dense_3_mask = K.variable(dense_3_mask)\n",
    "        dense_3_lambda = Lambda(lambda x: x * dense_3_mask)(dense_3)\n",
    "    else:\n",
    "        # We change the name so when loading the weights_file from a\n",
    "        # Imagenet pretrained model does not crash\n",
    "        dense_3 = Dense(n_classes, name='dense_3_new',\n",
    "                        W_regularizer=l2(l2_reg))(dense_3)\n",
    "        dense_3_mask = np.ones(shape=((1000,)))\n",
    "        dense_3_mask = K.variable(dense_3_mask)\n",
    "        dense_3_lambda = Lambda(lambda x: x * dense_3_mask)(dense_3)\n",
    "\n",
    "    prediction = Activation(\"softmax\", name=\"softmax\")(dense_3_lambda)\n",
    "\n",
    "    model = Model(input=inputs, output=prediction)\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the details of all the 1000 classes and the function to conver the synset id to words{\n",
    "meta_clsloc_file = '../../data/meta_clsloc.mat'\n",
    "synsets = loadmat(meta_clsloc_file)['synsets'][0]\n",
    "synsets_imagenet_sorted = sorted([(int(s[0]), str(s[1][0])) for s in synsets[:1000]],key=lambda v: v[1])\n",
    "corr = {}\n",
    "for j in range(1000):\n",
    "    corr[synsets_imagenet_sorted[j][0]] = j\n",
    "\n",
    "corr_inv = {}\n",
    "for j in range(1, 1001):\n",
    "    corr_inv[corr[j]] = j\n",
    "\n",
    "def id_to_words(id_):\n",
    "    return synsets[corr_inv[id_] - 1][2][0]\n",
    "\n",
    "def pprint_output(out, n_max_synsets=10):\n",
    "    wids = []\n",
    "    best_ids = out.argsort()[::-1][:10]\n",
    "    for u in best_ids:\n",
    "        wids.append(str(synsets[corr_inv[u] - 1][1][0]))\n",
    "    #print('%.2f' % round(100 * out[u], 2) + ' : ' + id_to_words(u)+' '+ str(synsets[corr_inv[u] - 1][1][0]))\n",
    "    return wids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code snippet to load the ground truth labels to measure the performance{\n",
    "truth = {}\n",
    "with open('../../data/ILSVRC2014_clsloc_validation_ground_truth.txt') as f:\n",
    "    line_num = 1\n",
    "    for line in f.readlines():\n",
    "        ind_ = int(line)\n",
    "        temp  = None\n",
    "        for i in synsets_imagenet_sorted:\n",
    "            if i[0] == ind_:\n",
    "                temp = i\n",
    "        #print ind_,temp\n",
    "        if temp != None:\n",
    "            truth[line_num] = temp\n",
    "        else:\n",
    "            print '##########', ind_\n",
    "            pass\n",
    "        line_num += 1\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to predict the top 5 accuracy\n",
    "def top5accuracy(true, predicted):\n",
    "    assert len(true) == len(predicted)\n",
    "    result = []\n",
    "    flag  = 0\n",
    "    for i in range(len(true)):\n",
    "        flag  = 0\n",
    "        temp = true[i]\n",
    "        for j in predicted[i]:\n",
    "            if j == temp:\n",
    "                flag = 1\n",
    "                break\n",
    "        if flag == 1:\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(0)\n",
    "    counter = 0.\n",
    "    for i in result:\n",
    "        if i == 1:\n",
    "            counter += 1.\n",
    "    error = 1.0 - counter/float(len(result))\n",
    "    #print len(np.where(np.asarray(result) == 1)[0])\n",
    "    return len(np.where(np.asarray(result) == 1)[0]), error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inanimate\n"
     ]
    }
   ],
   "source": [
    "# Loading the folder to be procesed from command line{\n",
    "p = 'inanimate'\n",
    "tmp = p.replace('/','_')\n",
    "print tmp\n",
    "\n",
    "\n",
    "p_num = 1\n",
    "url_path = '../../data/'+p+'/'\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the image list and pre-process them{\n",
    "true_wids = []\n",
    "im_list = []\n",
    "for i in os.listdir(url_path):\n",
    "    if not i.startswith('~') and not i.startswith('.'):\n",
    "        #print i, truth\n",
    "        temp = i.split('.')[0].split('_')[2]\n",
    "        true_wids.append(truth[int(temp)][1])\n",
    "        im_list.append(url_path+i)\n",
    "\n",
    "im = preprocess_image_batch(im_list,img_size=(256,256), crop_size=(227,227), color_mode=\"rgb\")\n",
    "#}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "th\n"
     ]
    }
   ],
   "source": [
    "# Model parmeters and running the model from the loaded weights{\n",
    "\n",
    "out_r = []\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model = AlexNet(weights_path=\"../../data/weights/alexnet_weights.h5\")\n",
    "model.compile(optimizer=sgd, loss='mse')\n",
    "#print model.summary()\n",
    "#plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "\n",
    "#KFold\n",
    "k = 4\n",
    "\n",
    "im_train, im_test = train_test_split(im_list, test_size=0.2, random_state=234)\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155 155 155\n",
      "132 0.148387096774\n",
      "conv_1 2 1 (155, 96, 55, 55) (96, 55, 55) (290400,)\n",
      "conv_2_1 2 1 (155, 128, 27, 27) (128, 27, 27) (93312,)\n",
      "conv_2_2 2 1 (155, 128, 27, 27) (128, 27, 27) (93312,)\n",
      "conv_3 2 1 (155, 384, 13, 13) (384, 13, 13) (64896,)\n",
      "conv_4_1 2 1 (155, 192, 13, 13) (192, 13, 13) (32448,)\n",
      "conv_4_2 2 1 (155, 192, 13, 13) (192, 13, 13) (32448,)\n",
      "conv_5_1 2 1 (155, 128, 13, 13) (128, 13, 13) (21632,)\n",
      "conv_5_2 2 1 (155, 128, 13, 13) (128, 13, 13) (21632,)\n",
      "dense_1 2 1 (155, 4096) (4096,) (4096,)\n",
      "dense_2 2 1 (155, 4096) (4096,) (4096,)\n",
      "dense_3 2 1 (155, 1000) (1000,) (1000,)\n"
     ]
    }
   ],
   "source": [
    "#Training data pkl\n",
    "fp_name = '../../data/pkl/'+str(p)+'_train_no_lesion_performance.txt'\n",
    "fp = open(fp_name,'a+')\n",
    "im_temp = preprocess_image_batch(im_train,img_size=(256,256), crop_size=(227,227), color_mode=\"rgb\")\n",
    "out = model.predict(im_temp,batch_size=64)\n",
    "\n",
    "true_valid_wids = []\n",
    "for i in im_train:\n",
    "        temp1 = i.split('/')[4]\n",
    "        temp = temp1.split('.')[0].split('_')[2]\n",
    "        true_valid_wids.append(truth[int(temp)][1])\n",
    "\n",
    "predicted_valid_wids = []\n",
    "for i in range(len(im_train)):\n",
    "    #print im_list[i], pprint_output(out[i]), true_wids[i]\n",
    "    predicted_valid_wids.append(pprint_output(out[i]))\n",
    "\n",
    "count, error  = top5accuracy(true_valid_wids, predicted_valid_wids)\n",
    "\n",
    "fp.write(str(p)+' '+str(count)+' '+str(len(im_train))+' '+str(error)+'\\n')\n",
    "\n",
    "\n",
    "print len(true_valid_wids), len(predicted_valid_wids), len(im_train)\n",
    "print count, error\n",
    "\n",
    "\n",
    "#}\n",
    "# Code snippet to get the activation values and saving information{\n",
    "data = np.array([])\n",
    "\n",
    "i = 0\n",
    "result ={}\n",
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    if len(weights) > 0:\n",
    "        activations = get_activations(model,i,im_temp)\n",
    "        if result.get(layer.name, None) is None:\n",
    "            result[layer.name] = activations[0]\n",
    "            temp = np.mean(activations[0], axis=0).ravel()\n",
    "            print layer.name,len(weights),len(activations), activations[0].shape, np.mean(activations[0], axis=0).shape, temp.shape\n",
    "            data = np.append(data, temp)\n",
    "    i += 1\n",
    "\n",
    "fp.close()\n",
    "with open('../../data/pkl/'+str(p)+'_train.pkl', 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39 39 39\n",
      "28 0.282051282051\n",
      "conv_1 2 1 (39, 96, 55, 55) (96, 55, 55) (290400,)\n",
      "conv_2_1 2 1 (39, 128, 27, 27) (128, 27, 27) (93312,)\n",
      "conv_2_2 2 1 (39, 128, 27, 27) (128, 27, 27) (93312,)\n",
      "conv_3 2 1 (39, 384, 13, 13) (384, 13, 13) (64896,)\n",
      "conv_4_1 2 1 (39, 192, 13, 13) (192, 13, 13) (32448,)\n",
      "conv_4_2 2 1 (39, 192, 13, 13) (192, 13, 13) (32448,)\n",
      "conv_5_1 2 1 (39, 128, 13, 13) (128, 13, 13) (21632,)\n",
      "conv_5_2 2 1 (39, 128, 13, 13) (128, 13, 13) (21632,)\n",
      "dense_1 2 1 (39, 4096) (4096,) (4096,)\n",
      "dense_2 2 1 (39, 4096) (4096,) (4096,)\n",
      "dense_3 2 1 (39, 1000) (1000,) (1000,)\n"
     ]
    }
   ],
   "source": [
    "#Testing data pkl\n",
    "fp_name = '../../data/pkl/'+str(p)+'_test_no_lesion_performance.txt'\n",
    "fp = open(fp_name,'a+')\n",
    "\n",
    "im_temp = preprocess_image_batch(im_test,img_size=(256,256), crop_size=(227,227), color_mode=\"rgb\")\n",
    "out = model.predict(im_temp,batch_size=64)\n",
    "\n",
    "true_valid_wids = []\n",
    "for i in im_test:\n",
    "        temp1 = i.split('/')[4]\n",
    "        temp = temp1.split('.')[0].split('_')[2]\n",
    "        true_valid_wids.append(truth[int(temp)][1])\n",
    "\n",
    "predicted_valid_wids = []\n",
    "for i in range(len(im_test)):\n",
    "    #print im_list[i], pprint_output(out[i]), true_wids[i]\n",
    "    predicted_valid_wids.append(pprint_output(out[i]))\n",
    "\n",
    "count, error  = top5accuracy(true_valid_wids, predicted_valid_wids)\n",
    "\n",
    "fp.write(str(p)+' '+str(count)+' '+str(len(im_test))+' '+str(error)+'\\n')\n",
    "\n",
    "\n",
    "print len(true_valid_wids), len(predicted_valid_wids), len(im_test)\n",
    "print count, error\n",
    "\n",
    "\n",
    "#}\n",
    "# Code snippet to get the activation values and saving information{\n",
    "data = np.array([])\n",
    "\n",
    "i = 0\n",
    "result ={}\n",
    "for layer in model.layers:\n",
    "    weights = layer.get_weights()\n",
    "    if len(weights) > 0:\n",
    "        activations = get_activations(model,i,im_temp)\n",
    "        if result.get(layer.name, None) is None:\n",
    "            result[layer.name] = activations[0]\n",
    "            temp = np.mean(activations[0], axis=0).ravel()\n",
    "            print layer.name,len(weights),len(activations), activations[0].shape, np.mean(activations[0], axis=0).shape, temp.shape\n",
    "            data = np.append(data, temp)\n",
    "    i += 1\n",
    "\n",
    "fp.close()\n",
    "with open('../../data/pkl/'+str(p)+'_test.pkl', 'wb') as f:\n",
    "    pickle.dump(data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Starting Fold: ', 1)\n",
      "39 39 39\n",
      "33 0.153846153846\n",
      "conv_1 2 1 (39, 96, 55, 55) (96, 55, 55) (290400,)\n",
      "conv_2_1 2 1 (39, 128, 27, 27) (128, 27, 27) (93312,)\n",
      "conv_2_2 2 1 (39, 128, 27, 27) (128, 27, 27) (93312,)\n",
      "conv_3 2 1 (39, 384, 13, 13) (384, 13, 13) (64896,)\n",
      "conv_4_1 2 1 (39, 192, 13, 13) (192, 13, 13) (32448,)\n",
      "conv_4_2 2 1 (39, 192, 13, 13) (192, 13, 13) (32448,)\n",
      "conv_5_1 2 1 (39, 128, 13, 13) (128, 13, 13) (21632,)\n",
      "conv_5_2 2 1 (39, 128, 13, 13) (128, 13, 13) (21632,)\n",
      "dense_1 2 1 (39, 4096) (4096,) (4096,)\n",
      "dense_2 2 1 (39, 4096) (4096,) (4096,)\n",
      "dense_3 2 1 (39, 1000) (1000,) (1000,)\n",
      "(659272,)\n",
      "('Starting Fold: ', 2)\n",
      "39 39 39\n",
      "29 0.25641025641\n",
      "conv_1 2 1 (39, 96, 55, 55) (96, 55, 55) (290400,)\n",
      "conv_2_1 2 1 (39, 128, 27, 27) (128, 27, 27) (93312,)\n",
      "conv_2_2 2 1 (39, 128, 27, 27) (128, 27, 27) (93312,)\n",
      "conv_3 2 1 (39, 384, 13, 13) (384, 13, 13) (64896,)\n",
      "conv_4_1 2 1 (39, 192, 13, 13) (192, 13, 13) (32448,)\n",
      "conv_4_2 2 1 (39, 192, 13, 13) (192, 13, 13) (32448,)\n",
      "conv_5_1 2 1 (39, 128, 13, 13) (128, 13, 13) (21632,)\n",
      "conv_5_2 2 1 (39, 128, 13, 13) (128, 13, 13) (21632,)\n",
      "dense_1 2 1 (39, 4096) (4096,) (4096,)\n",
      "dense_2 2 1 (39, 4096) (4096,) (4096,)\n",
      "dense_3 2 1 (39, 1000) (1000,) (1000,)\n",
      "(659272,)\n",
      "('Starting Fold: ', 3)\n",
      "39 39 39\n",
      "33 0.153846153846\n",
      "conv_1 2 1 (39, 96, 55, 55) (96, 55, 55) (290400,)\n",
      "conv_2_1 2 1 (39, 128, 27, 27) (128, 27, 27) (93312,)\n",
      "conv_2_2 2 1 (39, 128, 27, 27) (128, 27, 27) (93312,)\n",
      "conv_3 2 1 (39, 384, 13, 13) (384, 13, 13) (64896,)\n",
      "conv_4_1 2 1 (39, 192, 13, 13) (192, 13, 13) (32448,)\n",
      "conv_4_2 2 1 (39, 192, 13, 13) (192, 13, 13) (32448,)\n",
      "conv_5_1 2 1 (39, 128, 13, 13) (128, 13, 13) (21632,)\n",
      "conv_5_2 2 1 (39, 128, 13, 13) (128, 13, 13) (21632,)\n",
      "dense_1 2 1 (39, 4096) (4096,) (4096,)\n",
      "dense_2 2 1 (39, 4096) (4096,) (4096,)\n",
      "dense_3 2 1 (39, 1000) (1000,) (1000,)\n",
      "(659272,)\n",
      "('Starting Fold: ', 4)\n",
      "38 38 38\n",
      "37 0.0263157894737\n",
      "conv_1 2 1 (38, 96, 55, 55) (96, 55, 55) (290400,)\n",
      "conv_2_1 2 1 (38, 128, 27, 27) (128, 27, 27) (93312,)\n",
      "conv_2_2 2 1 (38, 128, 27, 27) (128, 27, 27) (93312,)\n",
      "conv_3 2 1 (38, 384, 13, 13) (384, 13, 13) (64896,)\n",
      "conv_4_1 2 1 (38, 192, 13, 13) (192, 13, 13) (32448,)\n",
      "conv_4_2 2 1 (38, 192, 13, 13) (192, 13, 13) (32448,)\n",
      "conv_5_1 2 1 (38, 128, 13, 13) (128, 13, 13) (21632,)\n",
      "conv_5_2 2 1 (38, 128, 13, 13) (128, 13, 13) (21632,)\n",
      "dense_1 2 1 (38, 4096) (4096,) (4096,)\n",
      "dense_2 2 1 (38, 4096) (4096,) (4096,)\n",
      "dense_3 2 1 (38, 1000) (1000,) (1000,)\n",
      "(659272,)\n"
     ]
    }
   ],
   "source": [
    "image_list_test = '../../data/pkl/'+p+'_image_list_test.txt'\n",
    "with open(image_list_test,'wb') as f:\n",
    "    for i in im_test:\n",
    "        f.write(i+'\\n')\n",
    "\n",
    "kf = KFold(n_splits= k)\n",
    "fold = 1\n",
    "fp_name = '../../data/pkl/'+str(p)+'_no_lesion_performance.txt'\n",
    "fp = open(fp_name,'a+')\n",
    "for train_index, valid_index in kf.split(im_train):\n",
    "    print(\"Starting Fold: \", fold)\n",
    "    im_valid_train = [im_train[i] for i in train_index] \n",
    "    im_valid_test = [im_train[i] for i in valid_index]\n",
    "    \n",
    "    image_list_train = '../../data/pkl/'+p+'_image_list_train_fold_'+str(fold)+'.txt'\n",
    "    with open(image_list_train,'wb') as f:\n",
    "        for i in im_valid_train:\n",
    "            f.write(i+'\\n')\n",
    "    \n",
    "    image_list_valid = '../../data/pkl/'+p+'_image_list_valid_fold_'+str(fold)+'.txt'\n",
    "    with open(image_list_valid,'wb') as f:\n",
    "        for i in im_valid_test:\n",
    "            f.write(i+'\\n')\n",
    "    \n",
    "   \n",
    "    im_temp = preprocess_image_batch(im_valid_test,img_size=(256,256), crop_size=(227,227), color_mode=\"rgb\")\n",
    "    out = model.predict(im_temp,batch_size=64)\n",
    "\n",
    "    true_valid_wids = []\n",
    "    for i in im_valid_test:\n",
    "            temp1 = i.split('/')[4]\n",
    "            temp = temp1.split('.')[0].split('_')[2]\n",
    "            true_valid_wids.append(truth[int(temp)][1])\n",
    "    \n",
    "    predicted_valid_wids = []\n",
    "    for i in range(len(im_valid_test)):\n",
    "        #print im_list[i], pprint_output(out[i]), true_wids[i]\n",
    "        predicted_valid_wids.append(pprint_output(out[i]))\n",
    "        \n",
    "    count, error  = top5accuracy(true_valid_wids, predicted_valid_wids)\n",
    "    \n",
    "    fp.write(str(p)+' '+str(fold)+' '+str(count)+' '+str(len(im_valid_test))+' '+str(error)+'\\n')\n",
    "\n",
    "    \n",
    "    print len(true_valid_wids), len(predicted_valid_wids), len(im_valid_test)\n",
    "    print count, error\n",
    "    \n",
    "    \n",
    "    #}\n",
    "    # Code snippet to get the activation values and saving information{\n",
    "    data = np.array([])\n",
    "\n",
    "    i = 0\n",
    "    result ={}\n",
    "    for layer in model.layers:\n",
    "        weights = layer.get_weights()\n",
    "        if len(weights) > 0:\n",
    "            activations = get_activations(model,i,im_temp)\n",
    "            if result.get(layer.name, None) is None:\n",
    "                result[layer.name] = activations[0]\n",
    "                temp = np.mean(activations[0], axis=0).ravel()\n",
    "                print layer.name,len(weights),len(activations), activations[0].shape, np.mean(activations[0], axis=0).shape, temp.shape\n",
    "                data = np.append(data, temp)\n",
    "        i += 1\n",
    "    print data.shape\n",
    "    out_r.append(data)\n",
    "    fold += 1\n",
    "    \n",
    "fp.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('inanimate_fold_1_train', 659272)\n",
      "('inanimate_fold_2_train', 659272)\n",
      "('inanimate_fold_3_train', 659272)\n",
      "('inanimate_fold_4_train', 659272)\n"
     ]
    }
   ],
   "source": [
    "#Saving all the data into pkl files\n",
    "for i in range(k):\n",
    "    name = p+'_fold_'+str(i+1)+'_train'\n",
    "    out_data = out_r[i]\n",
    "    with open('../../data/pkl/'+name+'.pkl', 'wb') as f:\n",
    "        pickle.dump(out_data, f)\n",
    "    print(name, len(out_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code Snippet for any plots if needed{\n",
    "#plt.figure(p_num)\n",
    "#plt.hist(data,bins='auto',color = 'blue')\n",
    "#plt.title('Histogram of '+p+ ' class')\n",
    "#plt.savefig('../../results/histograms/'+p+'_hist_alex.png')\n",
    "#p_num += 1\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
