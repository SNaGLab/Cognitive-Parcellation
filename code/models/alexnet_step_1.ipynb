{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "#To hide warnings export PYTHONWARNINGS=\"ignore\"\n",
    "#Imports{\n",
    "\n",
    "import os\n",
    "from os.path import dirname\n",
    "from os.path import join\n",
    "os.environ['KERAS_BACKEND'] = 'theano'\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' #Cha\n",
    "\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    \n",
    "import cPickle as pickle\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from scipy.misc import imread\n",
    "from scipy.misc import imresize\n",
    "from scipy.io import loadmat\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, MaxPooling2D, Input, ZeroPadding2D,merge,Lambda\n",
    "from keras.layers.convolutional import Convolution2D\n",
    "from keras.models import Model\n",
    "from keras.utils.layer_utils import convert_all_kernels_in_model\n",
    "from keras.optimizers import SGD\n",
    "from keras import backend as K\n",
    "from keras.engine import Layer\n",
    "from keras.layers.core import Lambda\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.layers.core import  Lambda\n",
    "from keras.regularizers import l2\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code snippet needed to read activation values from each layer of the pre-trained artificial neural networks\n",
    "def get_activations(model, layer, X_batch):\n",
    "    #keras.backend.function(inputs, outputs, updates=None)\n",
    "    get_activations = K.function([model.layers[0].input, K.learning_phase()], [model.layers[layer].output,])\n",
    "    #The learning phase flag is a bool tensor (0 = test, 1 = train)\n",
    "    activations = get_activations([X_batch,0])\n",
    "    return activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to pre-process the input image to ensure uniform size and color\n",
    "def preprocess_image_batch(image_paths, img_size=None, crop_size=None, color_mode='rgb', out=None):\n",
    "    \"\"\"\n",
    "    Consistent preprocessing of images batches\n",
    "    :param image_paths: iterable: images to process\n",
    "    :param crop_size: tuple: crop images if specified\n",
    "    :param img_size: tuple: resize images if specified\n",
    "    :param color_mode: Use rgb or change to bgr mode based on type of model you want to use\n",
    "    :param out: append output to this iterable if specified\n",
    "    \"\"\"\n",
    "    img_list = []\n",
    "\n",
    "    for im_path in image_paths:\n",
    "        img = imread(im_path, mode='RGB')\n",
    "        #print im_path\n",
    "        #print img.shape\n",
    "        if img_size:\n",
    "            img = imresize(img, img_size)\n",
    "\n",
    "        img = img.astype('float32')\n",
    "        # We normalize the colors (in RGB space) with the empirical means on the training set\n",
    "        img[:, :, 0] -= 123.68\n",
    "        img[:, :, 1] -= 116.779\n",
    "        img[:, :, 2] -= 103.939\n",
    "        # We permute the colors to get them in the BGR order\n",
    "        if color_mode == 'bgr':\n",
    "            img[:, :, [0, 1, 2]] = img[:, :, [2, 1, 0]]\n",
    "        img = img.transpose((2, 0, 1))\n",
    "\n",
    "        if crop_size:\n",
    "            img = img[:, (img_size[0] - crop_size[0]) // 2:(img_size[0] + crop_size[0]) // 2\n",
    "            , (img_size[1] - crop_size[1]) // 2:(img_size[1] + crop_size[1]) // 2]\n",
    "\n",
    "        img_list.append(img)\n",
    "\n",
    "    try:\n",
    "        img_batch = np.stack(img_list, axis=0)\n",
    "    except:\n",
    "        print im_path\n",
    "        raise ValueError('when img_size and crop_size are None, images'\n",
    "                ' in image_paths must have the same shapes.')\n",
    "\n",
    "    if out is not None and hasattr(out, 'append'):\n",
    "        out.append(img_batch)\n",
    "    else:\n",
    "        return img_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper function to normalization across channels\n",
    "K.set_image_dim_ordering('th')\n",
    "def crosschannelnormalization(alpha=1e-4, k=2, beta=0.75, n=5, **kwargs):\n",
    "    \"\"\"\n",
    "    This is the function used for cross channel normalization in the original\n",
    "    Alexnet\n",
    "    \"\"\"\n",
    "    def f(X):\n",
    "        if K.image_dim_ordering()=='tf':\n",
    "            b, r, c, ch = X.get_shape()\n",
    "        else:\n",
    "            b, ch, r, c = X.shape\n",
    "\n",
    "        half = n // 2\n",
    "        square = K.square(X)\n",
    "        scale = k\n",
    "        if K.image_dim_ordering() == 'th':\n",
    "            extra_channels = K.spatial_2d_padding(K.permute_dimensions(square, (0, 2, 3, 1)), ((0,0),(half,half)))\n",
    "            extra_channels = K.permute_dimensions(extra_channels, (0, 3, 1, 2))\n",
    "            for i in range(n):\n",
    "                scale += alpha * extra_channels[:, i:i+ch, :, :]\n",
    "        if K.image_dim_ordering() == 'tf':\n",
    "            extra_channels = K.spatial_2d_padding(K.permute_dimensions(square, (0, 3, 1, 2)), (half, 0))\n",
    "            extra_channels = K.permute_dimensions(extra_channels, (0, 2, 3, 1))\n",
    "            for i in range(n):\n",
    "                scale += alpha * extra_channels[:, :, :, i:i+int(ch)]\n",
    "        scale = scale ** beta\n",
    "        return X / scale\n",
    "\n",
    "\n",
    "    return Lambda(f, output_shape=lambda input_shape: input_shape, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Helper Function to split tensor\n",
    "def splittensor(axis=1, ratio_split=1, id_split=0, **kwargs):\n",
    "    def f(X):\n",
    "        div = K.shape(X)[axis] // ratio_split\n",
    "\n",
    "        if axis == 0:\n",
    "            output = X[id_split*div:(id_split+1)*div, :, :, :]\n",
    "        elif axis == 1:\n",
    "            output = X[:, id_split*div:(id_split+1)*div, :, :]\n",
    "        elif axis == 2:\n",
    "            output = X[:, :, id_split*div:(id_split+1)*div, :]\n",
    "        elif axis == 3:\n",
    "            output = X[:, :, :, id_split*div:(id_split+1)*div]\n",
    "        else:\n",
    "            raise ValueError(\"This axis is not possible\")\n",
    "        return output\n",
    "\n",
    "    def g(input_shape):\n",
    "        output_shape = list(input_shape)\n",
    "        output_shape[axis] = output_shape[axis] // ratio_split\n",
    "        return tuple(output_shape)\n",
    "\n",
    "\n",
    "    return Lambda(f, output_shape=lambda input_shape: g(input_shape), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alexnet layer architecture class\n",
    "def AlexNet(img_shape=(3, 227, 227), n_classes=1000, l2_reg=0.,weights_path=None, lambda_mask=None):\n",
    "\n",
    "    dim_ordering = K.image_dim_ordering()\n",
    "    print dim_ordering\n",
    "    if dim_ordering == 'th':\n",
    "        batch_index = 0\n",
    "        channel_index = 1\n",
    "        row_index = 2\n",
    "        col_index = 3\n",
    "    if dim_ordering == 'tf':\n",
    "        batch_index = 0\n",
    "        channel_index = 3\n",
    "        row_index = 1\n",
    "        col_index = 2\n",
    "        \n",
    "    \n",
    "    inputs = Input(img_shape)\n",
    "\n",
    "    conv_1 = Convolution2D(96, 11, 11, subsample=(4, 4), activation='relu',\n",
    "                           name='conv_1', W_regularizer=l2(l2_reg))(inputs)\n",
    "\n",
    "    if lambda_mask is not None:\n",
    "        conv_1_mask  = np.reshape(lambda_mask[0:290400], (96,55,55))\n",
    "    else:\n",
    "        conv_1_mask = np.ones(shape=((96, 55, 55)))\n",
    "    \n",
    "    conv_1_mask  = K.variable(conv_1_mask)\n",
    "    conv_1_lambda = Lambda(lambda x: x * conv_1_mask)(conv_1)\n",
    "\n",
    "    conv_2 = MaxPooling2D((3, 3), strides=(2, 2))(conv_1_lambda)\n",
    "    conv_2 = crosschannelnormalization(name=\"convpool_1\")(conv_2)\n",
    "    conv_2 = ZeroPadding2D((2, 2))(conv_2)\n",
    "    conv_2 = merge([\n",
    "        Convolution2D(128, 5, 5, activation=\"relu\", name='conv_2_'+str(i+1),\n",
    "                      W_regularizer=l2(l2_reg))(\n",
    "            splittensor(axis=channel_index, ratio_split=2, id_split=i)(conv_2)\n",
    "        ) for i in range(2)], mode='concat', concat_axis=channel_index, name=\"conv_2\")\n",
    "\n",
    "    if lambda_mask is not None:\n",
    "        conv_2_mask  = np.reshape(lambda_mask[290400:477024],(256, 27, 27) )\n",
    "    else:\n",
    "        conv_2_mask = np.ones(shape=((256, 27, 27)))\n",
    "        \n",
    "    conv_2_mask = K.variable(conv_2_mask)\n",
    "    conv_2_lambda = Lambda(lambda x: x * conv_2_mask)(conv_2)\n",
    "\n",
    "    conv_3 = MaxPooling2D((3, 3), strides=(2, 2))(conv_2_lambda)\n",
    "    conv_3 = crosschannelnormalization()(conv_3)\n",
    "    conv_3 = ZeroPadding2D((1, 1))(conv_3)\n",
    "    conv_3 = Convolution2D(384, 3, 3, activation='relu', name='conv_3',\n",
    "                           W_regularizer=l2(l2_reg))(conv_3)\n",
    "\n",
    "    if lambda_mask is not None:\n",
    "        conv_3_mask  = np.reshape(lambda_mask[477024:541920],(384, 13, 13))\n",
    "    else:\n",
    "        conv_3_mask = np.ones(shape=((384, 13, 13)))\n",
    "    \n",
    "    conv_3_mask = K.variable(conv_3_mask)\n",
    "    conv_3_lambda = Lambda(lambda x: x * conv_3_mask)(conv_3)\n",
    "\n",
    "    conv_4 = ZeroPadding2D((1, 1))(conv_3_lambda)\n",
    "    conv_4 = merge([\n",
    "        Convolution2D(192, 3, 3, activation=\"relu\", name='conv_4_'+str(i+1),\n",
    "                      W_regularizer=l2(l2_reg))(\n",
    "            splittensor(axis=channel_index, ratio_split=2, id_split=i)(conv_4)\n",
    "        ) for i in range(2)], mode='concat', concat_axis=channel_index, name=\"conv_4\")\n",
    "\n",
    "    if lambda_mask is not None:\n",
    "        conv_4_mask  = np.reshape(lambda_mask[541920:606816],(384, 13, 13))\n",
    "    else:\n",
    "        conv_4_mask = np.ones(shape=((384, 13, 13)))\n",
    "        \n",
    "    conv_4_mask = K.variable(conv_4_mask)\n",
    "    conv_4_lambda = Lambda(lambda x: x * conv_4_mask)(conv_4)\n",
    "\n",
    "    conv_5 = ZeroPadding2D((1, 1))(conv_4_lambda)\n",
    "    conv_5 = merge([\n",
    "        Convolution2D(128, 3, 3, activation=\"relu\", name='conv_5_'+str(i+1),\n",
    "                      W_regularizer=l2(l2_reg))(\n",
    "            splittensor(axis=channel_index, ratio_split=2, id_split=i)(conv_5)\n",
    "        ) for i in range(2)], mode='concat', concat_axis=channel_index, name=\"conv_5\")\n",
    "\n",
    "    if lambda_mask is not None:\n",
    "        conv_5_mask  = np.reshape(lambda_mask[606816:650080],(256, 13, 13))\n",
    "    else:\n",
    "        conv_5_mask = np.ones(shape=((256, 13, 13)))\n",
    "    \n",
    "    conv_5_mask = K.variable(conv_5_mask)\n",
    "    conv_5_lambda = Lambda(lambda x: x * conv_5_mask)(conv_5)\n",
    "\n",
    "    dense_1 = MaxPooling2D((3, 3), strides=(2, 2), name=\"convpool_5\")(conv_5_lambda)\n",
    "\n",
    "    dense_1 = Flatten(name=\"flatten\")(dense_1)\n",
    "    dense_1 = Dense(4096, activation='relu', name='dense_1',\n",
    "                    W_regularizer=l2(l2_reg))(dense_1)\n",
    "\n",
    "    if lambda_mask is not None:\n",
    "        dense_1_mask  = np.reshape(lambda_mask[650080:654176],(4096,))\n",
    "    else:\n",
    "        dense_1_mask = np.ones(shape=((4096,)))\n",
    "    \n",
    "    \n",
    "    dense_1_mask = K.variable(dense_1_mask)\n",
    "    dense_1_lambda = Lambda(lambda x: x * dense_1_mask)(dense_1)\n",
    "\n",
    "    dense_2 = Dropout(0.5)(dense_1_lambda)\n",
    "    dense_2 = Dense(4096, activation='relu', name='dense_2',\n",
    "                    W_regularizer=l2(l2_reg))(dense_2)\n",
    "\n",
    "    if lambda_mask is not None:\n",
    "        dense_2_mask  = np.reshape(lambda_mask[654176:658272],(4096,))\n",
    "    else:\n",
    "        dense_2_mask = np.ones(shape=((4096,)))\n",
    "    \n",
    "    dense_2_mask = K.variable(dense_2_mask)\n",
    "    dense_2_lambda = Lambda(lambda x: x * dense_2_mask)(dense_2)\n",
    "\n",
    "    dense_3 = Dropout(0.5)(dense_2_lambda)\n",
    "    if n_classes == 1000:\n",
    "        dense_3 = Dense(n_classes, name='dense_3',\n",
    "                        W_regularizer=l2(l2_reg))(dense_3)\n",
    "        if lambda_mask is not None:\n",
    "            dense_3_mask  = np.reshape(lambda_mask[658272:659272],(1000,))\n",
    "        else:\n",
    "            dense_3_mask = np.ones(shape=((1000,)))\n",
    "        dense_3_mask = K.variable(dense_3_mask)\n",
    "        dense_3_lambda = Lambda(lambda x: x * dense_3_mask)(dense_3)\n",
    "    else:\n",
    "        # We change the name so when loading the weights_file from a\n",
    "        # Imagenet pretrained model does not crash\n",
    "        dense_3 = Dense(n_classes, name='dense_3_new',\n",
    "                        W_regularizer=l2(l2_reg))(dense_3)\n",
    "        if lambda_mask is not None:\n",
    "            dense_3_mask  = np.reshape(lambda_mask[658272:659272],(1000,))\n",
    "        else:\n",
    "            dense_3_mask = np.ones(shape=((1000,)))\n",
    "        dense_3_mask = K.variable(dense_3_mask)\n",
    "        dense_3_lambda = Lambda(lambda x: x * dense_3_mask)(dense_3)\n",
    "\n",
    "    prediction = Activation(\"softmax\", name=\"softmax\")(dense_3_lambda)\n",
    "\n",
    "    model = Model(input=inputs, output=prediction)\n",
    "    if weights_path:\n",
    "        model.load_weights(weights_path)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load the details of all the 1000 classes and the function to conver the synset id to words{\n",
    "meta_clsloc_file = '../../data/meta_clsloc.mat'\n",
    "synsets = loadmat(meta_clsloc_file)['synsets'][0]\n",
    "synsets_imagenet_sorted = sorted([(int(s[0]), str(s[1][0])) for s in synsets[:1000]],key=lambda v: v[1])\n",
    "corr = {}\n",
    "for j in range(1000):\n",
    "    corr[synsets_imagenet_sorted[j][0]] = j\n",
    "\n",
    "corr_inv = {}\n",
    "for j in range(1, 1001):\n",
    "    corr_inv[corr[j]] = j\n",
    "\n",
    "def id_to_words(id_):\n",
    "    return synsets[corr_inv[id_] - 1][2][0]\n",
    "\n",
    "def pprint_output(out, n_max_synsets=10):\n",
    "    wids = []\n",
    "    best_ids = out.argsort()[::-1][:10]\n",
    "    for u in best_ids:\n",
    "        wids.append(str(synsets[corr_inv[u] - 1][1][0]))\n",
    "    #print('%.2f' % round(100 * out[u], 2) + ' : ' + id_to_words(u)+' '+ str(synsets[corr_inv[u] - 1][1][0]))\n",
    "    return wids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code snippet to load the ground truth labels to measure the performance{\n",
    "truth = {}\n",
    "with open('../../data/ILSVRC2014_clsloc_validation_ground_truth.txt') as f:\n",
    "    line_num = 1\n",
    "    for line in f.readlines():\n",
    "        ind_ = int(line)\n",
    "        temp  = None\n",
    "        for i in synsets_imagenet_sorted:\n",
    "            if i[0] == ind_:\n",
    "                temp = i\n",
    "        #print ind_,temp\n",
    "        if temp != None:\n",
    "            truth[line_num] = temp\n",
    "        else:\n",
    "            print '##########', ind_\n",
    "            pass\n",
    "        line_num += 1\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to predict the top 5 accuracy\n",
    "def top5accuracy(true, predicted):\n",
    "    assert len(true) == len(predicted)\n",
    "    result = []\n",
    "    flag  = 0\n",
    "    for i in range(len(true)):\n",
    "        flag  = 0\n",
    "        temp = true[i]\n",
    "        for j in predicted[i]:\n",
    "            if j == temp:\n",
    "                flag = 1\n",
    "                break\n",
    "        if flag == 1:\n",
    "            result.append(1)\n",
    "        else:\n",
    "            result.append(0)\n",
    "    counter = 0.\n",
    "    for i in result:\n",
    "        if i == 1:\n",
    "            counter += 1.\n",
    "    error = 1.0 - counter/float(len(result))\n",
    "    #print len(np.where(np.asarray(result) == 1)[0])\n",
    "    return len(np.where(np.asarray(result) == 1)[0]), error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Perfoming Fold: ', 1)\n",
      "1\n",
      "('Cluster: ', 1, 'Label: ', 0)\n",
      "th\n",
      "animate 1 0 39 1.0\n",
      "inanimate 1 0 39 1.0\n",
      "('Perfoming Fold: ', 2)\n",
      "1\n",
      "('Cluster: ', 1, 'Label: ', 0)\n",
      "th\n",
      "animate 2 0 39 1.0\n",
      "inanimate 2 0 39 1.0\n",
      "('Perfoming Fold: ', 3)\n",
      "1\n",
      "('Cluster: ', 1, 'Label: ', 0)\n",
      "th\n",
      "animate 3 0 39 1.0\n",
      "inanimate 3 0 39 1.0\n",
      "('Perfoming Fold: ', 4)\n",
      "1\n",
      "('Cluster: ', 1, 'Label: ', 0)\n",
      "th\n",
      "animate 4 0 38 1.0\n",
      "inanimate 4 0 38 1.0\n"
     ]
    }
   ],
   "source": [
    "#Reading pkl files from step 0 and clustering it{\n",
    "data_path = '../../data/pkl/'\n",
    "classes = ['animate','inanimate']\n",
    "\n",
    "\n",
    "result= {}\n",
    "\n",
    "k = 4 #Total Number of folds\n",
    "fold = 1\n",
    "\n",
    "for i in range(k):\n",
    "    \n",
    "    print('Perfoming Fold: ', fold)\n",
    "    clf_result = {}\n",
    "    \n",
    "    with open(data_path+classes[0]+'_fold_'+str(fold)+'_train.pkl') as f:\n",
    "        X_fold = pickle.load(f)\n",
    "    with open(data_path+classes[1]+'_fold_'+str(fold)+'_train.pkl') as f:\n",
    "        y_fold = pickle.load(f)\n",
    "    \n",
    "   \n",
    "    \n",
    "    X = np.column_stack((X_fold,y_fold))\n",
    "    \n",
    "    \n",
    "    #DO CLUSTERING AND GET CLUSTERS\n",
    "    \n",
    "    from sklearn.cluster import KMeans\n",
    "    \n",
    "    for j in range(1,101,1):\n",
    "        clf_result[j] = {}\n",
    "        print j\n",
    "        clf = KMeans(n_clusters=j, random_state=143)\n",
    "        y_pred = clf.fit_predict(X)\n",
    "        #print clf.cluster_centers_\n",
    "\n",
    "        for label in set(clf.labels_):\n",
    "            print('Cluster: ',j,'Label: ', label)\n",
    "            \n",
    "          \n",
    "            #Lesioning and measuring performance\n",
    "            pred = clf.predict(X)\n",
    "\n",
    "            loc = np.where(pred==label)\n",
    "            lambda_mask = np.ones(shape=((659272,)))\n",
    "            lambda_mask[loc] = 0.\n",
    "\n",
    "            #plt.scatter(X[:,0],X[:,1], c=y_pred) \n",
    "\n",
    "            sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "            model = AlexNet(weights_path=\"../../data/weights/alexnet_weights.h5\",lambda_mask=lambda_mask)\n",
    "            model.compile(optimizer=sgd, loss='mse')\n",
    "            \n",
    "            flag = 0\n",
    "            dprime = 0.\n",
    "            for p in classes:\n",
    "                im_valid_test = []\n",
    "                image_list_valid = '../../data/pkl/'+p+'_image_list_valid_fold_'+str(fold)+'.txt'\n",
    "                with open(image_list_valid,'rb') as f:\n",
    "                    for line in f.readlines():\n",
    "                        im_valid_test.append(line.strip('\\n'))\n",
    "                im_temp = preprocess_image_batch(im_valid_test,img_size=(256,256), crop_size=(227,227), color_mode=\"rgb\")\n",
    "                out = model.predict(im_temp,batch_size=64)\n",
    "\n",
    "                true_valid_wids = []\n",
    "                for i in im_valid_test:\n",
    "                        temp1 = i.split('/')[4]\n",
    "                        temp = temp1.split('.')[0].split('_')[2]\n",
    "                        true_valid_wids.append(truth[int(temp)][1])\n",
    "\n",
    "                predicted_valid_wids = []\n",
    "                for i in range(len(im_valid_test)):\n",
    "                    #print im_list[i], pprint_output(out[i]), true_wids[i]\n",
    "                    predicted_valid_wids.append(pprint_output(out[i]))\n",
    "\n",
    "                count, error  = top5accuracy(true_valid_wids, predicted_valid_wids)\n",
    "\n",
    "                print str(p)+' '+str(fold)+' '+str(count)+' '+str(len(im_valid_test))+' '+str(error)\n",
    "                \n",
    "                if flag == 0:\n",
    "                    dprime = error\n",
    "                    flag = 1\n",
    "                else:\n",
    "                    dprime -= error\n",
    "                    \n",
    "            clf_result[j][label] = dprime\n",
    "    \n",
    "    result[fold] = clf_result\n",
    "    fold += 1\n",
    "#}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {1: {0: 0.0}}, 2: {1: {0: 0.0}}, 3: {1: {0: 0.0}}, 4: {1: {0: 0.0}}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f = 1\n",
    "clf_result = result[f]\n",
    "\n",
    "\n",
    "plt.figure(1)\n",
    "X = range(1,101,1)\n",
    "for cl in X:\n",
    "    i = 0\n",
    "    for item in clf_result[cl].keys():\n",
    "        plt.plot(cl,clf_result[cl][item],'ro')\n",
    "        i += 1\n",
    "        \n",
    "plt.xticks(X)\n",
    "plt.xlabel('Number of cluster(s) k')\n",
    "plt.ylabel(\"Performance - d' (Animate vs Inanimate)\")\n",
    "plt.title('Scree Plot for fold '+ str(f))\n",
    "plt.savefig('../../results/scree/results_fold_'+str(f)+'.svg', format='svg', dpi=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
